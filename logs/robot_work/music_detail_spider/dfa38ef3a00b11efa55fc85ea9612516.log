2024-11-11 17:03:54 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: robot_work)
2024-11-11 17:03:54 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.10.0, Python 3.12.0 (tags/v3.12.0:0fb18b0, Oct  2 2023, 13:03:39) [MSC v.1935 64 bit (AMD64)], pyOpenSSL 24.2.1 (OpenSSL 3.3.2 3 Sep 2024), cryptography 43.0.3, Platform Windows-11-10.0.22631-SP0
2024-11-11 17:03:54 [music_detail_spider] INFO: Reading start URLs from redis key 'detail_url_queue' (batch size: 16, encoding: utf-8)
2024-11-11 17:03:54 [scrapy.addons] INFO: Enabled addons:
[]
2024-11-11 17:03:54 [asyncio] DEBUG: Using selector: SelectSelector
2024-11-11 17:03:54 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2024-11-11 17:03:54 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2024-11-11 17:03:55 [scrapy.extensions.telnet] INFO: Telnet Password: 3465588dfee1751b
2024-11-11 17:03:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2024-11-11 17:03:55 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'robot_work',
 'DUPEFILTER_CLASS': 'scrapy_redis.dupefilter.RFPDupeFilter',
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'C:\\robot_work\\logs\\robot_work\\music_detail_spider\\dfa38ef3a00b11efa55fc85ea9612516.log',
 'NEWSPIDER_MODULE': 'robot_work.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'ROBOTSTXT_OBEY': True,
 'SCHEDULER': 'scrapy_redis.scheduler.Scheduler',
 'SPIDER_MODULES': ['robot_work.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2024-11-11 17:03:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'robot_work.middlewares.CustomHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2024-11-11 17:03:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2024-11-11 17:03:55 [pymongo.topology] DEBUG: {"topologyId": {"$oid": "6731c87bb46ad984d55fc818"}, "message": "Starting topology monitoring"}
2024-11-11 17:03:55 [pymongo.topology] DEBUG: {"topologyId": {"$oid": "6731c87bb46ad984d55fc818"}, "previousDescription": "<TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: []>", "newDescription": "<TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None>]>", "message": "Topology description changed"}
2024-11-11 17:03:55 [pymongo.topology] DEBUG: {"topologyId": {"$oid": "6731c87bb46ad984d55fc818"}, "serverHost": "localhost", "serverPort": 27017, "message": "Starting server monitoring"}
2024-11-11 17:03:55 [pymongo.connection] DEBUG: {"clientId": {"$oid": "6731c87bb46ad984d55fc818"}, "message": "Connection pool created", "serverHost": "localhost", "serverPort": 27017}
2024-11-11 17:03:55 [scrapy.middleware] INFO: Enabled item pipelines:
['robot_work.pipelines.MongoDBPipeline']
2024-11-11 17:03:55 [scrapy.core.engine] INFO: Spider opened
2024-11-11 17:03:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-11 17:03:55 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2024-11-11 17:03:55 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:04:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/robots.txt> (referer: None)
2024-11-11 17:05:21 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:05:21 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2024-11-11 17:05:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8259436262> (referer: None)
2024-11-11 17:05:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=4887974807> (referer: None)
2024-11-11 17:05:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6771433039> (referer: None)
2024-11-11 17:05:26 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:05:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=2478853012> (referer: None)
2024-11-11 17:05:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=2144082923> (referer: None)
2024-11-11 17:05:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9127189679> (referer: None)
2024-11-11 17:05:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7493015991> (referer: None)
2024-11-11 17:05:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8879854870> (referer: None)
2024-11-11 17:05:26 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '3',
 'description': '介绍：华语顶级音综，一开嗓神仙沦陷！！！他们真的太会唱了！我不允许你们没有听过，歌单持续更新中，欢迎收藏，感谢聆听。',
 'play': '410069',
 'songs': '153',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:05:57 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '3',
 'description': '介绍：华语顶级音综，一开嗓神仙沦陷！！！他们真的太会唱了！我不允许你们没有听过，歌单持续更新中，欢迎收藏，感谢聆听。',
 'play': '410069',
 'songs': '153',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:05:57 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '384',
 'description': '介绍：岁月是神偷，轻易偷走最珍贵的时间。往事不可追，唯有回忆作陪。1990年的岁末没有严冬的寒冷，空气中弥漫着淡淡的温暖，这个时候的罗大佑已经36岁并发行了一首温暖胜过艳阳的歌曲《恋曲1990》。同年的郭富城发布专辑《对你爱不完》并迅速走红。1991年中国著名摇滚乐队黑豹乐队发行了他们的首张专辑《黑豹》，梅艳芳发布了新歌《亲密爱人》送给他的男朋友保罗，可以说是他们的爱情恋曲。90年代的李宗盛已经是滚石的金牌创作人，并于92年创作了如今的至尊级金曲《当爱已成往事》，首次与林忆莲搭档对唱，而这一年王菲一夜成名站到了香港乐坛的最顶峰，“四大天王”也崛起，港星开始流行大陆。太长时间没有发新曲的张信哲，似乎已被人遗忘。1993年的张学友处于事业低峰期，女朋友罗美薇的细心安慰，不离不弃使张学友慢慢恢复信心走上事业巅峰期，这一年张宇发布专辑《用心良苦》轰动一时，奠定了当时“苦情男”的地位。《爱江山更爱美人》是李丽芬演唱的一首中国古典风格的歌曲。这首歌后来被选为1994年马景涛、叶童、周海媚版《倚天屠龙记》片尾曲，时至今日依旧是经典。1995年的央视春晚，孟庭苇穿着白色连衣裙出现，给喜爱她的千万观众带来现场版的《风中有朵雨做的云》，让那个年代的人现在依旧回味无穷。1996年24岁的张惠妹在恩师张雨生的协助下，推出首张专辑，打破台湾唱片年度销量记录。这一年范晓萱19岁，她唱着《樱桃小丸子》和《哆啦A梦》的中文主题曲，走进了歌迷视野。1997年任贤齐开始走红，而这一年华语乐坛最富可能性的天才音乐人张雨生车祸病世，终年31岁。.......已经离我们远去的那个时代，因为有好音乐的存在，而历历在目。那是华语音乐辉煌的十年，也是华语音乐群雄逐鹿的十年。那是我们一起走过的青春，那里有音乐人奋斗的足迹，那里也有悲欢离合的故事。PS：简介从简写的，没有写到的希望大家多多包涵。',
 'play': '17938838',
 'songs': '100',
 'tag': '华语-流行-怀旧',
 'title': '无标题'}
2024-11-11 17:06:27 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '384',
 'description': '介绍：岁月是神偷，轻易偷走最珍贵的时间。往事不可追，唯有回忆作陪。1990年的岁末没有严冬的寒冷，空气中弥漫着淡淡的温暖，这个时候的罗大佑已经36岁并发行了一首温暖胜过艳阳的歌曲《恋曲1990》。同年的郭富城发布专辑《对你爱不完》并迅速走红。1991年中国著名摇滚乐队黑豹乐队发行了他们的首张专辑《黑豹》，梅艳芳发布了新歌《亲密爱人》送给他的男朋友保罗，可以说是他们的爱情恋曲。90年代的李宗盛已经是滚石的金牌创作人，并于92年创作了如今的至尊级金曲《当爱已成往事》，首次与林忆莲搭档对唱，而这一年王菲一夜成名站到了香港乐坛的最顶峰，“四大天王”也崛起，港星开始流行大陆。太长时间没有发新曲的张信哲，似乎已被人遗忘。1993年的张学友处于事业低峰期，女朋友罗美薇的细心安慰，不离不弃使张学友慢慢恢复信心走上事业巅峰期，这一年张宇发布专辑《用心良苦》轰动一时，奠定了当时“苦情男”的地位。《爱江山更爱美人》是李丽芬演唱的一首中国古典风格的歌曲。这首歌后来被选为1994年马景涛、叶童、周海媚版《倚天屠龙记》片尾曲，时至今日依旧是经典。1995年的央视春晚，孟庭苇穿着白色连衣裙出现，给喜爱她的千万观众带来现场版的《风中有朵雨做的云》，让那个年代的人现在依旧回味无穷。1996年24岁的张惠妹在恩师张雨生的协助下，推出首张专辑，打破台湾唱片年度销量记录。这一年范晓萱19岁，她唱着《樱桃小丸子》和《哆啦A梦》的中文主题曲，走进了歌迷视野。1997年任贤齐开始走红，而这一年华语乐坛最富可能性的天才音乐人张雨生车祸病世，终年31岁。.......已经离我们远去的那个时代，因为有好音乐的存在，而历历在目。那是华语音乐辉煌的十年，也是华语音乐群雄逐鹿的十年。那是我们一起走过的青春，那里有音乐人奋斗的足迹，那里也有悲欢离合的故事。PS：简介从简写的，没有写到的希望大家多多包涵。',
 'play': '17938838',
 'songs': '100',
 'tag': '华语-流行-怀旧',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:06:27 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '93',
 'description': '介绍：歌单最新更新时间:2024.11.11宝藏歌曲推荐～本歌单精选冷门/热门的歌曲萝卜白菜，各有所爱，总有一首是你喜欢的快来听听看有好听的歌曲也可以推荐给我哦～',
 'play': '3118325',
 'songs': '173',
 'tag': '流行-浪漫-华语',
 'title': '无标题'}
2024-11-11 17:06:57 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '93',
 'description': '介绍：歌单最新更新时间:2024.11.11宝藏歌曲推荐～本歌单精选冷门/热门的歌曲萝卜白菜，各有所爱，总有一首是你喜欢的快来听听看有好听的歌曲也可以推荐给我哦～',
 'play': '3118325',
 'songs': '173',
 'tag': '流行-浪漫-华语',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:06:57 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '867',
 'description': '介绍：※歌单缘由※在18年10月中，一首唱见的歌曲作品让我有了做这份歌单的理由不久之后我研究了一下云音乐关于唱见类的歌单的情况，发现多为没有成形或者只有ACG日语唱见翻唱类歌单，真正达到成功的屈指可数为此我做了这份没有人挑战过的华语情歌类国人唱见歌单♪选曲方面♭主要是一部分个人感觉喜欢的国人唱见(其中有如今比较火的唱见，也有现在不怎么火但感觉未来很有潜力的唱见)歌曲作品(选曲范围:华语/爱情)，大家可以以多去支持一下哦～[由于某些原因，本歌单无法收录唱见作品后面有"cover"的作品、歌曲下方有热门华语一类的歌曲，望见谅]更新日志:2/22 '
                '增加唱见:神婆SAMA、小凌、Pig小优、小鱼萝莉、uzaki、涵昱昱、瑾轩3/22:移除葛雨晴与熊子新添唱见:清弄、菌菌酱、KBShinya4/17:新增唱见:少年霜5/23:歌单完成修改▼以下为本歌单的唱见大大们▽泠鸢yousa、Akie秋绘、茶理理、Mukyo木西、三无MarBlue、Hanser、KBShinya、漆柚、东京塔子、不是Av的Ay君、Meandi鸦缺、小曲儿、冬名、斯雷嘟dududu、吾恩5n、傘妹、艾辰、肥皂菌、小缘、西国之海妖（司夏）、伦桑、双笙、封茗囧菌、Mario、karin的幸福理论、YUKIri、乌拉喵、雪霏岚岚、里桜Saneyori、叶洛洛、居里里、洛少爷、萧忆情Alex、祈lnory、哦漏QAQ、括号君、少年霜、根小八、墨橙菌、苏打海盐、拉草莓的西瓜JUN、悟我、夏璃夜、人衣大人、泥鳅Niko、匀子Cyrena、RaJor、柚木暖、临暗iZumi、椹酱kice、少恭（翘课迟到）、肆霁、以冬、凯瑟喵、嘟比Dubi、水曜日、千陵安浅、子弥、朵芊、落Aki、晴愔、樱奈、汐什么言、墨橙、纳豆、黑崎子、圈9、wispering4u、佑可猫、AUZ低音走调帝CRITTY、小义学长、Winky诗、西瓜Kune、锦零、白止、易世樊花、桃子在发芽、米白、云横、千是、随家安然、神婆SAMA、Pig小优、小鱼萝莉、uzakin、涵昱、瑾轩、清弄、菌菌酱、熙er、查理Cherry、Vk、谣君、蜉蝣先生、雪回、霏箬、池池和、雪璃、枪缇、予尔w（排序不分先后）感谢欣赏～封面来源@Charlie-hui微博ID:我好像要改名字了已授权PS:请不要拿唱见之间做对比哦～',
 'play': '7873748',
 'songs': '94',
 'tag': '华语-浪漫',
 'title': '无标题'}
2024-11-11 17:07:27 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '867',
 'description': '介绍：※歌单缘由※在18年10月中，一首唱见的歌曲作品让我有了做这份歌单的理由不久之后我研究了一下云音乐关于唱见类的歌单的情况，发现多为没有成形或者只有ACG日语唱见翻唱类歌单，真正达到成功的屈指可数为此我做了这份没有人挑战过的华语情歌类国人唱见歌单♪选曲方面♭主要是一部分个人感觉喜欢的国人唱见(其中有如今比较火的唱见，也有现在不怎么火但感觉未来很有潜力的唱见)歌曲作品(选曲范围:华语/爱情)，大家可以以多去支持一下哦～[由于某些原因，本歌单无法收录唱见作品后面有"cover"的作品、歌曲下方有热门华语一类的歌曲，望见谅]更新日志:2/22 '
                '增加唱见:神婆SAMA、小凌、Pig小优、小鱼萝莉、uzaki、涵昱昱、瑾轩3/22:移除葛雨晴与熊子新添唱见:清弄、菌菌酱、KBShinya4/17:新增唱见:少年霜5/23:歌单完成修改▼以下为本歌单的唱见大大们▽泠鸢yousa、Akie秋绘、茶理理、Mukyo木西、三无MarBlue、Hanser、KBShinya、漆柚、东京塔子、不是Av的Ay君、Meandi鸦缺、小曲儿、冬名、斯雷嘟dududu、吾恩5n、傘妹、艾辰、肥皂菌、小缘、西国之海妖（司夏）、伦桑、双笙、封茗囧菌、Mario、karin的幸福理论、YUKIri、乌拉喵、雪霏岚岚、里桜Saneyori、叶洛洛、居里里、洛少爷、萧忆情Alex、祈lnory、哦漏QAQ、括号君、少年霜、根小八、墨橙菌、苏打海盐、拉草莓的西瓜JUN、悟我、夏璃夜、人衣大人、泥鳅Niko、匀子Cyrena、RaJor、柚木暖、临暗iZumi、椹酱kice、少恭（翘课迟到）、肆霁、以冬、凯瑟喵、嘟比Dubi、水曜日、千陵安浅、子弥、朵芊、落Aki、晴愔、樱奈、汐什么言、墨橙、纳豆、黑崎子、圈9、wispering4u、佑可猫、AUZ低音走调帝CRITTY、小义学长、Winky诗、西瓜Kune、锦零、白止、易世樊花、桃子在发芽、米白、云横、千是、随家安然、神婆SAMA、Pig小优、小鱼萝莉、uzakin、涵昱、瑾轩、清弄、菌菌酱、熙er、查理Cherry、Vk、谣君、蜉蝣先生、雪回、霏箬、池池和、雪璃、枪缇、予尔w（排序不分先后）感谢欣赏～封面来源@Charlie-hui微博ID:我好像要改名字了已授权PS:请不要拿唱见之间做对比哦～',
 'play': '7873748',
 'songs': '94',
 'tag': '华语-浪漫',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:07:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6655442283> (referer: None)
2024-11-11 17:07:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12681888613> (referer: None)
2024-11-11 17:07:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=988690134> (referer: None)
2024-11-11 17:07:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9235269350> (referer: None)
2024-11-11 17:07:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12667172806> (referer: None)
2024-11-11 17:07:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=5117602648> (referer: None)
2024-11-11 17:07:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=5386704458> (referer: None)
2024-11-11 17:07:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12767212840> (referer: None)
2024-11-11 17:07:27 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 16 pages/min), scraped 0 items (at 0 items/min)
2024-11-11 17:07:28 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1141',
 'description': '介绍：/ 音 / 乐 / 是 / 心 / 情 / 的 / 催 / 化 / 剂 '
                '/怎么了又不开心了没关系哼首欢快的歌来拯救你的小确丧你并不孤单看 我一直陪着你啊周围的空气都莫名变得好甜这个世界 '
                '还是很美好的为歌单《以丧止丧 听一首把自己感动到哭的丧的歌》而建的治疗歌单 小丸子表示她很好 大家不用担心抱歉 戏有点多 '
                '哈哈哈哈哈',
 'play': '27790036',
 'songs': '39',
 'tag': '华语-放松-快乐',
 'title': '无标题'}
2024-11-11 17:07:58 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '1141',
 'description': '介绍：/ 音 / 乐 / 是 / 心 / 情 / 的 / 催 / 化 / 剂 '
                '/怎么了又不开心了没关系哼首欢快的歌来拯救你的小确丧你并不孤单看 我一直陪着你啊周围的空气都莫名变得好甜这个世界 '
                '还是很美好的为歌单《以丧止丧 听一首把自己感动到哭的丧的歌》而建的治疗歌单 小丸子表示她很好 大家不用担心抱歉 戏有点多 '
                '哈哈哈哈哈',
 'play': '27790036',
 'songs': '39',
 'tag': '华语-放松-快乐',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:07:58 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '17',
 'description': '介绍：华语实力派嗓音，他们是各大音乐综艺的常驻嘉宾，一开嗓就全场沦陷，哪一位歌手是你的白月光，欢迎评论区留言',
 'play': '1046306',
 'songs': '197',
 'tag': '华语-流行-感动',
 'title': '无标题'}
2024-11-11 17:08:28 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '17',
 'description': '介绍：华语实力派嗓音，他们是各大音乐综艺的常驻嘉宾，一开嗓就全场沦陷，哪一位歌手是你的白月光，欢迎评论区留言',
 'play': '1046306',
 'songs': '197',
 'tag': '华语-流行-感动',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:08:28 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '29',
 'description': '介绍：总有一天，你会遇到一个人，你在他面前可以肆无忌惮，可以随心所欲。而在这之前你需要的做的就只有一件事：变优秀。— — '
                '— — — — — — — — — — — — — 以此歌单祝愿大家收获甜甜的爱情～封面画师：口大奇瘪瘪',
 'play': '2701125',
 'songs': '198',
 'tag': '华语-浪漫-流行',
 'title': '无标题'}
2024-11-11 17:08:59 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '29',
 'description': '介绍：总有一天，你会遇到一个人，你在他面前可以肆无忌惮，可以随心所欲。而在这之前你需要的做的就只有一件事：变优秀。— — '
                '— — — — — — — — — — — — — 以此歌单祝愿大家收获甜甜的爱情～封面画师：口大奇瘪瘪',
 'play': '2701125',
 'songs': '198',
 'tag': '华语-浪漫-流行',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:08:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '15',
 'description': '介绍：天花板治愈嗓，绝美歌声首首入心，顶级治愈系，总有一首成为你的白月光，生活破破烂烂，音乐缝缝补补',
 'play': '1559547',
 'songs': '155',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:09:29 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '15',
 'description': '介绍：天花板治愈嗓，绝美歌声首首入心，顶级治愈系，总有一首成为你的白月光，生活破破烂烂，音乐缝缝补补',
 'play': '1559547',
 'songs': '155',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:09:29 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-11 17:09:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '129',
 'description': '介绍：状似芭蕉貌似岛，阿里山底雾气绕。兰花蝴蝶鱼米乡，日月神潭岛中宝。宝岛台湾一直是很多人心目中所向往的旅游胜地，高山、大海、峡谷、湖泊、少数名族风情、文化、美食（蚵仔煎、彰化肉、姜母鸭、忠孝东路黄牛肉面馆...）等等，造就了台湾无与伦比的迷人魅力与气质。另外，宝岛台湾还孕育出了一大批满腹灵性的SOLO音乐人。本歌单为你持续更新、精选出他们在我心中犹如朱砂痣的代表曲目，希望您喜欢。',
 'play': '5448857',
 'songs': '88',
 'tag': '华语-流行-浪漫',
 'title': '无标题'}
2024-11-11 17:09:59 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '129',
 'description': '介绍：状似芭蕉貌似岛，阿里山底雾气绕。兰花蝴蝶鱼米乡，日月神潭岛中宝。宝岛台湾一直是很多人心目中所向往的旅游胜地，高山、大海、峡谷、湖泊、少数名族风情、文化、美食（蚵仔煎、彰化肉、姜母鸭、忠孝东路黄牛肉面馆...）等等，造就了台湾无与伦比的迷人魅力与气质。另外，宝岛台湾还孕育出了一大批满腹灵性的SOLO音乐人。本歌单为你持续更新、精选出他们在我心中犹如朱砂痣的代表曲目，希望您喜欢。',
 'play': '5448857',
 'songs': '88',
 'tag': '华语-流行-浪漫',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:10:00 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：在阳光的微笑下，开着爱车，心情格外轻松愉悦，路上的每一点风景都是那么赏心悦目。',
 'play': '5357',
 'songs': '43',
 'tag': '华语-驾车-快乐',
 'title': '无标题'}
2024-11-11 17:10:30 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：在阳光的微笑下，开着爱车，心情格外轻松愉悦，路上的每一点风景都是那么赏心悦目。',
 'play': '5357',
 'songs': '43',
 'tag': '华语-驾车-快乐',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:10:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '4992',
 'description': '介绍：在时光中沉淀的首首经典老歌，承载了一段段印刻在内心最深处的回忆。重温经典，回味那些逝去的时光...',
 'play': '298513408',
 'songs': '115',
 'tag': '粤语-怀旧-华语',
 'title': '无标题'}
2024-11-11 17:11:00 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '4992',
 'description': '介绍：在时光中沉淀的首首经典老歌，承载了一段段印刻在内心最深处的回忆。重温经典，回味那些逝去的时光...',
 'play': '298513408',
 'songs': '115',
 'tag': '粤语-怀旧-华语',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:11:00 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '8',
 'description': '介绍：在夜晚寂静之时，这些旋律轻轻地抚摸你的伤痕，带你穿过回忆的河流，走向更加坚定的自己。适合20年代都市独行者的晚间情绪释放，既伤感又温暖的慢摇国风与流行混合，陪伴你在夜色中探索自我的边界。',
 'play': '74342',
 'songs': '57',
 'tag': '华语-流行-古风',
 'title': '无标题'}
2024-11-11 17:11:30 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '8',
 'description': '介绍：在夜晚寂静之时，这些旋律轻轻地抚摸你的伤痕，带你穿过回忆的河流，走向更加坚定的自己。适合20年代都市独行者的晚间情绪释放，既伤感又温暖的慢摇国风与流行混合，陪伴你在夜色中探索自我的边界。',
 'play': '74342',
 'songs': '57',
 'tag': '华语-流行-古风',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:11:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：歌声真挚动人歌词稚拙纯粹加之时光滤镜在静默一人时塞上耳机听听这些老歌一股莫名的感动涌入心间',
 'play': '1708',
 'songs': '271',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
2024-11-11 17:12:01 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：歌声真挚动人歌词稚拙纯粹加之时光滤镜在静默一人时塞上耳机听听这些老歌一股莫名的感动涌入心间',
 'play': '1708',
 'songs': '271',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:12:01 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '21',
 'description': '介绍：你是否也曾有个这样的愿望穿越到某个架空古代做一个浪荡剑客纵酒江湖 快意潇洒正邪爱恨 只凭一念恩怨情仇 '
                '沧海一笑亦或在某个没有高科技的时代在军营里从一个小兵当起金戈铁骑 驰骋沙场一将功成万骨枯虽满身鲜血却从不冷漠江湖老 '
                '红尘儿女飘摇听着这些承载无数江湖义气 英雄豪情的歌曲或大气洒脱 或婉转凄美饮上一壶好酒 岂不快哉一场大醉 '
                '一夜好眠重回江湖梦封面:东方不败Ⅰ林青霞饰——《笑傲江湖2:东方不败》歌曲均选自武侠仙侠影视系列正序对应片名:1. '
                '古剑奇谭2. 新龙门客栈3-4. 2006年版神雕侠侣5. 2017年版射雕英雄传6. 楚留香新传7-8. 绣春刀9. '
                '少年扬家将10. 九阴真经11-12. 黄飞鸿13. 小鱼儿与花无缺14-15. 天下第一16. 功夫17-18. '
                '十面埋伏19. 怪侠一枝梅20. 2019年版倚天屠龙记21. 东邪西毒22. 陆小凤之凤舞九天23. '
                '1983年版神雕侠侣24. 新楚留香25. 轩辕剑之天之痕26-27. 陆小凤与花满楼28. 碧海情天29. '
                '倩女幽魂30. 大话西游31. 蜀山奇侠32. 南帝北丐33. 风云雄霸天下34. 小李飞刀35-36. 大侠霍元甲37. '
                '香帅传奇38. 江湖儿女39. 2001年版倚天屠龙记40. 风云241. 七剑下天山42. 魔剑生死棋43. '
                '1998年版鹿鼎记44. 天涯明月刀45. 浣花洗剑录46. 萧十一郎47. 2014年版神雕侠侣48-50. '
                '新萧十一郎51. 水月洞天52-53. 新边城浪子54. 大人物55-58. 1994年版倚天屠龙记59. '
                '影版白发魔女传60. 1991年版雪山飞狐61. 雪花女神龙62-63. 2008年版射雕英雄传64-66. '
                '仙剑奇侠传三67. 荆轲刺秦68. 青蛇69. 2000年版碧血剑70. 1996年版笑傲江湖71. '
                '1994年版射雕英雄传72. 1991年版雪山飞狐73. 1995年版神雕侠侣74. 武林外传75. '
                '射雕英雄传之铁血丹心76. 2000年版笑傲江湖77. 射雕英雄传之华山论剑78. 影版笑傲江湖79. '
                '东方不败之风云再起80. 少年张三丰',
 'play': '1397230',
 'songs': '80',
 'tag': '华语-影视原声-古风',
 'title': '无标题'}
2024-11-11 17:12:31 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '21',
 'description': '介绍：你是否也曾有个这样的愿望穿越到某个架空古代做一个浪荡剑客纵酒江湖 快意潇洒正邪爱恨 只凭一念恩怨情仇 '
                '沧海一笑亦或在某个没有高科技的时代在军营里从一个小兵当起金戈铁骑 驰骋沙场一将功成万骨枯虽满身鲜血却从不冷漠江湖老 '
                '红尘儿女飘摇听着这些承载无数江湖义气 英雄豪情的歌曲或大气洒脱 或婉转凄美饮上一壶好酒 岂不快哉一场大醉 '
                '一夜好眠重回江湖梦封面:东方不败Ⅰ林青霞饰——《笑傲江湖2:东方不败》歌曲均选自武侠仙侠影视系列正序对应片名:1. '
                '古剑奇谭2. 新龙门客栈3-4. 2006年版神雕侠侣5. 2017年版射雕英雄传6. 楚留香新传7-8. 绣春刀9. '
                '少年扬家将10. 九阴真经11-12. 黄飞鸿13. 小鱼儿与花无缺14-15. 天下第一16. 功夫17-18. '
                '十面埋伏19. 怪侠一枝梅20. 2019年版倚天屠龙记21. 东邪西毒22. 陆小凤之凤舞九天23. '
                '1983年版神雕侠侣24. 新楚留香25. 轩辕剑之天之痕26-27. 陆小凤与花满楼28. 碧海情天29. '
                '倩女幽魂30. 大话西游31. 蜀山奇侠32. 南帝北丐33. 风云雄霸天下34. 小李飞刀35-36. 大侠霍元甲37. '
                '香帅传奇38. 江湖儿女39. 2001年版倚天屠龙记40. 风云241. 七剑下天山42. 魔剑生死棋43. '
                '1998年版鹿鼎记44. 天涯明月刀45. 浣花洗剑录46. 萧十一郎47. 2014年版神雕侠侣48-50. '
                '新萧十一郎51. 水月洞天52-53. 新边城浪子54. 大人物55-58. 1994年版倚天屠龙记59. '
                '影版白发魔女传60. 1991年版雪山飞狐61. 雪花女神龙62-63. 2008年版射雕英雄传64-66. '
                '仙剑奇侠传三67. 荆轲刺秦68. 青蛇69. 2000年版碧血剑70. 1996年版笑傲江湖71. '
                '1994年版射雕英雄传72. 1991年版雪山飞狐73. 1995年版神雕侠侣74. 武林外传75. '
                '射雕英雄传之铁血丹心76. 2000年版笑傲江湖77. 射雕英雄传之华山论剑78. 影版笑傲江湖79. '
                '东方不败之风云再起80. 少年张三丰',
 'play': '1397230',
 'songs': '80',
 'tag': '华语-影视原声-古风',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:12:31 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '31',
 'description': '介绍：我国是历史悠久的文明古国，几千年来创造了灿烂的文化，形成了高尚的道德准则、完整的礼义规范，被世人称为文明古国，礼义之邦。“礼”有礼貌、礼仪、礼节、仪式和礼宾等意涵。“义”有仁义、正义、忠义、情义和义务等意涵。“礼义”作为一个词组，丰富和提升了其分别作为单个词原有的意涵。如“礼义”所表示的含义就有“礼义廉耻”、“礼义教化”以及“以礼治国”等，较之“礼”、“义”作为单个词，其内涵要丰富厚重得多，几乎涵盖了儒家关于人伦、天道、政治、社会、文教和风俗等多方面的基本精神。“华夏”是指汉族的前身，以服饰华采之美为华；以疆界广阔与文化繁荣、礼义道德兴盛为夏。五千年来，在悠久的发展过程中，这片黄土上孕育出无数的文化，如朝代文化、地域文化以及其它各种物质或非物质文化等。—★朝代文化夏朝—《夏》商朝—《商颂》西周—《凤衔书》东周—《溯游》春秋—《春秋序》秦朝—《任尔评说》汉朝—《央央》汉唐—《汉唐逸歌》汉史—《千秋令》隋～清—《万国来朝》★地域文化洛阳—《洛辞》开封—《汴梁华梦》长安—《长安西安》《长安四韵》浙江—《天上白玉京》《折江寻情》《云山入梦舟》北京—《紫禁》南京—《秦淮河边的陈年往事》《金陵谣》苏州—《姑苏人间》武汉—《楚天舒》成都—《锦中客》无锡—《无锡》四大古都—《四城游记》★其它文化人生八雅—《此间风雅颂》工匠精神—《生而为匠》苏公堤—《苏公堤》古典舞蹈—《采薇》折扇文化—《折扇》神话传奇—《御龙行》山水情怀—《与山记》传统乐器—《华乐记》礼仪修养—《华礼记》修心养性—《吃茶记》梨园戏曲—《梨园小记》知己与酒—《青州从事》华夏礼仪—《礼仪之邦》超然心境—《吾道不孤》十二国粹—《十二风华鉴》国家宝藏—《华夏珍萃卷》汉服文化—《今时服华》历史笔墨—《华文记》《千古文心撰流光》篆隶楷行草—《汉体》民以食为天—《小食记》《人间滋味》洛神赋图—《兮若》千里江山图—《江山永巍》清明上河图—《清明上河图》听琴图—《见山是山》韩熙载夜宴图—《独醒》潇湘奇观图—《雾隐潇湘》挥扇仕女图—《盛世遗红》玉洞仙源图—《洞仙尘烟》芦汀密雪图—《芦汀有雪》万里长城—《长城之下》清静经—《江山雪》二十四节气—《二十四小令》文豪风流—《何必诗债换酒钱》《青衫薄》《风流当歌》',
 'play': '529030',
 'songs': '62',
 'tag': '古风-民族-华语',
 'title': '无标题'}
2024-11-11 17:13:01 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '31',
 'description': '介绍：我国是历史悠久的文明古国，几千年来创造了灿烂的文化，形成了高尚的道德准则、完整的礼义规范，被世人称为文明古国，礼义之邦。“礼”有礼貌、礼仪、礼节、仪式和礼宾等意涵。“义”有仁义、正义、忠义、情义和义务等意涵。“礼义”作为一个词组，丰富和提升了其分别作为单个词原有的意涵。如“礼义”所表示的含义就有“礼义廉耻”、“礼义教化”以及“以礼治国”等，较之“礼”、“义”作为单个词，其内涵要丰富厚重得多，几乎涵盖了儒家关于人伦、天道、政治、社会、文教和风俗等多方面的基本精神。“华夏”是指汉族的前身，以服饰华采之美为华；以疆界广阔与文化繁荣、礼义道德兴盛为夏。五千年来，在悠久的发展过程中，这片黄土上孕育出无数的文化，如朝代文化、地域文化以及其它各种物质或非物质文化等。—★朝代文化夏朝—《夏》商朝—《商颂》西周—《凤衔书》东周—《溯游》春秋—《春秋序》秦朝—《任尔评说》汉朝—《央央》汉唐—《汉唐逸歌》汉史—《千秋令》隋～清—《万国来朝》★地域文化洛阳—《洛辞》开封—《汴梁华梦》长安—《长安西安》《长安四韵》浙江—《天上白玉京》《折江寻情》《云山入梦舟》北京—《紫禁》南京—《秦淮河边的陈年往事》《金陵谣》苏州—《姑苏人间》武汉—《楚天舒》成都—《锦中客》无锡—《无锡》四大古都—《四城游记》★其它文化人生八雅—《此间风雅颂》工匠精神—《生而为匠》苏公堤—《苏公堤》古典舞蹈—《采薇》折扇文化—《折扇》神话传奇—《御龙行》山水情怀—《与山记》传统乐器—《华乐记》礼仪修养—《华礼记》修心养性—《吃茶记》梨园戏曲—《梨园小记》知己与酒—《青州从事》华夏礼仪—《礼仪之邦》超然心境—《吾道不孤》十二国粹—《十二风华鉴》国家宝藏—《华夏珍萃卷》汉服文化—《今时服华》历史笔墨—《华文记》《千古文心撰流光》篆隶楷行草—《汉体》民以食为天—《小食记》《人间滋味》洛神赋图—《兮若》千里江山图—《江山永巍》清明上河图—《清明上河图》听琴图—《见山是山》韩熙载夜宴图—《独醒》潇湘奇观图—《雾隐潇湘》挥扇仕女图—《盛世遗红》玉洞仙源图—《洞仙尘烟》芦汀密雪图—《芦汀有雪》万里长城—《长城之下》清静经—《江山雪》二十四节气—《二十四小令》文豪风流—《何必诗债换酒钱》《青衫薄》《风流当歌》',
 'play': '529030',
 'songs': '62',
 'tag': '古风-民族-华语',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:13:01 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：聚会是我们生活中不可或缺的一部分，它让我们感受到友情的温暖与快乐，让我们一起度过难忘的时光！',
 'play': '10633',
 'songs': '45',
 'tag': '华语-流行-网络歌曲',
 'title': '无标题'}
2024-11-11 17:13:31 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：聚会是我们生活中不可或缺的一部分，它让我们感受到友情的温暖与快乐，让我们一起度过难忘的时光！',
 'play': '10633',
 'songs': '45',
 'tag': '华语-流行-网络歌曲',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:13:31 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:13:31 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:14:52 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-11 17:14:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12495218492> (referer: None)
2024-11-11 17:14:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12503956369> (referer: None)
2024-11-11 17:14:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9964282654> (referer: None)
2024-11-11 17:14:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12587137395> (referer: None)
2024-11-11 17:14:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9717820963> (referer: None)
2024-11-11 17:14:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12592262791> (referer: None)
2024-11-11 17:14:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12615757868> (referer: None)
2024-11-11 17:14:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12569374399> (referer: None)
2024-11-11 17:14:53 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '37',
 'description': '介绍：每天上下班的路上都是音乐陪伴着我，不同的心情，听不同风格类型的音乐，已经成为了我的习惯！有时候，在路边、在商场里、在咖啡厅、在理发店…无论在哪里，甚至是在路人的手机铃声，偶遇听到自己喜欢的音乐，此时就会立马搜索收藏下来，生怕错过了！',
 'play': '173626',
 'songs': '29',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:15:23 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '37',
 'description': '介绍：每天上下班的路上都是音乐陪伴着我，不同的心情，听不同风格类型的音乐，已经成为了我的习惯！有时候，在路边、在商场里、在咖啡厅、在理发店…无论在哪里，甚至是在路人的手机铃声，偶遇听到自己喜欢的音乐，此时就会立马搜索收藏下来，生怕错过了！',
 'play': '173626',
 'songs': '29',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:15:23 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1',
 'description': '介绍：每一个年代都有经典老歌它们承载着无数人的青葱岁月，随着时间的流逝，熟悉的旋律会和时光一起，被深藏在记忆的某个角落，当难忘旋律再次缓缓响起，恍如青风迎面吹来...',
 'play': '185029',
 'songs': '294',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:15:54 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '1',
 'description': '介绍：每一个年代都有经典老歌它们承载着无数人的青葱岁月，随着时间的流逝，熟悉的旋律会和时光一起，被深藏在记忆的某个角落，当难忘旋律再次缓缓响起，恍如青风迎面吹来...',
 'play': '185029',
 'songs': '294',
 'tag': '华语-流行-90后',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:15:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12766799065> (referer: None)
2024-11-11 17:15:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12788525429> (referer: None)
2024-11-11 17:15:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12640948826> (referer: None)
2024-11-11 17:15:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12674145081> (referer: None)
2024-11-11 17:15:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12682184758> (referer: None)
2024-11-11 17:15:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12646450605> (referer: None)
2024-11-11 17:15:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12662453990> (referer: None)
2024-11-11 17:15:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12659296496> (referer: None)
2024-11-11 17:15:54 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 16 pages/min), scraped 0 items (at 0 items/min)
2024-11-11 17:15:54 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '17',
 'description': '介绍：经典值得反复聆听，国内比较具有代表性的R&B歌手经典歌曲收录：陶喆 方大同 周杰伦 陈奕迅 王力宏 胡彦斌 丁世光 '
                '余佳运……那些耳熟能详的华语R&B经典歌曲，你都听过几首？欢迎推荐和补充！小百科：国内华语流行歌曲中的“节奏布鲁斯”风格发轫于上世纪八十年代，形成于九十年代，并在2000年以来不断发展，充分与华语流行音乐风格特点相结合，在港台流行音乐、内地流行音乐中掀起了一股经久不衰的R&B音乐风格潮流。可以说，节奏布鲁斯是当代我国流行音乐中的主流风格类型，早期在音乐作品中使用节奏布鲁斯的艺人包括有庾澄庆、林忆莲、王菲等歌手九十年代以来则以陶喆、王力宏、周杰伦等歌手为代表，进入新世纪后，华语流行歌曲的风格更加多元，除林俊杰、胡彦斌等歌手外，我们还能从大部分华语流行歌手的音乐作品中寻找到明显的"节奏布鲁斯"音乐风格.来源网络，仅供参考.【尊重原创，歌单勿盗】',
 'play': '1049668',
 'songs': '94',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
2024-11-11 17:16:24 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '17',
 'description': '介绍：经典值得反复聆听，国内比较具有代表性的R&B歌手经典歌曲收录：陶喆 方大同 周杰伦 陈奕迅 王力宏 胡彦斌 丁世光 '
                '余佳运……那些耳熟能详的华语R&B经典歌曲，你都听过几首？欢迎推荐和补充！小百科：国内华语流行歌曲中的“节奏布鲁斯”风格发轫于上世纪八十年代，形成于九十年代，并在2000年以来不断发展，充分与华语流行音乐风格特点相结合，在港台流行音乐、内地流行音乐中掀起了一股经久不衰的R&B音乐风格潮流。可以说，节奏布鲁斯是当代我国流行音乐中的主流风格类型，早期在音乐作品中使用节奏布鲁斯的艺人包括有庾澄庆、林忆莲、王菲等歌手九十年代以来则以陶喆、王力宏、周杰伦等歌手为代表，进入新世纪后，华语流行歌曲的风格更加多元，除林俊杰、胡彦斌等歌手外，我们还能从大部分华语流行歌手的音乐作品中寻找到明显的"节奏布鲁斯"音乐风格.来源网络，仅供参考.【尊重原创，歌单勿盗】',
 'play': '1049668',
 'songs': '94',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:16:24 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：洗澡的时候不唱歌，怎么可能洗的下去?不信？请你点击随机播放，打开热水开关，记得洗完回来告诉我你唱没唱出来！网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.9.12歌單完善: 2024.9.17歌單製作: 莣情歌單封面: 来源于网络侵删',
 'play': '41343',
 'songs': '44',
 'tag': '华语-流行-放松',
 'title': '无标题'}
2024-11-11 17:16:54 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：洗澡的时候不唱歌，怎么可能洗的下去?不信？请你点击随机播放，打开热水开关，记得洗完回来告诉我你唱没唱出来！网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.9.12歌單完善: 2024.9.17歌單製作: 莣情歌單封面: 来源于网络侵删',
 'play': '41343',
 'songs': '44',
 'tag': '华语-流行-放松',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:16:55 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '4',
 'description': '介绍：神仙女嗓，一开嗓就沦陷，单依纯张碧晨刘惜君郁可唯张靓颖，每一位都是神仙级别的女嗓，你最爱哪位，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '402329',
 'songs': '123',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:17:25 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '4',
 'description': '介绍：神仙女嗓，一开嗓就沦陷，单依纯张碧晨刘惜君郁可唯张靓颖，每一位都是神仙级别的女嗓，你最爱哪位，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '402329',
 'songs': '123',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:17:25 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '17',
 'description': '介绍：人会因为嘴硬失去很多东西 也会因为心软承受很多委屈一个人也能走很远的路 走远了就不需要什么虚伪的陪伴了',
 'play': '51490',
 'songs': '59',
 'tag': '华语-流行-伤感',
 'title': '无标题'}
2024-11-11 17:17:55 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '17',
 'description': '介绍：人会因为嘴硬失去很多东西 也会因为心软承受很多委屈一个人也能走很远的路 走远了就不需要什么虚伪的陪伴了',
 'play': '51490',
 'songs': '59',
 'tag': '华语-流行-伤感',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:17:55 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：青春是一本打开就再也合不上的书，我们含着泪一读在读。也曾有过这样的比喻，人一离开，就像合上了的书。那些过去的欢乐和曾经的苦痛，就好比鲜活得花瓣夹在书页里，再翻开的时候都成了干枯的回忆。但幸好有音乐的陪伴，让我们再一次乘坐青春的末班车。细品那些年藏在MP3里的歌曲，回味校园经历过各种的酸甜苦辣。网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.9.13歌單完善: 2024.9.18歌單製作: 莣情歌單封面: 来源于网络侵删',
 'play': '662',
 'songs': '85',
 'tag': '华语-校园-90后',
 'title': '无标题'}
2024-11-11 17:18:26 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：青春是一本打开就再也合不上的书，我们含着泪一读在读。也曾有过这样的比喻，人一离开，就像合上了的书。那些过去的欢乐和曾经的苦痛，就好比鲜活得花瓣夹在书页里，再翻开的时候都成了干枯的回忆。但幸好有音乐的陪伴，让我们再一次乘坐青春的末班车。细品那些年藏在MP3里的歌曲，回味校园经历过各种的酸甜苦辣。网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.9.13歌單完善: 2024.9.18歌單製作: 莣情歌單封面: 来源于网络侵删',
 'play': '662',
 'songs': '85',
 'tag': '华语-校园-90后',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:18:26 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '21',
 'description': '介绍：“质疑声可能会影响我的心情 但从不会影响我前进的步伐.”',
 'play': '329316',
 'songs': '110',
 'tag': '流行-网络歌曲-华语',
 'title': '无标题'}
2024-11-11 17:18:56 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '21',
 'description': '介绍：“质疑声可能会影响我的心情 但从不会影响我前进的步伐.”',
 'play': '329316',
 'songs': '110',
 'tag': '流行-网络歌曲-华语',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:18:56 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-11 17:18:56 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：在这个秋天，让我们搭乘华语流行男声的音乐便车，进入秋天的温暖与深情。从深情款款的抒情歌到充满活力的流行乐，这些旋律将伴随你走过秋日的每一个美好时刻。 '
                '以上歌曲源于合伙人高分曲库。 /封面图源网络',
 'play': '3346',
 'songs': '60',
 'tag': '华语-流行',
 'title': '无标题'}
2024-11-11 17:19:27 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：在这个秋天，让我们搭乘华语流行男声的音乐便车，进入秋天的温暖与深情。从深情款款的抒情歌到充满活力的流行乐，这些旋律将伴随你走过秋日的每一个美好时刻。 '
                '以上歌曲源于合伙人高分曲库。 /封面图源网络',
 'play': '3346',
 'songs': '60',
 'tag': '华语-流行',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:19:27 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：陈绮贞在演唱会上对歌迷说:你们真是疯狂又浪漫又不切实际，或许会有人说你们纤细敏感又想太多。但是这个世界上有一个人，写着一首又一首歌，就是想要保护你们的纤细敏感，浪漫与疯狂。',
 'play': '137',
 'songs': '40',
 'tag': '华语-流行-散步',
 'title': '无标题'}
2024-11-11 17:19:57 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：陈绮贞在演唱会上对歌迷说:你们真是疯狂又浪漫又不切实际，或许会有人说你们纤细敏感又想太多。但是这个世界上有一个人，写着一首又一首歌，就是想要保护你们的纤细敏感，浪漫与疯狂。',
 'play': '137',
 'songs': '40',
 'tag': '华语-流行-散步',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:19:57 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：这些歌说起来不得不提方能充电器 闪光那种但凡有一首没听过的 '
                '自己都觉得不是90真的不想相信也不敢相信这些曾经耳熟能详朗朗上口的歌都是已经小20年或20多年前的歌了那时的一切都是满满的爱情，可现在嘛……初听是高三 '
                '再听是三高歌老了 哥也老了 歌是当年的歌哥已不是当年的哥 但哥还喜欢当年的歌幸好 我完美的通关了 全都会唱几句 '
                '熟悉的几句整理：陈穆泽封面：源自网络图片',
 'play': '1065',
 'songs': '50',
 'tag': '华语-怀旧-经典',
 'title': '无标题'}
2024-11-11 17:20:28 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：这些歌说起来不得不提方能充电器 闪光那种但凡有一首没听过的 '
                '自己都觉得不是90真的不想相信也不敢相信这些曾经耳熟能详朗朗上口的歌都是已经小20年或20多年前的歌了那时的一切都是满满的爱情，可现在嘛……初听是高三 '
                '再听是三高歌老了 哥也老了 歌是当年的歌哥已不是当年的哥 但哥还喜欢当年的歌幸好 我完美的通关了 全都会唱几句 '
                '熟悉的几句整理：陈穆泽封面：源自网络图片',
 'play': '1065',
 'songs': '50',
 'tag': '华语-怀旧-经典',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:20:28 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '16',
 'description': '介绍：生活总是两难，再多执着，再多不肯，最终不得不学会接受。从哭着控制，到笑着对待，到头来，不过是一场随遇而安。别想太多，一切都会过去的',
 'play': '50822',
 'songs': '34',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:20:58 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '16',
 'description': '介绍：生活总是两难，再多执着，再多不肯，最终不得不学会接受。从哭着控制，到笑着对待，到头来，不过是一场随遇而安。别想太多，一切都会过去的',
 'play': '50822',
 'songs': '34',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:20:58 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：积蓄力量 继续前进 '
                '一切美好如约而至心若向阳，无惧风雨心中有阳光，便无惧风雨。面对生活中的挑战与困境，我们保持乐观，坚信希望之光总在前方。心若向阳，无惧风雨，砥砺前行的脚步，书写不凡的人生。',
 'play': '166',
 'songs': '39',
 'tag': '华语-流行-清新',
 'title': '无标题'}
2024-11-11 17:21:29 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：积蓄力量 继续前进 '
                '一切美好如约而至心若向阳，无惧风雨心中有阳光，便无惧风雨。面对生活中的挑战与困境，我们保持乐观，坚信希望之光总在前方。心若向阳，无惧风雨，砥砺前行的脚步，书写不凡的人生。',
 'play': '166',
 'songs': '39',
 'tag': '华语-流行-清新',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:21:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：你:你什么血型？我:R&B '
                '稀有血型！R&B歌曲节奏动感，旋律优美且富有转音，和声丰富，演唱慵懒随性。情感细腻，充满感染力，让人沉浸其中。',
 'play': '422',
 'songs': '31',
 'tag': '华语-欧美-R&B/Soul',
 'title': '无标题'}
2024-11-11 17:21:59 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：你:你什么血型？我:R&B '
                '稀有血型！R&B歌曲节奏动感，旋律优美且富有转音，和声丰富，演唱慵懒随性。情感细腻，充满感染力，让人沉浸其中。',
 'play': '422',
 'songs': '31',
 'tag': '华语-欧美-R&B/Soul',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:21:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：在这个歌单里的旋律宛如细雨，轻柔落在听者心头。经典的华语老歌诉说着温柔与伤感的故事，带你在80至00年代的回忆中慢慢漂流，让你感受到熟悉的孤单与温暖。',
 'play': '3140',
 'songs': '80',
 'tag': '流行-华语',
 'title': '无标题'}
2024-11-11 17:22:29 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：在这个歌单里的旋律宛如细雨，轻柔落在听者心头。经典的华语老歌诉说着温柔与伤感的故事，带你在80至00年代的回忆中慢慢漂流，让你感受到熟悉的孤单与温暖。',
 'play': '3140',
 'songs': '80',
 'tag': '流行-华语',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:22:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '13',
 'description': '介绍：你是我梦中的星辰大海，是我心中永恒的浪漫彼岸。',
 'play': '116456',
 'songs': '56',
 'tag': '华语-流行-浪漫',
 'title': '无标题'}
2024-11-11 17:23:00 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '13',
 'description': '介绍：你是我梦中的星辰大海，是我心中永恒的浪漫彼岸。',
 'play': '116456',
 'songs': '56',
 'tag': '华语-流行-浪漫',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:23:00 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:23:00 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:24:26 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-11 17:24:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6849437846> (referer: None)
2024-11-11 17:24:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=10028686145> (referer: None)
2024-11-11 17:24:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6731094367> (referer: None)
2024-11-11 17:24:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=10089912508> (referer: None)
2024-11-11 17:24:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=10009812616> (referer: None)
2024-11-11 17:24:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12466491231> (referer: None)
2024-11-11 17:24:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9471373420> (referer: None)
2024-11-11 17:24:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9946817162> (referer: None)
2024-11-11 17:24:26 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1664',
 'description': '介绍：摩登天空是目前中国最大规模的新音乐独立唱片公司，旗下音乐人在中国独立音乐发展路途中有着无法被忽视的作用。',
 'play': '3990395',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:24:56 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '1664',
 'description': '介绍：摩登天空是目前中国最大规模的新音乐独立唱片公司，旗下音乐人在中国独立音乐发展路途中有着无法被忽视的作用。',
 'play': '3990395',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12676719495> (referer: None)
2024-11-11 17:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12656674237> (referer: None)
2024-11-11 17:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12672478257> (referer: None)
2024-11-11 17:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12718517117> (referer: None)
2024-11-11 17:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12592186263> (referer: None)
2024-11-11 17:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12468131100> (referer: None)
2024-11-11 17:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12639940815> (referer: None)
2024-11-11 17:24:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12696107660> (referer: None)
2024-11-11 17:24:56 [scrapy.extensions.logstats] INFO: Crawled 49 pages (at 16 pages/min), scraped 0 items (at 0 items/min)
2024-11-11 17:24:57 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '11',
 'description': '介绍：十个勤天，做大做强！（有版权的都放进歌单啦）十个勤天只能是十个勤天！十个勤天！缺一不可！',
 'play': '222174',
 'songs': '69',
 'tag': '华语-旅行-运动',
 'title': '无标题'}
2024-11-11 17:25:27 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '11',
 'description': '介绍：十个勤天，做大做强！（有版权的都放进歌单啦）十个勤天只能是十个勤天！十个勤天！缺一不可！',
 'play': '222174',
 'songs': '69',
 'tag': '华语-旅行-运动',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:25:27 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '87',
 'description': '介绍：综艺《谁是宝藏歌手》音频全收录 '
                '（更新中）。谁是宝藏歌手，即使无人知晓！这一次，只用歌声证明自己。实力歌手隐藏在符号之后，用作品赢得推荐人的认可。谁将获得公演舞台的位置，收获观众的掌声与呐喊？',
 'play': '1441781',
 'songs': '94',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:25:57 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '87',
 'description': '介绍：综艺《谁是宝藏歌手》音频全收录 '
                '（更新中）。谁是宝藏歌手，即使无人知晓！这一次，只用歌声证明自己。实力歌手隐藏在符号之后，用作品赢得推荐人的认可。谁将获得公演舞台的位置，收获观众的掌声与呐喊？',
 'play': '1441781',
 'songs': '94',
 'tag': '无',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:25:57 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '4',
 'description': '介绍：张碧晨杨宗纬汪苏泷单依纯等，神仙歌手，一开嗓就让人沦陷的神级现场，你最爱哪位歌手的作品，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '206781',
 'songs': '101',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:26:28 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '4',
 'description': '介绍：张碧晨杨宗纬汪苏泷单依纯等，神仙歌手，一开嗓就让人沦陷的神级现场，你最爱哪位歌手的作品，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '206781',
 'songs': '101',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:26:28 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '11',
 'description': '介绍：华语天使女嗓，绝了，她们真的太会唱了，单依纯张碧晨姚晓棠郁可唯等，总有一首能打动你，欢迎收藏，感谢聆听',
 'play': '230612',
 'songs': '77',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:26:58 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '11',
 'description': '介绍：华语天使女嗓，绝了，她们真的太会唱了，单依纯张碧晨姚晓棠郁可唯等，总有一首能打动你，欢迎收藏，感谢聆听',
 'play': '230612',
 'songs': '77',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:26:58 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：毛不易 周深 张碧晨 薛之谦 '
                '单依纯，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '9158',
 'songs': '98',
 'tag': '华语-流行-感动',
 'title': '无标题'}
2024-11-11 17:27:28 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：毛不易 周深 张碧晨 薛之谦 '
                '单依纯，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '9158',
 'songs': '98',
 'tag': '华语-流行-感动',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:27:28 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '10',
 'description': '介绍：工作太无聊，不如休息一下听会儿歌，放松一下心情，在迎接新的挑战吧。办公室或者在家办公，都需要来点音乐放松心情',
 'play': '558321',
 'songs': '115',
 'tag': '华语-工作-网络歌曲',
 'title': '无标题'}
2024-11-11 17:27:59 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '10',
 'description': '介绍：工作太无聊，不如休息一下听会儿歌，放松一下心情，在迎接新的挑战吧。办公室或者在家办公，都需要来点音乐放松心情',
 'play': '558321',
 'songs': '115',
 'tag': '华语-工作-网络歌曲',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:27:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '21',
 'description': '介绍：天赐的声音第五季回归，神曲现场，一曲惊艳全场，精选历届最值得听的top50歌曲，欢迎收藏，感谢聆听',
 'play': '1109459',
 'songs': '107',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:28:29 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '21',
 'description': '介绍：天赐的声音第五季回归，神曲现场，一曲惊艳全场，精选历届最值得听的top50歌曲，欢迎收藏，感谢聆听',
 'play': '1109459',
 'songs': '107',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:28:29 [scrapy.extensions.logstats] INFO: Crawled 49 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2024-11-11 17:28:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：小时候听的歌好多都是电视剧里的小时候就知道周杰伦 '
                '许嵩～那时候年轻，抄写歌词，还有专门的歌词本努力攒压岁钱就为了买一个MP3专门找朋友帮忙下载很多歌记得第一次去网吧就是为了去下歌～说起来都是满满的回忆～满满的青春～',
 'play': '35098',
 'songs': '217',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
2024-11-11 17:28:59 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：小时候听的歌好多都是电视剧里的小时候就知道周杰伦 '
                '许嵩～那时候年轻，抄写歌词，还有专门的歌词本努力攒压岁钱就为了买一个MP3专门找朋友帮忙下载很多歌记得第一次去网吧就是为了去下歌～说起来都是满满的回忆～满满的青春～',
 'play': '35098',
 'songs': '217',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:29:00 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：“如果大海能够换回曾经的爱，就让我用一生等待，如果深情往事你已不再留恋，就让他随风飘远“张雨生的《大海》是我拥有过的第一张磁带听的第一首歌，在那个还是录音机的90年代，首歌都能听上好久，从此也在心里生了根。选了一些90年代的歌曲，满满都是回忆，有你的记忆吗?',
 'play': '25757',
 'songs': '129',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:29:30 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：“如果大海能够换回曾经的爱，就让我用一生等待，如果深情往事你已不再留恋，就让他随风飘远“张雨生的《大海》是我拥有过的第一张磁带听的第一首歌，在那个还是录音机的90年代，首歌都能听上好久，从此也在心里生了根。选了一些90年代的歌曲，满满都是回忆，有你的记忆吗?',
 'play': '25757',
 'songs': '129',
 'tag': '华语-流行-90后',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:29:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：神仙音综：声生不息×天赐的声音，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '3010',
 'songs': '40',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:30:00 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：神仙音综：声生不息×天赐的声音，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '3010',
 'songs': '40',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:30:00 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：营销号来活儿了，你一句我一句，助力曹雪芹复出人往往不会记得跋山涉水来见自己的人，他只会记得自己小心翼翼攒钱跨越万水千山只为一面的人',
 'play': '7394',
 'songs': '72',
 'tag': '华语-流行-快乐',
 'title': '无标题'}
2024-11-11 17:30:30 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：营销号来活儿了，你一句我一句，助力曹雪芹复出人往往不会记得跋山涉水来见自己的人，他只会记得自己小心翼翼攒钱跨越万水千山只为一面的人',
 'play': '7394',
 'songs': '72',
 'tag': '华语-流行-快乐',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:30:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：有一种爱，无需繁华的修饰，只需你我心心相印。让我们的浪漫在月光下绽放，永不停歇。',
 'play': '9457',
 'songs': '58',
 'tag': '华语-驾车-放松',
 'title': '无标题'}
2024-11-11 17:31:01 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：有一种爱，无需繁华的修饰，只需你我心心相印。让我们的浪漫在月光下绽放，永不停歇。',
 'play': '9457',
 'songs': '58',
 'tag': '华语-驾车-放松',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:31:01 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：每一个年代都有经典老歌它们承载着无数人的青葱岁月，随着时间的流逝，熟悉的旋律会和时光一起，被深藏在记忆的某个角落，当难忘旋律再次缓缓响起，恍如青风迎面吹来...',
 'play': '83104',
 'songs': '115',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:31:31 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：每一个年代都有经典老歌它们承载着无数人的青葱岁月，随着时间的流逝，熟悉的旋律会和时光一起，被深藏在记忆的某个角落，当难忘旋律再次缓缓响起，恍如青风迎面吹来...',
 'play': '83104',
 'songs': '115',
 'tag': '华语-流行-90后',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:31:31 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：年少多好啊明目张胆的偏爱浇灭不了的壮志不可遮掩的意气可如今我们坐在一起不敢轻易说出心底话',
 'play': '2905',
 'songs': '170',
 'tag': 'KTV-华语-伤感',
 'title': '无标题'}
2024-11-11 17:32:01 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：年少多好啊明目张胆的偏爱浇灭不了的壮志不可遮掩的意气可如今我们坐在一起不敢轻易说出心底话',
 'play': '2905',
 'songs': '170',
 'tag': 'KTV-华语-伤感',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:32:02 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：每次听李宗盛都想来根老烟始终印象很深刻梁静茹有一次开演唱会请李宗盛来当嘉宾他们合唱了《明明白白我的心》期间李宗盛对梁静茹说："曾经的小姑娘长大了，听得懂老豆的歌了""但希望你不要像老豆经历的那么多"然而人生的路终究还是要自己经历在所难免在一些特定的时刻不得已听懂了李宗盛的歌并且这种懂不是强烈的被冲击而是一种从泥泞里爬出来之后发现人只能自渡的那种孤世感有句话说的好啊"智者不入爱河"因为"情爱里无智者',
 'play': '1136',
 'songs': '221',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
2024-11-11 17:32:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12696107660>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：每次听李宗盛都想来根老烟始终印象很深刻梁静茹有一次开演唱会请李宗盛来当嘉宾他们合唱了《明明白白我的心》期间李宗盛对梁静茹说："曾经的小姑娘长大了，听得懂老豆的歌了""但希望你不要像老豆经历的那么多"然而人生的路终究还是要自己经历在所难免在一些特定的时刻不得已听懂了李宗盛的歌并且这种懂不是强烈的被冲击而是一种从泥泞里爬出来之后发现人只能自渡的那种孤世感有句话说的好啊"智者不入爱河"因为"情爱里无智者',
 'play': '1136',
 'songs': '221',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
2024-11-11 17:32:17 [scrapy.extensions.logstats] INFO: Crawled 49 pages (at 0 pages/min), scraped 1 items (at 1 items/min)
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:32:17 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:33:39 [scrapy.extensions.logstats] INFO: Crawled 49 pages (at 0 pages/min), scraped 1 items (at 0 items/min)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8481131201> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6957303377> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7562480734> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6969447123> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8451919201> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7572863604> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7388898544> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7534118001> (referer: None)
2024-11-11 17:33:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1',
 'description': '介绍：环球音乐集团是一家全世界最大的音乐公司 在60多个国家和地区开展音乐制作发行 版权管理 '
                '授权商品销售和视听内容等全方位业务',
 'play': '56785',
 'songs': '120',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8481131201>
{'collection': '播放',
 'comments': '1',
 'description': '介绍：环球音乐集团是一家全世界最大的音乐公司 在60多个国家和地区开展音乐制作发行 版权管理 '
                '授权商品销售和视听内容等全方位业务',
 'play': '56785',
 'songs': '120',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '7',
 'description': '介绍：1995年经典歌曲精选',
 'play': '303326',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6957303377>
{'collection': '播放',
 'comments': '7',
 'description': '介绍：1995年经典歌曲精选',
 'play': '303326',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '3',
 'description': '介绍：戴佩妮的唱片从来不缺态度，这次带来新专辑《被动的观众》引人联想的唱片名，是一张思想与情绪主导的唱片。戴佩妮依然包办词曲全创作，这也保证了这张唱片完整反映歌手身为创作者的所思所想所感。',
 'play': '128833',
 'songs': '41',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7562480734>
{'collection': '播放',
 'comments': '3',
 'description': '介绍：戴佩妮的唱片从来不缺态度，这次带来新专辑《被动的观众》引人联想的唱片名，是一张思想与情绪主导的唱片。戴佩妮依然包办词曲全创作，这也保证了这张唱片完整反映歌手身为创作者的所思所想所感。',
 'play': '128833',
 'songs': '41',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '8',
 'description': '介绍：月亮和音乐代表我的心。',
 'play': '227122',
 'songs': '35',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6969447123>
{'collection': '播放',
 'comments': '8',
 'description': '介绍：月亮和音乐代表我的心。',
 'play': '227122',
 'songs': '35',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '4',
 'description': '介绍：夏季总是浪漫而热烈 乐队总是放肆又张扬 这些点滴都记录着青春',
 'play': '576394',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8451919201>
{'collection': '播放',
 'comments': '4',
 'description': '介绍：夏季总是浪漫而热烈 乐队总是放肆又张扬 这些点滴都记录着青春',
 'play': '576394',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '20',
 'description': '介绍：《2022中国好声音》是由浙江卫视和灿星制作联手打造的大型励志专业音乐评论类节目。作为国内首屈一指的音乐综艺IP，好声音一直是对年轻人最有号召力的王牌综艺',
 'play': '494716',
 'songs': '99',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7572863604>
{'collection': '播放',
 'comments': '20',
 'description': '介绍：《2022中国好声音》是由浙江卫视和灿星制作联手打造的大型励志专业音乐评论类节目。作为国内首屈一指的音乐综艺IP，好声音一直是对年轻人最有号召力的王牌综艺',
 'play': '494716',
 'songs': '99',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8865057200> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=10101614852> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8484246201> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12641825441> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=10024899665> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12694396558> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9846115204> (referer: None)
2024-11-11 17:33:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12691103302> (referer: None)
2024-11-11 17:33:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '70',
 'description': '介绍：湖南卫视大型民歌竞唱节目《春天花会开》3月11日起每周五20:10播出。节目中年轻的歌者，以多元的音乐样貌，新唱、新编、新创民族音乐。',
 'play': '100605',
 'songs': '49',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7388898544>
{'collection': '播放',
 'comments': '70',
 'description': '介绍：湖南卫视大型民歌竞唱节目《春天花会开》3月11日起每周五20:10播出。节目中年轻的歌者，以多元的音乐样貌，新唱、新编、新创民族音乐。',
 'play': '100605',
 'songs': '49',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '12',
 'description': '介绍：刘若英，中国台湾流行乐女歌手、影视演员、导演、词曲创作者。她的音乐，则以诚挚朴实见长，她会用情感歌唱，能轻易感染听众。她的歌声中有一种表达的冲动，将真挚的、有感而发的东西通过歌声去坦白表露。',
 'play': '610426',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7534118001>
{'collection': '播放',
 'comments': '12',
 'description': '介绍：刘若英，中国台湾流行乐女歌手、影视演员、导演、词曲创作者。她的音乐，则以诚挚朴实见长，她会用情感歌唱，能轻易感染听众。她的歌声中有一种表达的冲动，将真挚的、有感而发的东西通过歌声去坦白表露。',
 'play': '610426',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '3',
 'description': '介绍：一个个躁动的音符就是助跑时的兴奋剂 让人越跑越有激情 根本停不下来',
 'play': '499756',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8865057200>
{'collection': '播放',
 'comments': '3',
 'description': '介绍：一个个躁动的音符就是助跑时的兴奋剂 让人越跑越有激情 根本停不下来',
 'play': '499756',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：睡不着R&B就是安眠曲，像一个雨夜，打开音响，让思绪充斥整个房间，时间暂停，在音乐里徘徊游荡。',
 'play': '141110',
 'songs': '244',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
2024-11-11 17:33:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=10101614852>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：睡不着R&B就是安眠曲，像一个雨夜，打开音响，让思绪充斥整个房间，时间暂停，在音乐里徘徊游荡。',
 'play': '141110',
 'songs': '244',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
2024-11-11 17:33:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2',
 'description': '介绍：听见滚石时光经典。',
 'play': '70823',
 'songs': '80',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8484246201>
{'collection': '播放',
 'comments': '2',
 'description': '介绍：听见滚石时光经典。',
 'play': '70823',
 'songs': '80',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:33:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：久听不讨厌，你爱的歌 '
                '，值得反复聆听，热门情歌，收藏你的最爱歌，经典新老歌曲，每一首歌有你的故事，希望你们，收藏起来!歌单制作；新疆RaZeL哥封面来源；网络歌单更新；每日更新请注意; '
                '歌单不要模仿\u200b勿侵；欢迎收藏，关注 ！',
 'play': '12968',
 'songs': '207',
 'tag': '华语-流行-浪漫',
 'title': '无标题'}
2024-11-11 17:33:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12641825441>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：久听不讨厌，你爱的歌 '
                '，值得反复聆听，热门情歌，收藏你的最爱歌，经典新老歌曲，每一首歌有你的故事，希望你们，收藏起来!歌单制作；新疆RaZeL哥封面来源；网络歌单更新；每日更新请注意; '
                '歌单不要模仿\u200b勿侵；欢迎收藏，关注 ！',
 'play': '12968',
 'songs': '207',
 'tag': '华语-流行-浪漫',
 'title': '无标题'}
2024-11-11 17:33:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '5',
 'description': '介绍：天赐的声音，汪苏泷&张碧晨&陈楚生&姚晓棠等歌手的代表作品，每一首都是顶级实力派歌手的用心演绎，欢迎收藏，感谢聆听',
 'play': '664539',
 'songs': '93',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:33:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=10024899665>
{'collection': '播放',
 'comments': '5',
 'description': '介绍：天赐的声音，汪苏泷&张碧晨&陈楚生&姚晓棠等歌手的代表作品，每一首都是顶级实力派歌手的用心演绎，欢迎收藏，感谢聆听',
 'play': '664539',
 'songs': '93',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:33:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2',
 'description': '介绍：“如果大海能够换回曾经的爱，就让我用一生等待，如果深情往事你已不再留恋，就让他随风飘远“张雨生的《大海》是我拥有过的第一张磁带听的第一首歌，在那个还是录音机的90年代，首歌都能听上好久，从此也在心里生了根。选了一些90年代的歌曲，满满都是回忆，有你的记忆吗?',
 'play': '26404',
 'songs': '106',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:33:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12694396558>
{'collection': '播放',
 'comments': '2',
 'description': '介绍：“如果大海能够换回曾经的爱，就让我用一生等待，如果深情往事你已不再留恋，就让他随风飘远“张雨生的《大海》是我拥有过的第一张磁带听的第一首歌，在那个还是录音机的90年代，首歌都能听上好久，从此也在心里生了根。选了一些90年代的歌曲，满满都是回忆，有你的记忆吗?',
 'play': '26404',
 'songs': '106',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:33:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '159',
 'description': '介绍：落魄谷中寒风吹，春秋蝉鸣少年归。荡魂山处石人泪，定仙游走魔向北。逆流河上万仙退，爱情不敌坚持泪。宿命天成命中败。仙尊悔而我不悔。早岁已知世事艰，仍许飞鸿荡云间。一路寒风身如絮，命海沉浮客独行。千磨万击心铸铁，殚精竭虑铸一剑。今朝剑指叠云处，炼蛊炼人还炼天。千古帝仙随风逝，昔日三王归青冢。羊莽汉云谁吾拜，卷土重来再称王。天河一挂钓龙鱼，逆天独行顾八荒。今日暂且展翼去，明朝登仙吃凤凰。',
 'play': '1553398',
 'songs': '116',
 'tag': '华语-古风-伤感',
 'title': '无标题'}
2024-11-11 17:33:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9846115204>
{'collection': '播放',
 'comments': '159',
 'description': '介绍：落魄谷中寒风吹，春秋蝉鸣少年归。荡魂山处石人泪，定仙游走魔向北。逆流河上万仙退，爱情不敌坚持泪。宿命天成命中败。仙尊悔而我不悔。早岁已知世事艰，仍许飞鸿荡云间。一路寒风身如絮，命海沉浮客独行。千磨万击心铸铁，殚精竭虑铸一剑。今朝剑指叠云处，炼蛊炼人还炼天。千古帝仙随风逝，昔日三王归青冢。羊莽汉云谁吾拜，卷土重来再称王。天河一挂钓龙鱼，逆天独行顾八荒。今日暂且展翼去，明朝登仙吃凤凰。',
 'play': '1553398',
 'songs': '116',
 'tag': '华语-古风-伤感',
 'title': '无标题'}
2024-11-11 17:33:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：回忆90后的儿时时光，陪着爸妈一起走过的光辉岁月，时间在父母脸上留下的痕迹，一道道年轮，还记得那会年轻的他们也那么的漂亮那么帅气！经久不衰的还是经典，岁月再快，心依旧不老!网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.10.6歌單完善: 2024.10.11歌單製作: 莣情歌單封面: 邓丽君',
 'play': '4551',
 'songs': '139',
 'tag': '华语-经典-70后',
 'title': '无标题'}
2024-11-11 17:33:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12691103302>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：回忆90后的儿时时光，陪着爸妈一起走过的光辉岁月，时间在父母脸上留下的痕迹，一道道年轮，还记得那会年轻的他们也那么的漂亮那么帅气！经久不衰的还是经典，岁月再快，心依旧不老!网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.10.6歌單完善: 2024.10.11歌單製作: 莣情歌單封面: 邓丽君',
 'play': '4551',
 'songs': '139',
 'tag': '华语-经典-70后',
 'title': '无标题'}
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:33:41 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:35:01 [scrapy.extensions.logstats] INFO: Crawled 65 pages (at 16 pages/min), scraped 17 items (at 16 items/min)
2024-11-11 17:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6957296439> (referer: None)
2024-11-11 17:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6847249919> (referer: None)
2024-11-11 17:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7793230288> (referer: None)
2024-11-11 17:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8006931752> (referer: None)
2024-11-11 17:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7561460225> (referer: None)
2024-11-11 17:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7706461556> (referer: None)
2024-11-11 17:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8293309078> (referer: None)
2024-11-11 17:35:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7752312415> (referer: None)
2024-11-11 17:35:01 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '6',
 'description': '介绍：1999年经典歌曲精选',
 'play': '604408',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6957296439>
{'collection': '播放',
 'comments': '6',
 'description': '介绍：1999年经典歌曲精选',
 'play': '604408',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:01 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '3',
 'description': '介绍：炫目的灯光、 强烈的节奏、 喧闹的人群、 花哨的服装.... 风靡当年的劲歌热舞仍在 '
                '是时候再来回味一下往日的潇洒了！',
 'play': '139052',
 'songs': '95',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6847249919>
{'collection': '播放',
 'comments': '3',
 'description': '介绍：炫目的灯光、 强烈的节奏、 喧闹的人群、 花哨的服装.... 风靡当年的劲歌热舞仍在 '
                '是时候再来回味一下往日的潇洒了！',
 'play': '139052',
 'songs': '95',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:01 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '3879',
 'description': '介绍：张云雷，本名张磊， '
                '1992年1月11日出生于天津市，中国内地相声男演员、歌手，德云演出八队队长。2019年1月发布首支单曲《毓贞》，正式跨界成为歌手',
 'play': '195806',
 'songs': '12',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7793230288>
{'collection': '播放',
 'comments': '3879',
 'description': '介绍：张云雷，本名张磊， '
                '1992年1月11日出生于天津市，中国内地相声男演员、歌手，德云演出八队队长。2019年1月发布首支单曲《毓贞》，正式跨界成为歌手',
 'play': '195806',
 'songs': '12',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:01 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '46',
 'description': '介绍：摩登天空是目前中国最大规模的新音乐独立唱片公司，旗下艺人众多，痛仰、新裤子、二手玫瑰等许多我们熟知的乐队都是来自摩登天空。他们以摇滚与浪漫，电子与迷幻，将绮丽与悲伤的梦藏进live里。',
 'play': '660154',
 'songs': '53',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:01 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8006931752>
{'collection': '播放',
 'comments': '46',
 'description': '介绍：摩登天空是目前中国最大规模的新音乐独立唱片公司，旗下艺人众多，痛仰、新裤子、二手玫瑰等许多我们熟知的乐队都是来自摩登天空。他们以摇滚与浪漫，电子与迷幻，将绮丽与悲伤的梦藏进live里。',
 'play': '660154',
 'songs': '53',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:02 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '29',
 'description': '介绍：独自在深夜里踏上归程，凝视窗外，月明星稀，晚风微凉。即便再晚，也有音乐相伴，给夜归的你留一盏灯，晚安陌生人。',
 'play': '3793102',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7561460225>
{'collection': '播放',
 'comments': '29',
 'description': '介绍：独自在深夜里踏上归程，凝视窗外，月明星稀，晚风微凉。即便再晚，也有音乐相伴，给夜归的你留一盏灯，晚安陌生人。',
 'play': '3793102',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:02 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '16',
 'description': '介绍：对享受独处的人来说，即使是一人食也被赋予了仪式感，吃饭不仅仅只有果腹的意义，它还意味着在喧闹的世界中，挤出一个与自己寒暄的空间。',
 'play': '1568268',
 'songs': '59',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7706461556>
{'collection': '播放',
 'comments': '16',
 'description': '介绍：对享受独处的人来说，即使是一人食也被赋予了仪式感，吃饭不仅仅只有果腹的意义，它还意味着在喧闹的世界中，挤出一个与自己寒暄的空间。',
 'play': '1568268',
 'songs': '59',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:02 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '116',
 'description': '介绍：有些音乐适合用来疗伤止痛；有些音乐适合用来回忆；王菲的音乐适合用来彼此安慰。她用自己的寂寞吟唱的歌暗合了你的寂寞。她的歌声如同彼岸的花朵，盛开在不可触及的远方。让我们一起来听王菲的歌曲吧！',
 'play': '716678',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7752312415>
{'collection': '播放',
 'comments': '116',
 'description': '介绍：有些音乐适合用来疗伤止痛；有些音乐适合用来回忆；王菲的音乐适合用来彼此安慰。她用自己的寂寞吟唱的歌暗合了你的寂寞。她的歌声如同彼岸的花朵，盛开在不可触及的远方。让我们一起来听王菲的歌曲吧！',
 'play': '716678',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:02 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '7',
 'description': '介绍：吴青峰，台湾创作歌手、作词人、作曲人、编曲人，昵称青峰，生于台北市，是乐团鱼丁糸（同时也是苏打绿）创始团员及主唱，同时也是乐团内主要的词曲创作者。除了乐团专辑的制作，吴青峰也为众多华语歌手创作词曲。',
 'play': '92423',
 'songs': '51',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8293309078>
{'collection': '播放',
 'comments': '7',
 'description': '介绍：吴青峰，台湾创作歌手、作词人、作曲人、编曲人，昵称青峰，生于台北市，是乐团鱼丁糸（同时也是苏打绿）创始团员及主唱，同时也是乐团内主要的词曲创作者。除了乐团专辑的制作，吴青峰也为众多华语歌手创作词曲。',
 'play': '92423',
 'songs': '51',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8661641200> (referer: None)
2024-11-11 17:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12696801630> (referer: None)
2024-11-11 17:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8835218200> (referer: None)
2024-11-11 17:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12302787711> (referer: None)
2024-11-11 17:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12539210503> (referer: None)
2024-11-11 17:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12657163779> (referer: None)
2024-11-11 17:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12227034364> (referer: None)
2024-11-11 17:35:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8377438674> (referer: None)
2024-11-11 17:35:02 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '6',
 'description': '介绍：住进私人咖啡星球 享受惬意时光',
 'play': '83685',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8661641200>
{'collection': '播放',
 'comments': '6',
 'description': '介绍：住进私人咖啡星球 享受惬意时光',
 'play': '83685',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:02 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '3',
 'description': '介绍：当旋律想起，我相信你一定会会被吸引因为这次小编主打旋律控!特别为你精选压箱底优质出圈的好歌百分百能俘获你的听觉赚足你的欲求不满的耳朵！建议随机播放哦~每一首都是爆款收割机！网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.10.7歌單完善: 2024.10.12歌單製作: 莣情歌單封面: 来源于网络侵删',
 'play': '109547',
 'songs': '202',
 'tag': '华语-流行-榜单',
 'title': '无标题'}
2024-11-11 17:35:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12696801630>
{'collection': '播放',
 'comments': '3',
 'description': '介绍：当旋律想起，我相信你一定会会被吸引因为这次小编主打旋律控!特别为你精选压箱底优质出圈的好歌百分百能俘获你的听觉赚足你的欲求不满的耳朵！建议随机播放哦~每一首都是爆款收割机！网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.10.7歌單完善: 2024.10.12歌單製作: 莣情歌單封面: 来源于网络侵删',
 'play': '109547',
 'songs': '202',
 'tag': '华语-流行-榜单',
 'title': '无标题'}
2024-11-11 17:35:02 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '13',
 'description': '介绍：有音乐 在家也不无聊～',
 'play': '1229214',
 'songs': '70',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8835218200>
{'collection': '播放',
 'comments': '13',
 'description': '介绍：有音乐 在家也不无聊～',
 'play': '1229214',
 'songs': '70',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:02 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '10',
 'description': '介绍：《敏感战争》、《闪电》、《短路一刻火花四散》无版权。武汉站6.23《黑眼圈》、《雨天》，成都站7.6《银河》、《小段》，7.7《苏璞》、《关于你》，南京站7.20《雨天雨天》替换《指纹》、《某人》替换《海绵宝宝》、大转盘《第十二夜》、《那个男孩》，7.21《种子》、《古怪》，郑州站8.17《放·逐》替换《我想念》、大转盘《还是想念》、《雾都孤儿》，8.18《恋爱动物》、《伊甸园》、《晴》，合肥站8.31《命运》替换《酒醉的蝴蝶》、大转盘《等不到你》、《眼泪落下之前》9.1《祝我快乐》、《吵架歌》，苏州站9.17（生日场）（歌单顺序大调整）《让我们乐在一起》、《慢慢懂》、大转盘《唯你懂我心》、《普通爱情故事》、《站台》，天津站9.27新增《全城热恋》、大转盘《末班飞行》、《茉莉》、《风度》，9.28《每月5号》替换《侏罗纪》、大转盘《致曾来过的你》（无版权）、《那一年》、《岛》，杭州站10.12《还是想念》、《但是我爱你》，10.13《专属味道》、《坠入》、《小段》，上海站10.25《桃花扇》、《随便》，10.26《因为了解》、《你让我懂》，10.27《第一首情歌》、《幸福是被你需要》、《他的爱》，深圳站11.1《那个男孩》、《站台》，11.2《那一年》、《随便》。持续更新ing……',
 'play': '48718',
 'songs': '87',
 'tag': '华语-流行',
 'title': '无标题'}
2024-11-11 17:35:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12302787711>
{'collection': '播放',
 'comments': '10',
 'description': '介绍：《敏感战争》、《闪电》、《短路一刻火花四散》无版权。武汉站6.23《黑眼圈》、《雨天》，成都站7.6《银河》、《小段》，7.7《苏璞》、《关于你》，南京站7.20《雨天雨天》替换《指纹》、《某人》替换《海绵宝宝》、大转盘《第十二夜》、《那个男孩》，7.21《种子》、《古怪》，郑州站8.17《放·逐》替换《我想念》、大转盘《还是想念》、《雾都孤儿》，8.18《恋爱动物》、《伊甸园》、《晴》，合肥站8.31《命运》替换《酒醉的蝴蝶》、大转盘《等不到你》、《眼泪落下之前》9.1《祝我快乐》、《吵架歌》，苏州站9.17（生日场）（歌单顺序大调整）《让我们乐在一起》、《慢慢懂》、大转盘《唯你懂我心》、《普通爱情故事》、《站台》，天津站9.27新增《全城热恋》、大转盘《末班飞行》、《茉莉》、《风度》，9.28《每月5号》替换《侏罗纪》、大转盘《致曾来过的你》（无版权）、《那一年》、《岛》，杭州站10.12《还是想念》、《但是我爱你》，10.13《专属味道》、《坠入》、《小段》，上海站10.25《桃花扇》、《随便》，10.26《因为了解》、《你让我懂》，10.27《第一首情歌》、《幸福是被你需要》、《他的爱》，深圳站11.1《那个男孩》、《站台》，11.2《那一年》、《随便》。持续更新ing……',
 'play': '48718',
 'songs': '87',
 'tag': '华语-流行',
 'title': '无标题'}
2024-11-11 17:35:02 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '4',
 'description': '介绍：天赐的声音live：历届金曲精选集！每一首都是顶级歌手的用心演绎，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '366965',
 'songs': '94',
 'tag': '华语-综艺-驾车',
 'title': '无标题'}
2024-11-11 17:35:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12539210503>
{'collection': '播放',
 'comments': '4',
 'description': '介绍：天赐的声音live：历届金曲精选集！每一首都是顶级歌手的用心演绎，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '366965',
 'songs': '94',
 'tag': '华语-综艺-驾车',
 'title': '无标题'}
2024-11-11 17:35:02 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：无论是长途旅行还是短途郊游，放假总是让我们心情愉悦。抛开繁忙的工作，与家人朋友一同享受这美好的时光吧！',
 'play': '2065',
 'songs': '43',
 'tag': '华语-治愈-放松',
 'title': '无标题'}
2024-11-11 17:35:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12657163779>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：无论是长途旅行还是短途郊游，放假总是让我们心情愉悦。抛开繁忙的工作，与家人朋友一同享受这美好的时光吧！',
 'play': '2065',
 'songs': '43',
 'tag': '华语-治愈-放松',
 'title': '无标题'}
2024-11-11 17:35:03 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '4',
 'description': '介绍：有人释怀、有人在风里热情不再，我试着把孤独藏进耳机，终是浪漫世界值孤獨。如果你也喜欢R&B，那我们就是好朋友歌单不定期更新，喜欢可以点点收藏么❤️单主建议随机播放',
 'play': '307123',
 'songs': '105',
 'tag': '华语-流行-R&B/Soul',
 'title': '无标题'}
2024-11-11 17:35:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12227034364>
{'collection': '播放',
 'comments': '4',
 'description': '介绍：有人释怀、有人在风里热情不再，我试着把孤独藏进耳机，终是浪漫世界值孤獨。如果你也喜欢R&B，那我们就是好朋友歌单不定期更新，喜欢可以点点收藏么❤️单主建议随机播放',
 'play': '307123',
 'songs': '105',
 'tag': '华语-流行-R&B/Soul',
 'title': '无标题'}
2024-11-11 17:35:03 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '73',
 'description': '介绍：《天赐的声音》是一档中国电视音乐选秀节目，在浙江卫视播出，至今已播出四季。',
 'play': '1149145',
 'songs': '99',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8377438674>
{'collection': '播放',
 'comments': '73',
 'description': '介绍：《天赐的声音》是一档中国电视音乐选秀节目，在浙江卫视播出，至今已播出四季。',
 'play': '1149145',
 'songs': '99',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:35:03 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:36:28 [scrapy.extensions.logstats] INFO: Crawled 81 pages (at 16 pages/min), scraped 33 items (at 16 items/min)
2024-11-11 17:36:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7571447656> (referer: None)
2024-11-11 17:36:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8039486188> (referer: None)
2024-11-11 17:36:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8451919201> (referer: None)
2024-11-11 17:36:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8071093123> (referer: None)
2024-11-11 17:36:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8237704460> (referer: None)
2024-11-11 17:36:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8484246205> (referer: None)
2024-11-11 17:36:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8293407973> (referer: None)
2024-11-11 17:36:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8377327676> (referer: None)
2024-11-11 17:36:28 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '14',
 'description': '介绍：《蒙面歌王》是由江苏卫视从韩国MBC电视台引进推出的同名音乐挑战类真人秀节目，共11期，由李好主持。',
 'play': '656257',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7571447656>
{'collection': '播放',
 'comments': '14',
 'description': '介绍：《蒙面歌王》是由江苏卫视从韩国MBC电视台引进推出的同名音乐挑战类真人秀节目，共11期，由李好主持。',
 'play': '656257',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:28 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '920',
 'description': '介绍：汪苏泷 Silence Wang '
                '内地唱作男歌手、音乐制作人他不断以独属于汪苏泷的多变音乐风格，展现其不俗的音乐才华，传达内心最真挚的音乐态度。',
 'play': '994063',
 'songs': '57',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8039486188>
{'collection': '播放',
 'comments': '920',
 'description': '介绍：汪苏泷 Silence Wang '
                '内地唱作男歌手、音乐制作人他不断以独属于汪苏泷的多变音乐风格，展现其不俗的音乐才华，传达内心最真挚的音乐态度。',
 'play': '994063',
 'songs': '57',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:28 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '4',
 'description': '介绍：夏季总是浪漫而热烈 乐队总是放肆又张扬 这些点滴都记录着青春',
 'play': '576398',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8451919201>
{'collection': '播放',
 'comments': '4',
 'description': '介绍：夏季总是浪漫而热烈 乐队总是放肆又张扬 这些点滴都记录着青春',
 'play': '576398',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:28 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '74',
 'description': '介绍：从1983年到2023年，春晚陪伴全国人民度过了40个团圆之夜如今，春晚不再只是一场晚会，它是每一年心照不宣的约定，是只属于中国的浪漫仪式',
 'play': '405769',
 'songs': '45',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8071093123>
{'collection': '播放',
 'comments': '74',
 'description': '介绍：从1983年到2023年，春晚陪伴全国人民度过了40个团圆之夜如今，春晚不再只是一场晚会，它是每一年心照不宣的约定，是只属于中国的浪漫仪式',
 'play': '405769',
 'songs': '45',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '185',
 'description': '介绍：《声生不息·宝岛季》是由芒果TV洪啸工作室制作的一档以台湾金曲为内容的音乐文化交流节目。借以年代为线索同享音乐盛宴，全面梳理和呈现宝岛台湾特色的“中华音乐编年史”。',
 'play': '1837097',
 'songs': '101',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8237704460>
{'collection': '播放',
 'comments': '185',
 'description': '介绍：《声生不息·宝岛季》是由芒果TV洪啸工作室制作的一档以台湾金曲为内容的音乐文化交流节目。借以年代为线索同享音乐盛宴，全面梳理和呈现宝岛台湾特色的“中华音乐编年史”。',
 'play': '1837097',
 'songs': '101',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1',
 'description': '介绍：宝丽金（PolyGram）成立于1972年，是一家历史悠久的唱片公司。先后将周慧敏、张国荣等歌手揽入旗下。',
 'play': '50365',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8484246205>
{'collection': '播放',
 'comments': '1',
 'description': '介绍：宝丽金（PolyGram）成立于1972年，是一家历史悠久的唱片公司。先后将周慧敏、张国荣等歌手揽入旗下。',
 'play': '50365',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '200',
 'description': '介绍：鱼丁糸，中国台湾乐团，由吴青峰、谢馨仪、史俊威、何景扬、刘家凯、龚钰祺成员组成。2020年7月3日，鱼丁糸作为苏打绿的分身正式官宣。',
 'play': '116439',
 'songs': '81',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8293407973>
{'collection': '播放',
 'comments': '200',
 'description': '介绍：鱼丁糸，中国台湾乐团，由吴青峰、谢馨仪、史俊威、何景扬、刘家凯、龚钰祺成员组成。2020年7月3日，鱼丁糸作为苏打绿的分身正式官宣。',
 'play': '116439',
 'songs': '81',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9238869483> (referer: None)
2024-11-11 17:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12259807770> (referer: None)
2024-11-11 17:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12606065341> (referer: None)
2024-11-11 17:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12592183485> (referer: None)
2024-11-11 17:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12627168131> (referer: None)
2024-11-11 17:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12617725666> (referer: None)
2024-11-11 17:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12697516954> (referer: None)
2024-11-11 17:36:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12291302678> (referer: None)
2024-11-11 17:36:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '138',
 'description': '介绍：双笙，本名陈元汐，新生代国风女歌手，自 2015 '
                '年在网络发歌起，持续积累粉丝的同时也不断向新的领域突破，从网络翻唱到影视 OST 到原创音乐，佳绩频出，潜力无限。',
 'play': '83469',
 'songs': '19',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8377327676>
{'collection': '播放',
 'comments': '138',
 'description': '介绍：双笙，本名陈元汐，新生代国风女歌手，自 2015 '
                '年在网络发歌起，持续积累粉丝的同时也不断向新的领域突破，从网络翻唱到影视 OST 到原创音乐，佳绩频出，潜力无限。',
 'play': '83469',
 'songs': '19',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:36:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '10',
 'description': '介绍：神级翻唱live，享受天花板级别的嗓音，超强的实力一开嗓就震撼心灵，你最爱哪位歌手，欢迎评论区留言',
 'play': '455686',
 'songs': '110',
 'tag': '华语-翻唱-综艺',
 'title': '无标题'}
2024-11-11 17:36:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9238869483>
{'collection': '播放',
 'comments': '10',
 'description': '介绍：神级翻唱live，享受天花板级别的嗓音，超强的实力一开嗓就震撼心灵，你最爱哪位歌手，欢迎评论区留言',
 'play': '455686',
 'songs': '110',
 'tag': '华语-翻唱-综艺',
 'title': '无标题'}
2024-11-11 17:36:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '7',
 'description': '介绍：华语实力派歌手代表作品精选，一键收听，任素汐 张碧晨 单依纯 薛之谦 陈楚生 '
                '周深，每一首都值得反复聆听，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏感谢聆听',
 'play': '330967',
 'songs': '118',
 'tag': '华语-流行-驾车',
 'title': '无标题'}
2024-11-11 17:36:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12259807770>
{'collection': '播放',
 'comments': '7',
 'description': '介绍：华语实力派歌手代表作品精选，一键收听，任素汐 张碧晨 单依纯 薛之谦 陈楚生 '
                '周深，每一首都值得反复聆听，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏感谢聆听',
 'play': '330967',
 'songs': '118',
 'tag': '华语-流行-驾车',
 'title': '无标题'}
2024-11-11 17:36:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：久听不讨厌，你爱的歌 '
                '，值得反复聆听，热门情歌，收藏你的最爱歌，经典新老歌曲，每一首歌有你的故事，希望你们，收藏起来!歌单制作；新疆RaZeL哥封面来源；网络歌单更新；每日更新请注意; '
                '歌单不要模仿\u200b勿侵；欢迎收藏，关注 ！',
 'play': '2149',
 'songs': '44',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:36:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12606065341>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：久听不讨厌，你爱的歌 '
                '，值得反复聆听，热门情歌，收藏你的最爱歌，经典新老歌曲，每一首歌有你的故事，希望你们，收藏起来!歌单制作；新疆RaZeL哥封面来源；网络歌单更新；每日更新请注意; '
                '歌单不要模仿\u200b勿侵；欢迎收藏，关注 ！',
 'play': '2149',
 'songs': '44',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:36:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：在学生总有那么一首歌陪伴着你，那是满满的回忆。你是否还记得跟好朋友们一起在小本本上抄录的歌词呢？接着就让我们跟着熟悉的旋律，穿越到属于我们90后的学生时代吧，回味我们的青涩年华。网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.9.13歌單完善: 2024.9.18歌單製作: 莣情歌單封面: 来源于网络侵删',
 'play': '1586',
 'songs': '95',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:36:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12592183485>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：在学生总有那么一首歌陪伴着你，那是满满的回忆。你是否还记得跟好朋友们一起在小本本上抄录的歌词呢？接着就让我们跟着熟悉的旋律，穿越到属于我们90后的学生时代吧，回味我们的青涩年华。网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.9.13歌單完善: 2024.9.18歌單製作: 莣情歌單封面: 来源于网络侵删',
 'play': '1586',
 'songs': '95',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:36:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：自由的风会吹动木讷的树，木讷的树留不住自由的风我想你是明媚的 是勇敢的 是快乐的 是乐观主义者 '
                '我想你一定能会成为这样',
 'play': '1023',
 'songs': '76',
 'tag': '华语-R&B/Soul-放松',
 'title': '无标题'}
2024-11-11 17:36:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12627168131>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：自由的风会吹动木讷的树，木讷的树留不住自由的风我想你是明媚的 是勇敢的 是快乐的 是乐观主义者 '
                '我想你一定能会成为这样',
 'play': '1023',
 'songs': '76',
 'tag': '华语-R&B/Soul-放松',
 'title': '无标题'}
2024-11-11 17:36:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1',
 'description': '介绍：华语神仙嗓：单依纯 周深 毛不易 '
                '张碧晨，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '137683',
 'songs': '86',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:36:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12617725666>
{'collection': '播放',
 'comments': '1',
 'description': '介绍：华语神仙嗓：单依纯 周深 毛不易 '
                '张碧晨，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '137683',
 'songs': '86',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:36:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：有好心情才会有好心态，好磁场，好运来，都是一环扣一环的，所以人一定要活的开心！可多听一些高能量的歌，多看治愈的颜色，会越来越好！',
 'play': '2006',
 'songs': '64',
 'tag': '华语-R&B/Soul-快乐',
 'title': '无标题'}
2024-11-11 17:36:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12697516954>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：有好心情才会有好心态，好磁场，好运来，都是一环扣一环的，所以人一定要活的开心！可多听一些高能量的歌，多看治愈的颜色，会越来越好！',
 'play': '2006',
 'songs': '64',
 'tag': '华语-R&B/Soul-快乐',
 'title': '无标题'}
2024-11-11 17:36:29 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '14',
 'description': '介绍：华语顶级音综，天赐的声音第五季最值得听的TOP30，每一首都值得反复聆听，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏感谢聆听',
 'play': '649469',
 'songs': '52',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:36:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12291302678>
{'collection': '播放',
 'comments': '14',
 'description': '介绍：华语顶级音综，天赐的声音第五季最值得听的TOP30，每一首都值得反复聆听，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏感谢聆听',
 'play': '649469',
 'songs': '52',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:36:29 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:37:50 [scrapy.extensions.logstats] INFO: Crawled 97 pages (at 16 pages/min), scraped 49 items (at 16 items/min)
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=514947114> (referer: None)
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=625683970> (referer: None)
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=2331136477> (referer: None)
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=2685449094> (referer: None)
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=3233164347> (referer: None)
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=2041615881> (referer: None)
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=729556632> (referer: None)
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=3001035934> (referer: None)
2024-11-11 17:37:51 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '820',
 'description': '介绍：民谣 一听就是一个故事民谣 唱的人普通 听的人平凡民谣 喜欢那种感同身受 '
                '热爱那些温柔辞藻用歌曲说话用歌曲讲故事因为被赋予旋律所以才更容易打动人心简单的旋律和歌词也可以传达出最饱含诗意的深情有时候民谣像是唱着长达一生的曾经却又像只是讲了某天放学后暗恋少年阳光下灿烂的笑脸在民谣里 '
                '回忆过去怀念过去的故事想念那些无法再见的人在民谣里 '
                '憧憬未来坚信有一天终将会抵达的远方因为有记忆我们变得丰满因为有向往我们才会一往无前即使有一天我们白发苍苍回首一生有那么多丰富的回忆和故事此生足矣愿孤独的你有诗的态度也有当下的远方朩朩青尘2016.11.22',
 'play': '29367668',
 'songs': '287',
 'tag': '华语-民谣-孤独',
 'title': '无标题'}
2024-11-11 17:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=514947114>
{'collection': '播放',
 'comments': '820',
 'description': '介绍：民谣 一听就是一个故事民谣 唱的人普通 听的人平凡民谣 喜欢那种感同身受 '
                '热爱那些温柔辞藻用歌曲说话用歌曲讲故事因为被赋予旋律所以才更容易打动人心简单的旋律和歌词也可以传达出最饱含诗意的深情有时候民谣像是唱着长达一生的曾经却又像只是讲了某天放学后暗恋少年阳光下灿烂的笑脸在民谣里 '
                '回忆过去怀念过去的故事想念那些无法再见的人在民谣里 '
                '憧憬未来坚信有一天终将会抵达的远方因为有记忆我们变得丰满因为有向往我们才会一往无前即使有一天我们白发苍苍回首一生有那么多丰富的回忆和故事此生足矣愿孤独的你有诗的态度也有当下的远方朩朩青尘2016.11.22',
 'play': '29367668',
 'songs': '287',
 'tag': '华语-民谣-孤独',
 'title': '无标题'}
2024-11-11 17:37:51 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '45',
 'description': '介绍：听live真的是稀碎人生中唯一能肯定开心的事了～',
 'play': '579014',
 'songs': '97',
 'tag': '摇滚-华语-流行',
 'title': '无标题'}
2024-11-11 17:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=625683970>
{'collection': '播放',
 'comments': '45',
 'description': '介绍：听live真的是稀碎人生中唯一能肯定开心的事了～',
 'play': '579014',
 'songs': '97',
 'tag': '摇滚-华语-流行',
 'title': '无标题'}
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6620660821> (referer: None)
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6845908342> (referer: None)
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8937026669> (referer: None)
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8213357610> (referer: None)
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7492116019> (referer: None)
2024-11-11 17:37:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7392583710> (referer: None)
2024-11-11 17:37:51 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1533',
 'description': '介绍：他经历过失望，辜负，又行走于世间百态最露骨的地方，却依然留存了一颗少年之心。赤诚，坦荡，以我所爱为爱， '
                '以我所恨为恨。而他则说，那我便管不了了，洒了我这一捧血，自有后来人接收。那日清雅茶堂，琵琶声穿堂而过，像极了爱情疾疾，惊掠心头。——高台树色 '
                '《穿堂惊掠琵琶声》（歌单的灵感来源于《声声慢》，颇为惊艳的一首歌，歌单里有几首有些跑题，但我觉得，你会喜欢❤）歌单名出处：满堂花醉三千客，一剑霜寒十四州。《献钱尚父 '
                '》唐 · 贯休封面：@六萌星整理：鹤禅眠2018.7.26',
 'play': '18496554',
 'songs': '112',
 'tag': '华语-民谣-古风',
 'title': '无标题'}
2024-11-11 17:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=2331136477>
{'collection': '播放',
 'comments': '1533',
 'description': '介绍：他经历过失望，辜负，又行走于世间百态最露骨的地方，却依然留存了一颗少年之心。赤诚，坦荡，以我所爱为爱， '
                '以我所恨为恨。而他则说，那我便管不了了，洒了我这一捧血，自有后来人接收。那日清雅茶堂，琵琶声穿堂而过，像极了爱情疾疾，惊掠心头。——高台树色 '
                '《穿堂惊掠琵琶声》（歌单的灵感来源于《声声慢》，颇为惊艳的一首歌，歌单里有几首有些跑题，但我觉得，你会喜欢❤）歌单名出处：满堂花醉三千客，一剑霜寒十四州。《献钱尚父 '
                '》唐 · 贯休封面：@六萌星整理：鹤禅眠2018.7.26',
 'play': '18496554',
 'songs': '112',
 'tag': '华语-民谣-古风',
 'title': '无标题'}
2024-11-11 17:37:51 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '777',
 'description': '介绍：播放这张歌单的时候请想象自己有那么一个庭院，里面栽满了各种花草树木、瓜果蔬菜，还有一只会说话的鹦鹉，和几条锦鲤，院子中央有一张池塘。春天，院子里开满了各种各样的花，枯草也开始慢慢变绿，池塘里的水一点点积满，空气中夹带着荔枝花的香味。闲时和鹦鹉拌拌嘴，给前来采蜜的蜜蜂指引花香，喂着那三五条锦鲤消遣着这春日时光。夏天，待荷花开满整个池塘，便摘上几颗荔枝于池塘正中的亭子里，边吃着荔枝，边摇着折扇，欣赏这映日荷花，感受美好而惬意的夏日时光。秋天，是个丰收的季节，远处田野传来了阵阵稻香，篱笆下的菊花正好拿来泡茶，菊花茶再配上一碟桂花糕，谁言秋日不如春？冬天，当院子里所有的花都凋谢时，墙角的几株梅花安静地开着，花香四溢，若是下了雪，便可以邀上几位知交好友围炉饮酒，看这梅雪相争了，倒是为这看似无趣的冬天增添了无限雅趣。封面画师：伊吹五月',
 'play': '12992235',
 'songs': '150',
 'tag': '华语-古风-浪漫',
 'title': '无标题'}
2024-11-11 17:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=2685449094>
{'collection': '播放',
 'comments': '777',
 'description': '介绍：播放这张歌单的时候请想象自己有那么一个庭院，里面栽满了各种花草树木、瓜果蔬菜，还有一只会说话的鹦鹉，和几条锦鲤，院子中央有一张池塘。春天，院子里开满了各种各样的花，枯草也开始慢慢变绿，池塘里的水一点点积满，空气中夹带着荔枝花的香味。闲时和鹦鹉拌拌嘴，给前来采蜜的蜜蜂指引花香，喂着那三五条锦鲤消遣着这春日时光。夏天，待荷花开满整个池塘，便摘上几颗荔枝于池塘正中的亭子里，边吃着荔枝，边摇着折扇，欣赏这映日荷花，感受美好而惬意的夏日时光。秋天，是个丰收的季节，远处田野传来了阵阵稻香，篱笆下的菊花正好拿来泡茶，菊花茶再配上一碟桂花糕，谁言秋日不如春？冬天，当院子里所有的花都凋谢时，墙角的几株梅花安静地开着，花香四溢，若是下了雪，便可以邀上几位知交好友围炉饮酒，看这梅雪相争了，倒是为这看似无趣的冬天增添了无限雅趣。封面画师：伊吹五月',
 'play': '12992235',
 'songs': '150',
 'tag': '华语-古风-浪漫',
 'title': '无标题'}
2024-11-11 17:37:51 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '127',
 'description': '介绍：“最近迷上了听乐队，仿佛喻示着自己的青春已逝。”用吉他、键盘、贝斯、架子鼓，就能打造出极尽青春、温柔、浪漫、迷幻、无边的摇滚宇宙。似是与爱人牵手沐浴在夕阳最后的余晖里，海风轻拂，令原本无味的人生，也多了些许期待！',
 'play': '4697629',
 'songs': '102',
 'tag': '华语-另类/独立-浪漫',
 'title': '无标题'}
2024-11-11 17:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=3233164347>
{'collection': '播放',
 'comments': '127',
 'description': '介绍：“最近迷上了听乐队，仿佛喻示着自己的青春已逝。”用吉他、键盘、贝斯、架子鼓，就能打造出极尽青春、温柔、浪漫、迷幻、无边的摇滚宇宙。似是与爱人牵手沐浴在夕阳最后的余晖里，海风轻拂，令原本无味的人生，也多了些许期待！',
 'play': '4697629',
 'songs': '102',
 'tag': '华语-另类/独立-浪漫',
 'title': '无标题'}
2024-11-11 17:37:52 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2566',
 'description': '介绍：古风圈曲作一人一首代表作作曲是指一首歌曲，或者是一段音乐作品的主旋律，创作主旋律的过程就是作曲winky诗：山鬼千年破晓：故梦小幻：爱殇擎天：杯欢贰婶：悟空横颜君：颜非猿卢印：别赋锦年：逐鹿泡泡：红妆慕云凌风：天局归公子：春归安靖羽：觅红吉他兔：对奕Zoey：魂归音频怪物：琴师白蔓：谓我sea云：杀生叶里：冠玉阿坤：栖枝锦衣小盆友：非鱼小宅：将卿m.86：东流玄昌俊：青衣排骨教主：初雪熤煜：又雪木一：大梦汤汤：归一ilem：葬歌孙沛：谪仙龙小葵：王者徒有琴：琵琶行小曲儿：爱莲说千草仙：兰若词贺鑫：不记年只有影子：湖心亭爆款：春庭雪墨狂君：满城雪银临：牵丝戏胡蝶：露中生胡碧乔：小城谣徐梦圆：采茶纪西瓜JUN：长生诀潇儿：花满楼高林栋：四时令小千：乌衣巷零：不死城KIDE：江山雪董贞：相思引七叶：风月令恒曌：蜉蝣梦寒殇：长相忆兔子Jei：篱边秋慕霄：花间事琴宇/LBG：丹青客Wing翼：三月雨刘珂矣：半壶纱圣香：云水逢乐夕：倦世间著小生：杏花巷墨熙：犬物语安靖羽：明月舟Hita：水龙吟伦桑：酒情钟熙er：双人行阿鲲：三生叹泥鳅：南柯梦寒苍凌：浮生祭Ming明：江南语草莓酱：雨霖铃鲁四月：北凉歌灰色：醉人间甘璐：眉心妆偏生梓归：一寒辞浔浔：离人殇李懋扬：寄明月灰白：舞霓裳燕池：东流水Tacke竹桑：薛涛笺西凉Cassie：醉狂草少年Sei：喵万岁徐一：贺新遥盏月陆离：徽墨说君撷：蜀·御风DMYoung：将进酒河图：倾尽天下王朝：君临天下小慕：落霞云归墨水：如玉如歌徐一鸣：弱水三千乌龟：权御天下洪尘：何生枷锁弭沅：十年一晌舜禹：阖眸烟云李建衡：热爱至上安九：礼仪之邦少司命：梅坞寻茶卡其漠：苍山负雪五色石南叶：春风夏雨江潮：一介书生执素兮：山有木兮陈鹏杰：少读红楼0.5：盛世回首倾夜：江湖少年章鱼烧正太：仙侠世界江枫云鹤：千年空城微风：梨花熏雨涵昱：巷雨梨花曹开挽：上元姑娘潮汐：明月天涯霜陌遥：府上花开小尘：月华沉梦山雨山语：山水画意天音之旋：何以清尘又又：梦里偕老灰原穷：棠梨煎雪祝贺：谪宦悲秋纱朵：浮云生死花色游戏2018.1.3',
 'play': '30196956',
 'songs': '192',
 'tag': '华语-古风-学习',
 'title': '无标题'}
2024-11-11 17:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=2041615881>
{'collection': '播放',
 'comments': '2566',
 'description': '介绍：古风圈曲作一人一首代表作作曲是指一首歌曲，或者是一段音乐作品的主旋律，创作主旋律的过程就是作曲winky诗：山鬼千年破晓：故梦小幻：爱殇擎天：杯欢贰婶：悟空横颜君：颜非猿卢印：别赋锦年：逐鹿泡泡：红妆慕云凌风：天局归公子：春归安靖羽：觅红吉他兔：对奕Zoey：魂归音频怪物：琴师白蔓：谓我sea云：杀生叶里：冠玉阿坤：栖枝锦衣小盆友：非鱼小宅：将卿m.86：东流玄昌俊：青衣排骨教主：初雪熤煜：又雪木一：大梦汤汤：归一ilem：葬歌孙沛：谪仙龙小葵：王者徒有琴：琵琶行小曲儿：爱莲说千草仙：兰若词贺鑫：不记年只有影子：湖心亭爆款：春庭雪墨狂君：满城雪银临：牵丝戏胡蝶：露中生胡碧乔：小城谣徐梦圆：采茶纪西瓜JUN：长生诀潇儿：花满楼高林栋：四时令小千：乌衣巷零：不死城KIDE：江山雪董贞：相思引七叶：风月令恒曌：蜉蝣梦寒殇：长相忆兔子Jei：篱边秋慕霄：花间事琴宇/LBG：丹青客Wing翼：三月雨刘珂矣：半壶纱圣香：云水逢乐夕：倦世间著小生：杏花巷墨熙：犬物语安靖羽：明月舟Hita：水龙吟伦桑：酒情钟熙er：双人行阿鲲：三生叹泥鳅：南柯梦寒苍凌：浮生祭Ming明：江南语草莓酱：雨霖铃鲁四月：北凉歌灰色：醉人间甘璐：眉心妆偏生梓归：一寒辞浔浔：离人殇李懋扬：寄明月灰白：舞霓裳燕池：东流水Tacke竹桑：薛涛笺西凉Cassie：醉狂草少年Sei：喵万岁徐一：贺新遥盏月陆离：徽墨说君撷：蜀·御风DMYoung：将进酒河图：倾尽天下王朝：君临天下小慕：落霞云归墨水：如玉如歌徐一鸣：弱水三千乌龟：权御天下洪尘：何生枷锁弭沅：十年一晌舜禹：阖眸烟云李建衡：热爱至上安九：礼仪之邦少司命：梅坞寻茶卡其漠：苍山负雪五色石南叶：春风夏雨江潮：一介书生执素兮：山有木兮陈鹏杰：少读红楼0.5：盛世回首倾夜：江湖少年章鱼烧正太：仙侠世界江枫云鹤：千年空城微风：梨花熏雨涵昱：巷雨梨花曹开挽：上元姑娘潮汐：明月天涯霜陌遥：府上花开小尘：月华沉梦山雨山语：山水画意天音之旋：何以清尘又又：梦里偕老灰原穷：棠梨煎雪祝贺：谪宦悲秋纱朵：浮云生死花色游戏2018.1.3',
 'play': '30196956',
 'songs': '192',
 'tag': '华语-古风-学习',
 'title': '无标题'}
2024-11-11 17:37:52 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '242',
 'description': '介绍：随着继承并弘扬传统文化的呼声日益高涨，诸多制作精良的古装影视作品问世，广受都市人们的喜爱。同时，结合中国元素的流行歌曲，也备受瞩目。本歌单收录了含人声的国风摇滚、说唱、电子、戏腔、民谣。当然还有国风爵士等类型少量收录，有机会会继续收录哒！此刻，就让我们沉溺在不一样的国风浪潮中，感受华夏大地的悠扬古韵吧！（封面来源网络，侵删致歉。）',
 'play': '9752180',
 'songs': '136',
 'tag': '华语-古风-流行',
 'title': '无标题'}
2024-11-11 17:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=3001035934>
{'collection': '播放',
 'comments': '242',
 'description': '介绍：随着继承并弘扬传统文化的呼声日益高涨，诸多制作精良的古装影视作品问世，广受都市人们的喜爱。同时，结合中国元素的流行歌曲，也备受瞩目。本歌单收录了含人声的国风摇滚、说唱、电子、戏腔、民谣。当然还有国风爵士等类型少量收录，有机会会继续收录哒！此刻，就让我们沉溺在不一样的国风浪潮中，感受华夏大地的悠扬古韵吧！（封面来源网络，侵删致歉。）',
 'play': '9752180',
 'songs': '136',
 'tag': '华语-古风-流行',
 'title': '无标题'}
2024-11-11 17:37:52 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '6',
 'description': '介绍：陶喆，方大同，丁世光，Tension，李玖哲，温岚，还有一些陶喆作曲编曲的作品',
 'play': '344108',
 'songs': '189',
 'tag': '华语-R&B/Soul-浪漫',
 'title': '无标题'}
2024-11-11 17:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=729556632>
{'collection': '播放',
 'comments': '6',
 'description': '介绍：陶喆，方大同，丁世光，Tension，李玖哲，温岚，还有一些陶喆作曲编曲的作品',
 'play': '344108',
 'songs': '189',
 'tag': '华语-R&B/Soul-浪漫',
 'title': '无标题'}
2024-11-11 17:37:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6938208354> (referer: None)
2024-11-11 17:37:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12712085640> (referer: None)
2024-11-11 17:37:52 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '75',
 'description': '介绍：【封面】果拿拿【前言】歌单收集1980年至今对岸乐团/组合，曲库分两部分，前29首歌是每年成立时间挑选一个乐团；后面部分是根据成立时间倒序，一个乐团一首歌，越往后听年代越久远。【萌芽阶段】50年代美国军中广播是散播摇滚乐的最佳播种者，成立于1981年的丘丘合唱团为首支发行专辑的流行乐团，1984年成团的Why '
                'Not走在时代的很前面。1986年水晶唱片成立，引介时下英美正方兴未艾的新音乐，同时也将地下乐团的概念引进。90年代初台北乐团目前仍处于学习阶段，模彷西方摇滚乐团。【地下乐团】伍佰首张专辑《爱上别人是快乐的事》叫好不叫座，开始与China '
                'blue合作带领出新一波现场演唱文化，后面合作两张专辑都卖座，唱片公司意识到「乐团可能是未来唱片市场的主流」，纷纷抢签乐团。1994由骨肉皮主唱阿峰开设了「Scum」，要求登台乐团至少要有一首自创曲。同年，「人狗跟蚂蚁」的毁于一场大火，同时结束了台北乐团的模仿时期。【乐团世代】地下乐团转进女巫店演出；角头音乐和阿帕唱片的成立开创新阶段的独立唱片公司出版模式；乩童秩序、五月天、脱拉库于主流唱片公司发表首张专辑，其中五月天在市场大有斩获。2000年，乱弹拿下金曲奖最佳团体奖，在金曲奖典礼上振臂高呼「乐团的时代来临了！」算是正式宣告摇滚乐团的时代出现在主流音乐市场。地下乐团数量逐渐增多，独立乐团取代地下场景。【Z世代】网络的发展让乐团风格多样化，在地文化的发展让越来越多的乐团愿意尝试将当地特色的民俗元素带入自己的歌曲中；由于数位器材的普及，录音成本和技术门坎下降，许多新乐团都尝试用数位宅录方式制作专辑。【丧世代】青年的无力和沮丧也出现在许多年轻的乐团中，其中草东没有派对以DIY方式自行出版了首张专辑《丑奴儿》，得到了金曲奖肯定，「乐团之声」再度引起注目，一批“厌世”类的乐团走进大家的视野。【chill世代】以落日飞车为代表的这股chill、软绵的「台式新浪漫」得益于互联网扩散至全世界；并且在这几年，R&B也出现了回潮的现象，一批新生代怪物新人正崭露头角。',
 'play': '1044097',
 'songs': '411',
 'tag': '华语-摇滚-流行',
 'title': '无标题'}
2024-11-11 17:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6620660821>
{'collection': '播放',
 'comments': '75',
 'description': '介绍：【封面】果拿拿【前言】歌单收集1980年至今对岸乐团/组合，曲库分两部分，前29首歌是每年成立时间挑选一个乐团；后面部分是根据成立时间倒序，一个乐团一首歌，越往后听年代越久远。【萌芽阶段】50年代美国军中广播是散播摇滚乐的最佳播种者，成立于1981年的丘丘合唱团为首支发行专辑的流行乐团，1984年成团的Why '
                'Not走在时代的很前面。1986年水晶唱片成立，引介时下英美正方兴未艾的新音乐，同时也将地下乐团的概念引进。90年代初台北乐团目前仍处于学习阶段，模彷西方摇滚乐团。【地下乐团】伍佰首张专辑《爱上别人是快乐的事》叫好不叫座，开始与China '
                'blue合作带领出新一波现场演唱文化，后面合作两张专辑都卖座，唱片公司意识到「乐团可能是未来唱片市场的主流」，纷纷抢签乐团。1994由骨肉皮主唱阿峰开设了「Scum」，要求登台乐团至少要有一首自创曲。同年，「人狗跟蚂蚁」的毁于一场大火，同时结束了台北乐团的模仿时期。【乐团世代】地下乐团转进女巫店演出；角头音乐和阿帕唱片的成立开创新阶段的独立唱片公司出版模式；乩童秩序、五月天、脱拉库于主流唱片公司发表首张专辑，其中五月天在市场大有斩获。2000年，乱弹拿下金曲奖最佳团体奖，在金曲奖典礼上振臂高呼「乐团的时代来临了！」算是正式宣告摇滚乐团的时代出现在主流音乐市场。地下乐团数量逐渐增多，独立乐团取代地下场景。【Z世代】网络的发展让乐团风格多样化，在地文化的发展让越来越多的乐团愿意尝试将当地特色的民俗元素带入自己的歌曲中；由于数位器材的普及，录音成本和技术门坎下降，许多新乐团都尝试用数位宅录方式制作专辑。【丧世代】青年的无力和沮丧也出现在许多年轻的乐团中，其中草东没有派对以DIY方式自行出版了首张专辑《丑奴儿》，得到了金曲奖肯定，「乐团之声」再度引起注目，一批“厌世”类的乐团走进大家的视野。【chill世代】以落日飞车为代表的这股chill、软绵的「台式新浪漫」得益于互联网扩散至全世界；并且在这几年，R&B也出现了回潮的现象，一批新生代怪物新人正崭露头角。',
 'play': '1044097',
 'songs': '411',
 'tag': '华语-摇滚-流行',
 'title': '无标题'}
2024-11-11 17:37:52 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '6',
 'description': '介绍：《天赐的声音》是浙江卫视推出的音乐励志节目，由浙江卫视节目中心制作。节目邀请音乐合伙人寻找音乐中的另一半，每期六组飞行合伙人两两成组合作演唱，一人和常驻音乐合伙人合作共同演绎一首歌曲，进行“推荐金曲争夺战”。《天赐的声音》包括《天赐的声音第一季》《天赐的声音第二季》。第一季由胡海泉、陈欢担任声音推荐人，王力宏、苏有朋、胡彦斌、张韶涵担任音乐合伙人，于2020年2月15日起每周六20:30首播，于2020年5月16日收官；第二季由胡海泉、陈欢担任声音推荐人，胡彦斌、张韶涵、胡海泉、陶喆、张信哲等担任音乐合伙人，于2021年1月15日起每周五晚22:00首播，于2021年4月2日收官。',
 'play': '669209',
 'songs': '114',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8937026669>
{'collection': '播放',
 'comments': '6',
 'description': '介绍：《天赐的声音》是浙江卫视推出的音乐励志节目，由浙江卫视节目中心制作。节目邀请音乐合伙人寻找音乐中的另一半，每期六组飞行合伙人两两成组合作演唱，一人和常驻音乐合伙人合作共同演绎一首歌曲，进行“推荐金曲争夺战”。《天赐的声音》包括《天赐的声音第一季》《天赐的声音第二季》。第一季由胡海泉、陈欢担任声音推荐人，王力宏、苏有朋、胡彦斌、张韶涵担任音乐合伙人，于2020年2月15日起每周六20:30首播，于2020年5月16日收官；第二季由胡海泉、陈欢担任声音推荐人，胡彦斌、张韶涵、胡海泉、陶喆、张信哲等担任音乐合伙人，于2021年1月15日起每周五晚22:00首播，于2021年4月2日收官。',
 'play': '669209',
 'songs': '114',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:37:52 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '764',
 'description': '介绍：七岁的那一年，抓住那只蝉，以为能抓住夏天。十七岁的那年，吻过她的脸，就以为和她能永远。',
 'play': '8286114',
 'songs': '192',
 'tag': '流行-华语-伤感',
 'title': '无标题'}
2024-11-11 17:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7492116019>
{'collection': '播放',
 'comments': '764',
 'description': '介绍：七岁的那一年，抓住那只蝉，以为能抓住夏天。十七岁的那年，吻过她的脸，就以为和她能永远。',
 'play': '8286114',
 'songs': '192',
 'tag': '流行-华语-伤感',
 'title': '无标题'}
2024-11-11 17:37:52 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '79',
 'description': '介绍：R&B:一般称为“节奏蓝调“或“节奏布鲁斯”。是一种融合了爵士乐，福音音乐和蓝调音乐的音乐形式，起源于20世纪40年代的非裔美国人社区。这个音乐术语最早由美国公告牌( '
                'Billboard)于1940年代提出，如今已经成为风靡世界的一种音乐风格。歌单精选了华语的情歌R&B，温柔的声线搭配浪漫的旋律，好像冬日里的恋情，爱意浓浓的感觉～',
 'play': '4656445',
 'songs': '99',
 'tag': '华语-流行-R&B/Soul',
 'title': '无标题'}
2024-11-11 17:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8213357610>
{'collection': '播放',
 'comments': '79',
 'description': '介绍：R&B:一般称为“节奏蓝调“或“节奏布鲁斯”。是一种融合了爵士乐，福音音乐和蓝调音乐的音乐形式，起源于20世纪40年代的非裔美国人社区。这个音乐术语最早由美国公告牌( '
                'Billboard)于1940年代提出，如今已经成为风靡世界的一种音乐风格。歌单精选了华语的情歌R&B，温柔的声线搭配浪漫的旋律，好像冬日里的恋情，爱意浓浓的感觉～',
 'play': '4656445',
 'songs': '99',
 'tag': '华语-流行-R&B/Soul',
 'title': '无标题'}
2024-11-11 17:37:53 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '15',
 'description': '介绍：当熟悉的旋律再次响起，让我们一起重温那些经典的影视场景。搜索【经典专区】，更多金曲等你来听。',
 'play': '915098',
 'songs': '92',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6845908342>
{'collection': '播放',
 'comments': '15',
 'description': '介绍：当熟悉的旋律再次响起，让我们一起重温那些经典的影视场景。搜索【经典专区】，更多金曲等你来听。',
 'play': '915098',
 'songs': '92',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:37:53 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '384',
 'description': '介绍：-当蓝玫瑰坠入克莱因海未曾谋面的也终将相遇☆1-6(1-8)首是固定排序哦☆',
 'play': '10790539',
 'songs': '324',
 'tag': '华语-R&B/Soul-浪漫',
 'title': '无标题'}
2024-11-11 17:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7392583710>
{'collection': '播放',
 'comments': '384',
 'description': '介绍：-当蓝玫瑰坠入克莱因海未曾谋面的也终将相遇☆1-6(1-8)首是固定排序哦☆',
 'play': '10790539',
 'songs': '324',
 'tag': '华语-R&B/Soul-浪漫',
 'title': '无标题'}
2024-11-11 17:37:53 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '97',
 'description': '介绍：惊艳你的第一眼，便是古装剧中的神颜，实在是太好看了，可是不仅仅古装剧有颜，还有很有惊艳的主题曲，实在是太绝了，在这收录一些古装剧中一绝的音乐。',
 'play': '4183926',
 'songs': '55',
 'tag': '华语-影视原声',
 'title': '无标题'}
2024-11-11 17:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6938208354>
{'collection': '播放',
 'comments': '97',
 'description': '介绍：惊艳你的第一眼，便是古装剧中的神颜，实在是太好看了，可是不仅仅古装剧有颜，还有很有惊艳的主题曲，实在是太绝了，在这收录一些古装剧中一绝的音乐。',
 'play': '4183926',
 'songs': '55',
 'tag': '华语-影视原声',
 'title': '无标题'}
2024-11-11 17:37:53 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：汇聚当下华语R&B热门作品 一起感受当代华语R&B的魅力。',
 'play': '54734',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12712085640>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：汇聚当下华语R&B热门作品 一起感受当代华语R&B的魅力。',
 'play': '54734',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:37:53 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:39:13 [scrapy.extensions.logstats] INFO: Crawled 113 pages (at 16 pages/min), scraped 65 items (at 16 items/min)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9688111518> (referer: None)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12448290473> (referer: None)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12457734587> (referer: None)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9410563708> (referer: None)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12557442319> (referer: None)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12488273741> (referer: None)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9182116322> (referer: None)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=10145579133> (referer: None)
2024-11-11 17:39:14 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '20',
 'description': '介绍：青春的美丽与珍贵，就在于它的无邪与无瑕，在于它的可遇而不可求，在于它的永不重回。为了获得，我们献出青春，为了证明，我们接受衰老。',
 'play': '2632119',
 'songs': '218',
 'tag': '华语-流行-怀旧',
 'title': '无标题'}
2024-11-11 17:39:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9688111518>
{'collection': '播放',
 'comments': '20',
 'description': '介绍：青春的美丽与珍贵，就在于它的无邪与无瑕，在于它的可遇而不可求，在于它的永不重回。为了获得，我们献出青春，为了证明，我们接受衰老。',
 'play': '2632119',
 'songs': '218',
 'tag': '华语-流行-怀旧',
 'title': '无标题'}
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12645390381> (referer: None)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12681885253> (referer: None)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12663138118> (referer: None)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12576088985> (referer: None)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12624684782> (referer: None)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12716405636> (referer: None)
2024-11-11 17:39:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12626968268> (referer: None)
2024-11-11 17:39:14 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：朝与夕，通勤路上的治愈精神良曲~调节好磁场，提升能量：远离一些让自己不开心的人和事。要珍惜自己的能量和精气神。多和高能量的人在一起，对方能带动你一起往前走，也能收获很多好运。',
 'play': '2556',
 'songs': '58',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:39:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12448290473>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：朝与夕，通勤路上的治愈精神良曲~调节好磁场，提升能量：远离一些让自己不开心的人和事。要珍惜自己的能量和精气神。多和高能量的人在一起，对方能带动你一起往前走，也能收获很多好运。',
 'play': '2556',
 'songs': '58',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:39:14 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：时光机是有的，跟着过去的一音乐回到2004年。随身听磁带，CD， '
                'DVD，收音机，广播，还有一直陪伴的musicradio音乐之声。',
 'play': '2695',
 'songs': '102',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:39:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12457734587>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：时光机是有的，跟着过去的一音乐回到2004年。随身听磁带，CD， '
                'DVD，收音机，广播，还有一直陪伴的musicradio音乐之声。',
 'play': '2695',
 'songs': '102',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:39:14 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1',
 'description': '介绍：华语治愈系歌手，他们真的很会唱，没有不好听的，毛不易，周深，汪苏泷，单依纯等实力派，你最爱哪位歌手的作品，欢迎评论区留言',
 'play': '181934',
 'songs': '104',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:39:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9410563708>
{'collection': '播放',
 'comments': '1',
 'description': '介绍：华语治愈系歌手，他们真的很会唱，没有不好听的，毛不易，周深，汪苏泷，单依纯等实力派，你最爱哪位歌手的作品，欢迎评论区留言',
 'play': '181934',
 'songs': '104',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:39:15 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '11',
 'description': '介绍：张杰演唱会神级歌曲，开口直接万人合唱，每首都无法超越2024下半年 世界巡回城市：重庆 → 武汉 → 北京 → 苏州 '
                '→ 福州 → 郑州 → 深圳 → 南宁 → 成都 → '
                '三亚这次不是环线是直达！各位旅客，你们做好上车准备了吗？搭上张杰未·LIVE—「开往1982」之旅的列车去肆意追赶从不停歇的明天！',
 'play': '57328',
 'songs': '66',
 'tag': '华语-流行-兴奋',
 'title': '无标题'}
2024-11-11 17:39:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12557442319>
{'collection': '播放',
 'comments': '11',
 'description': '介绍：张杰演唱会神级歌曲，开口直接万人合唱，每首都无法超越2024下半年 世界巡回城市：重庆 → 武汉 → 北京 → 苏州 '
                '→ 福州 → 郑州 → 深圳 → 南宁 → 成都 → '
                '三亚这次不是环线是直达！各位旅客，你们做好上车准备了吗？搭上张杰未·LIVE—「开往1982」之旅的列车去肆意追赶从不停歇的明天！',
 'play': '57328',
 'songs': '66',
 'tag': '华语-流行-兴奋',
 'title': '无标题'}
2024-11-11 17:39:15 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '16',
 'description': '介绍：理智都明，但该痛的还是会痛，该恨的还是会恨，该笑的也还是会笑，毕竟内心的困扰不是理智所能释怀的。',
 'play': '583261',
 'songs': '190',
 'tag': '华语-流行-网络歌曲',
 'title': '无标题'}
2024-11-11 17:39:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12488273741>
{'collection': '播放',
 'comments': '16',
 'description': '介绍：理智都明，但该痛的还是会痛，该恨的还是会恨，该笑的也还是会笑，毕竟内心的困扰不是理智所能释怀的。',
 'play': '583261',
 'songs': '190',
 'tag': '华语-流行-网络歌曲',
 'title': '无标题'}
2024-11-11 17:39:15 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '6',
 'description': '介绍：陈楚生的嗓音一出来，大家就会明白为什么当年他会是冠军，用实力说话，这可是大家用小灵通一票一票投出来的',
 'play': '221653',
 'songs': '90',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:39:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9182116322>
{'collection': '播放',
 'comments': '6',
 'description': '介绍：陈楚生的嗓音一出来，大家就会明白为什么当年他会是冠军，用实力说话，这可是大家用小灵通一票一票投出来的',
 'play': '221653',
 'songs': '90',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:39:15 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '23',
 'description': '介绍：歌舞升平，盛世安宁',
 'play': '63532',
 'songs': '194',
 'tag': '古风-华语',
 'title': '无标题'}
2024-11-11 17:39:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=10145579133>
{'collection': '播放',
 'comments': '23',
 'description': '介绍：歌舞升平，盛世安宁',
 'play': '63532',
 'songs': '194',
 'tag': '古风-华语',
 'title': '无标题'}
2024-11-11 17:39:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12716861606> (referer: None)
2024-11-11 17:39:15 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '24',
 'description': '介绍：不贪念自己范围之外的东西，不盲目追逐自己能力不匹配的生活。带着自己的节奏，在喜欢的状态里生活，做你自己，生活不在富足而在满足。',
 'play': '24736',
 'songs': '40',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:39:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12645390381>
{'collection': '播放',
 'comments': '24',
 'description': '介绍：不贪念自己范围之外的东西，不盲目追逐自己能力不匹配的生活。带着自己的节奏，在喜欢的状态里生活，做你自己，生活不在富足而在满足。',
 'play': '24736',
 'songs': '40',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:39:15 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2',
 'description': '介绍：封神live：好听到爆的现场精彩演绎!网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.10.4歌單完善: 2024.10.9歌單製作: 莣情歌單封面: 来源于网络侵删',
 'play': '218129',
 'songs': '96',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:39:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12681885253>
{'collection': '播放',
 'comments': '2',
 'description': '介绍：封神live：好听到爆的现场精彩演绎!网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.10.4歌單完善: 2024.10.9歌單製作: 莣情歌單封面: 来源于网络侵删',
 'play': '218129',
 'songs': '96',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:39:15 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：华语R&B天花板：王力宏，陶喆，方大同等，一起来感受轻松自由的旋律艺术',
 'play': '3791',
 'songs': '60',
 'tag': '华语-R&B/Soul-放松',
 'title': '无标题'}
2024-11-11 17:39:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12663138118>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：华语R&B天花板：王力宏，陶喆，方大同等，一起来感受轻松自由的旋律艺术',
 'play': '3791',
 'songs': '60',
 'tag': '华语-R&B/Soul-放松',
 'title': '无标题'}
2024-11-11 17:39:15 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：深夜的寂静里，唯剩下心跳的声音。曾经的欢声笑语，如今已成为泡影，恍若隔世。痛苦与失落交织，愁绪无法释怀，任由泪水在脸颊滑落。',
 'play': '889',
 'songs': '46',
 'tag': '华语-驾车-快乐',
 'title': '无标题'}
2024-11-11 17:39:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12576088985>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：深夜的寂静里，唯剩下心跳的声音。曾经的欢声笑语，如今已成为泡影，恍若隔世。痛苦与失落交织，愁绪无法释怀，任由泪水在脸颊滑落。',
 'play': '889',
 'songs': '46',
 'tag': '华语-驾车-快乐',
 'title': '无标题'}
2024-11-11 17:39:15 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '3',
 'description': '介绍：每一首歌，都在唱着那些特别的你。',
 'play': '49596',
 'songs': '150',
 'tag': '华语-流行-R&B/Soul',
 'title': '无标题'}
2024-11-11 17:39:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12624684782>
{'collection': '播放',
 'comments': '3',
 'description': '介绍：每一首歌，都在唱着那些特别的你。',
 'play': '49596',
 'songs': '150',
 'tag': '华语-流行-R&B/Soul',
 'title': '无标题'}
2024-11-11 17:39:15 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：这张专辑带你穿梭于近几年间的暖心歌曲，用说唱和流行的交织唤起内心的柔软与心动。当风轻柔吹过发梢，当歌声流淌过心灵的一隅，那甜甜的心情再次复苏，在清新的调子里细味那段温馨情怀',
 'play': '8276',
 'songs': '36',
 'tag': '流行-华语-浪漫',
 'title': '无标题'}
2024-11-11 17:39:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12716405636>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：这张专辑带你穿梭于近几年间的暖心歌曲，用说唱和流行的交织唤起内心的柔软与心动。当风轻柔吹过发梢，当歌声流淌过心灵的一隅，那甜甜的心情再次复苏，在清新的调子里细味那段温馨情怀',
 'play': '8276',
 'songs': '36',
 'tag': '流行-华语-浪漫',
 'title': '无标题'}
2024-11-11 17:39:15 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：0713宝藏男团，哥哥们用绝对的实力再次翻红，来听听老贝贝们的精选好歌，祝愿他们越来越好',
 'play': '13577',
 'songs': '95',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:39:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12626968268>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：0713宝藏男团，哥哥们用绝对的实力再次翻红，来听听老贝贝们的精选好歌，祝愿他们越来越好',
 'play': '13577',
 'songs': '95',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:39:15 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1',
 'description': '介绍：在这个秋意渐浓的季节，情感仿佛也变得愈加深沉与复杂歌单汇集了那些充满深意的歌曲，每一首都在诉说着经历时间沉淀的情感故事。这些旋律和歌词如同秋天的落叶，带着些许的感伤与回味，让人深思与感动。 '
                '以上歌曲源于合伙人高分曲库。 /封面图源网络',
 'play': '1997',
 'songs': '54',
 'tag': '华语-流行',
 'title': '无标题'}
2024-11-11 17:39:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12716861606>
{'collection': '播放',
 'comments': '1',
 'description': '介绍：在这个秋意渐浓的季节，情感仿佛也变得愈加深沉与复杂歌单汇集了那些充满深意的歌曲，每一首都在诉说着经历时间沉淀的情感故事。这些旋律和歌词如同秋天的落叶，带着些许的感伤与回味，让人深思与感动。 '
                '以上歌曲源于合伙人高分曲库。 /封面图源网络',
 'play': '1997',
 'songs': '54',
 'tag': '华语-流行',
 'title': '无标题'}
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:39:15 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:40:40 [scrapy.extensions.logstats] INFO: Crawled 129 pages (at 16 pages/min), scraped 81 items (at 16 items/min)
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=10150476151> (referer: None)
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12605950947> (referer: None)
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12374392188> (referer: None)
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12547998354> (referer: None)
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9295587633> (referer: None)
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12516730539> (referer: None)
2024-11-11 17:40:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '13',
 'description': '介绍：华语实力派，一键收听，单依纯张碧晨周深毛不易陈楚生汪苏泷等，每一首都是实力派歌手的用心演绎直击心灵，欢迎收藏，感谢聆听',
 'play': '517822',
 'songs': '139',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:40:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=10150476151>
{'collection': '播放',
 'comments': '13',
 'description': '介绍：华语实力派，一键收听，单依纯张碧晨周深毛不易陈楚生汪苏泷等，每一首都是实力派歌手的用心演绎直击心灵，欢迎收藏，感谢聆听',
 'play': '517822',
 'songs': '139',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12546260056> (referer: None)
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9167007851> (referer: None)
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12644925729> (referer: None)
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12606443420> (referer: None)
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12632138158> (referer: None)
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12629430526> (referer: None)
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12626925255> (referer: None)
2024-11-11 17:40:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12660546673> (referer: None)
2024-11-11 17:40:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：你要做一个不动声色的大人了，不准情绪化，不准偷偷想念，不准回头看。去过自己另外的生活，你要听话，不是所有的鱼都会生活在同一片海里每一天晚上都要早早睡觉，不要熬夜，不要多想',
 'play': '855',
 'songs': '48',
 'tag': '华语-流行-感动',
 'title': '无标题'}
2024-11-11 17:40:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12605950947>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：你要做一个不动声色的大人了，不准情绪化，不准偷偷想念，不准回头看。去过自己另外的生活，你要听话，不是所有的鱼都会生活在同一片海里每一天晚上都要早早睡觉，不要熬夜，不要多想',
 'play': '855',
 'songs': '48',
 'tag': '华语-流行-感动',
 'title': '无标题'}
2024-11-11 17:40:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：实力唱将：张碧晨 薛之谦 林俊杰 '
                '单依纯，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '7121',
 'songs': '97',
 'tag': '华语-流行-感动',
 'title': '无标题'}
2024-11-11 17:40:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12516730539>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：实力唱将：张碧晨 薛之谦 林俊杰 '
                '单依纯，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '7121',
 'songs': '97',
 'tag': '华语-流行-感动',
 'title': '无标题'}
2024-11-11 17:40:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '5',
 'description': '介绍：与你的故事就在那个夏天戛然而止了……总幻想着回到过去，可是我们的青春已变成回忆，但是我们初心依然不变，勇敢生活，勇敢做自己吧~90后那些年mp3里的青春回忆，慢慢回味！',
 'play': '630981',
 'songs': '114',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:40:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12374392188>
{'collection': '播放',
 'comments': '5',
 'description': '介绍：与你的故事就在那个夏天戛然而止了……总幻想着回到过去，可是我们的青春已变成回忆，但是我们初心依然不变，勇敢生活，勇敢做自己吧~90后那些年mp3里的青春回忆，慢慢回味！',
 'play': '630981',
 'songs': '114',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:40:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：天赐的声音+我们的歌：金曲live，神仙音综，直击心灵，每一首都很好听，你最爱哪位歌手的舞台，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '3081',
 'songs': '38',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:40:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12547998354>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：天赐的声音+我们的歌：金曲live，神仙音综，直击心灵，每一首都很好听，你最爱哪位歌手的舞台，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '3081',
 'songs': '38',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:40:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '10',
 'description': '介绍：华语流行实力派，一开嗓就能抓住人心的顶级嗓音，你最爱哪位歌手的作品，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '770434',
 'songs': '151',
 'tag': '华语-流行-感动',
 'title': '无标题'}
2024-11-11 17:40:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9295587633>
{'collection': '播放',
 'comments': '10',
 'description': '介绍：华语流行实力派，一开嗓就能抓住人心的顶级嗓音，你最爱哪位歌手的作品，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '770434',
 'songs': '151',
 'tag': '华语-流行-感动',
 'title': '无标题'}
2024-11-11 17:40:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12674638696> (referer: None)
2024-11-11 17:40:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12730289425> (referer: None)
2024-11-11 17:40:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '7',
 'description': '介绍：童年时期最喜欢夏天，或许是因为夏天有吃不完的冰棒，有对小朋友来说足够多的假期，有不被打扰的自由作息。而随着时间流逝，一切都有了变化，我对夏天的抱怨也日渐增多，上不完的课，窗外蝉鸣聒噪，来校路上整日被太阳炙烤，汗液在排泄和蒸发中不断循环，但这些也只能算是客观因素。我明白，主观上影响最大的还是念旧心理，重游以前走过的路，身边却不再是相同的人，看着曾经的好朋友们分享着新的人和事物，孤独与难过在犹豫是否点赞的过程中变得具象化。记忆中的夏天实在是好，好到我要在一年又一年的夏风中学着释怀。',
 'play': '66711',
 'songs': '231',
 'tag': '华语-90后-怀旧',
 'title': '无标题'}
2024-11-11 17:40:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12546260056>
{'collection': '播放',
 'comments': '7',
 'description': '介绍：童年时期最喜欢夏天，或许是因为夏天有吃不完的冰棒，有对小朋友来说足够多的假期，有不被打扰的自由作息。而随着时间流逝，一切都有了变化，我对夏天的抱怨也日渐增多，上不完的课，窗外蝉鸣聒噪，来校路上整日被太阳炙烤，汗液在排泄和蒸发中不断循环，但这些也只能算是客观因素。我明白，主观上影响最大的还是念旧心理，重游以前走过的路，身边却不再是相同的人，看着曾经的好朋友们分享着新的人和事物，孤独与难过在犹豫是否点赞的过程中变得具象化。记忆中的夏天实在是好，好到我要在一年又一年的夏风中学着释怀。',
 'play': '66711',
 'songs': '231',
 'tag': '华语-90后-怀旧',
 'title': '无标题'}
2024-11-11 17:40:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '5',
 'description': '介绍：每一首都像是云朵轻轻吐露的爱语，让你感受到漂浮在空中的轻盈和甜蜜。就像在云层之上，寻找一场梦幻般的恋爱经历。',
 'play': '193937',
 'songs': '47',
 'tag': '说唱-浪漫-华语',
 'title': '无标题'}
2024-11-11 17:40:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9167007851>
{'collection': '播放',
 'comments': '5',
 'description': '介绍：每一首都像是云朵轻轻吐露的爱语，让你感受到漂浮在空中的轻盈和甜蜜。就像在云层之上，寻找一场梦幻般的恋爱经历。',
 'play': '193937',
 'songs': '47',
 'tag': '说唱-浪漫-华语',
 'title': '无标题'}
2024-11-11 17:40:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：“我向往：干净的圈子 规律的生活简单的爱情 中意的人不累人 不费神不刻意的余生”',
 'play': '2094',
 'songs': '73',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
2024-11-11 17:40:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12644925729>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：“我向往：干净的圈子 规律的生活简单的爱情 中意的人不累人 不费神不刻意的余生”',
 'play': '2094',
 'songs': '73',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
2024-11-11 17:40:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：还是老歌好听现在什么都变得越来越先进，越来越方便，越来越电子化智能化，但是真的好怀念以前买磁带的时候，有的是期待好久喜欢的歌手的新专辑，有的是盲买的，打开内页，一篇篇翻过去看作词作曲，猜一下哪首会好听，跟现在拆盲盒差不多的心情，那时候听歌范围特别广，现在，害',
 'play': '2098',
 'songs': '201',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
2024-11-11 17:40:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12632138158>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：还是老歌好听现在什么都变得越来越先进，越来越方便，越来越电子化智能化，但是真的好怀念以前买磁带的时候，有的是期待好久喜欢的歌手的新专辑，有的是盲买的，打开内页，一篇篇翻过去看作词作曲，猜一下哪首会好听，跟现在拆盲盒差不多的心情，那时候听歌范围特别广，现在，害',
 'play': '2098',
 'songs': '201',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
2024-11-11 17:40:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：暖心情歌：梁静茹，单依纯，蔡健雅，郁可唯，每一首都能唱进心里，你最爱哪位女神的作品，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '1850',
 'songs': '79',
 'tag': '华语-流行-感动',
 'title': '无标题'}
2024-11-11 17:40:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12606443420>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：暖心情歌：梁静茹，单依纯，蔡健雅，郁可唯，每一首都能唱进心里，你最爱哪位女神的作品，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '1850',
 'songs': '79',
 'tag': '华语-流行-感动',
 'title': '无标题'}
2024-11-11 17:40:42 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：天赐的神仙嗓音，一曲封神的顶级live，超强唱功震撼心灵，好听到停不下来',
 'play': '1787',
 'songs': '61',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:40:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12626925255>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：天赐的神仙嗓音，一曲封神的顶级live，超强唱功震撼心灵，好听到停不下来',
 'play': '1787',
 'songs': '61',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:40:42 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：“我们应该从喜欢里得到力量和快乐，而不是花光所有的力量和快乐去喜欢。”',
 'play': '662',
 'songs': '75',
 'tag': '华语-流行-快乐',
 'title': '无标题'}
2024-11-11 17:40:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12629430526>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：“我们应该从喜欢里得到力量和快乐，而不是花光所有的力量和快乐去喜欢。”',
 'play': '662',
 'songs': '75',
 'tag': '华语-流行-快乐',
 'title': '无标题'}
2024-11-11 17:40:42 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：音乐类综艺节目《天赐的声音》张碧晨 汪苏泷 陈楚生 姚晓棠 歌曲收集',
 'play': '2350',
 'songs': '85',
 'tag': '华语-综艺-流行',
 'title': '无标题'}
2024-11-11 17:40:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12660546673>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：音乐类综艺节目《天赐的声音》张碧晨 汪苏泷 陈楚生 姚晓棠 歌曲收集',
 'play': '2350',
 'songs': '85',
 'tag': '华语-综艺-流行',
 'title': '无标题'}
2024-11-11 17:40:42 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：高速开车简直太爽了哇，比平常在马路上开起安逸多了，没有红绿灯，没有行人电马儿乱窜。安逸！',
 'play': '3934',
 'songs': '54',
 'tag': '华语-驾车-快乐',
 'title': '无标题'}
2024-11-11 17:40:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12674638696>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：高速开车简直太爽了哇，比平常在马路上开起安逸多了，没有红绿灯，没有行人电马儿乱窜。安逸！',
 'play': '3934',
 'songs': '54',
 'tag': '华语-驾车-快乐',
 'title': '无标题'}
2024-11-11 17:40:42 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '74',
 'description': '介绍：日落以前没能相聚，那就日落以后极美欢庆！！把生命中的每个日落串起，日落之前的灿烂，日落之后的勇气，一切都值得从零开始。希望这次能与你们再创造美好的记忆。♥就在日落以后，首站2025年4月5日、6日新加坡见！上海深圳北京南京重庆台湾、香港、马来西亚⋯更多场地待公布',
 'play': '96224',
 'songs': '50',
 'tag': '华语-流行',
 'title': '无标题'}
2024-11-11 17:40:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12730289425>
{'collection': '播放',
 'comments': '74',
 'description': '介绍：日落以前没能相聚，那就日落以后极美欢庆！！把生命中的每个日落串起，日落之前的灿烂，日落之后的勇气，一切都值得从零开始。希望这次能与你们再创造美好的记忆。♥就在日落以后，首站2025年4月5日、6日新加坡见！上海深圳北京南京重庆台湾、香港、马来西亚⋯更多场地待公布',
 'play': '96224',
 'songs': '50',
 'tag': '华语-流行',
 'title': '无标题'}
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:40:42 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:42:02 [scrapy.extensions.logstats] INFO: Crawled 145 pages (at 16 pages/min), scraped 97 items (at 16 items/min)
2024-11-11 17:42:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6847225823> (referer: None)
2024-11-11 17:42:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8497844200> (referer: None)
2024-11-11 17:42:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7597314544> (referer: None)
2024-11-11 17:42:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9680703509> (referer: None)
2024-11-11 17:42:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7568132458> (referer: None)
2024-11-11 17:42:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7596856116> (referer: None)
2024-11-11 17:42:03 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：弹着吉他，吹着口琴， 畅谈理想、憧憬未来， 围坐在操场边， 那些学生时代许下的愿望你是否还记得？\u200b',
 'play': '74195',
 'songs': '90',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6847225823>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：弹着吉他，吹着口琴， 畅谈理想、憧憬未来， 围坐在操场边， 那些学生时代许下的愿望你是否还记得？\u200b',
 'play': '74195',
 'songs': '90',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7636462655> (referer: None)
2024-11-11 17:42:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9976270592> (referer: None)
2024-11-11 17:42:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7593579587> (referer: None)
2024-11-11 17:42:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12313270614> (referer: None)
2024-11-11 17:42:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=10115027923> (referer: None)
2024-11-11 17:42:03 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2',
 'description': '介绍：2015经典歌曲精选',
 'play': '60716',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8497844200>
{'collection': '播放',
 'comments': '2',
 'description': '介绍：2015经典歌曲精选',
 'play': '60716',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:03 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '69',
 'description': '介绍：韩红，中国内地流行乐女歌手、音乐人 '
                '、公益志愿者、导演、主持人，全国政协委员，国家一级演员，中国宋庆龄基金会理事等。她凭借宛若天籁的声线和独具风格的词曲创作赢得了众多歌迷的青睐。',
 'play': '278114',
 'songs': '56',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7568132458>
{'collection': '播放',
 'comments': '69',
 'description': '介绍：韩红，中国内地流行乐女歌手、音乐人 '
                '、公益志愿者、导演、主持人，全国政协委员，国家一级演员，中国宋庆龄基金会理事等。她凭借宛若天籁的声线和独具风格的词曲创作赢得了众多歌迷的青睐。',
 'play': '278114',
 'songs': '56',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:03 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '5',
 'description': '介绍：杜德伟，华语流行乐男歌手、音乐人。1985年从加拿大留学归来，参加香港第四届新秀歌唱比赛获得冠军，随后进入演艺圈，签约华星唱片。',
 'play': '81352',
 'songs': '41',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7597314544>
{'collection': '播放',
 'comments': '5',
 'description': '介绍：杜德伟，华语流行乐男歌手、音乐人。1985年从加拿大留学归来，参加香港第四届新秀歌唱比赛获得冠军，随后进入演艺圈，签约华星唱片。',
 'play': '81352',
 'songs': '41',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:04 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '12',
 'description': '介绍：炽热的青春，从不退后，一往无前！直到我昨晚梦见你才明白听《我们的爱》的情景梦里我也知道你结婚了还给你脑补出了一个儿子梦里的你依然很优秀我也依然很爱你在无意识状态 '
                '我发现内心深处比清醒的时候更喜欢你回不去了我的爱在光年之外',
 'play': '916510',
 'songs': '185',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:42:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9680703509>
{'collection': '播放',
 'comments': '12',
 'description': '介绍：炽热的青春，从不退后，一往无前！直到我昨晚梦见你才明白听《我们的爱》的情景梦里我也知道你结婚了还给你脑补出了一个儿子梦里的你依然很优秀我也依然很爱你在无意识状态 '
                '我发现内心深处比清醒的时候更喜欢你回不去了我的爱在光年之外',
 'play': '916510',
 'songs': '185',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:42:04 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '7',
 'description': '介绍：任贤齐，华语流行乐男歌手、影视演员、词曲创作人、导演、赛车手。1991年因出演电影《官兵捉强盗》进入影视圈。1996年发行的专辑《心太软》创下2600万张的销售记录，凭借专辑同名主打歌《心太软》成名。',
 'play': '415735',
 'songs': '45',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7596856116>
{'collection': '播放',
 'comments': '7',
 'description': '介绍：任贤齐，华语流行乐男歌手、影视演员、词曲创作人、导演、赛车手。1991年因出演电影《官兵捉强盗》进入影视圈。1996年发行的专辑《心太软》创下2600万张的销售记录，凭借专辑同名主打歌《心太软》成名。',
 'play': '415735',
 'songs': '45',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12640145521> (referer: None)
2024-11-11 17:42:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12588251660> (referer: None)
2024-11-11 17:42:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=10180263776> (referer: None)
2024-11-11 17:42:04 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '88',
 'description': '介绍：中国大陆流行女歌手。2007年《比天空还远》EP '
                '第八届音乐⻛云榜“最佳女歌手”、“最佳唱作人”、“最佳作曲”、“最佳作词”等五项提名。“最佳唱作人”、“最佳作曲”两项大奖。',
 'play': '246244',
 'songs': '58',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7636462655>
{'collection': '播放',
 'comments': '88',
 'description': '介绍：中国大陆流行女歌手。2007年《比天空还远》EP '
                '第八届音乐⻛云榜“最佳女歌手”、“最佳唱作人”、“最佳作曲”、“最佳作词”等五项提名。“最佳唱作人”、“最佳作曲”两项大奖。',
 'play': '246244',
 'songs': '58',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:04 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '20',
 'description': '介绍：车载流行实力派嗓音，任素汐陈楚生周深毛不易林俊杰汪苏泷等，总有一首能唱进你心里，欢迎收藏，感谢聆听',
 'play': '640985',
 'songs': '142',
 'tag': '华语-流行-驾车',
 'title': '无标题'}
2024-11-11 17:42:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9976270592>
{'collection': '播放',
 'comments': '20',
 'description': '介绍：车载流行实力派嗓音，任素汐陈楚生周深毛不易林俊杰汪苏泷等，总有一首能唱进你心里，欢迎收藏，感谢聆听',
 'play': '640985',
 'songs': '142',
 'tag': '华语-流行-驾车',
 'title': '无标题'}
2024-11-11 17:42:04 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '51',
 'description': '介绍：黄子韬，1993年5月2日出生于山东省青岛市，中国内地男歌手、演员、主持人。2011年12月，黄子韬以TAO为艺名公开武术视频，首次公开亮相。2012年4月，出席第12届音乐风云榜颁奖典礼，正式出道。',
 'play': '63704',
 'songs': '40',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7593579587>
{'collection': '播放',
 'comments': '51',
 'description': '介绍：黄子韬，1993年5月2日出生于山东省青岛市，中国内地男歌手、演员、主持人。2011年12月，黄子韬以TAO为艺名公开武术视频，首次公开亮相。2012年4月，出席第12届音乐风云榜颁奖典礼，正式出道。',
 'play': '63704',
 'songs': '40',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:42:04 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：天赐的声音|音综封神舞台live，每一首都值得反复聆听，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏感谢聆听',
 'play': '169716',
 'songs': '52',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:42:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12313270614>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：天赐的声音|音综封神舞台live，每一首都值得反复聆听，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏感谢聆听',
 'play': '169716',
 'songs': '52',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:42:04 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '11',
 'description': '介绍：天赐的声音历届金曲舞台live盘点，如果可以，若月亮没来，字字句句等火遍全网的歌曲都在这里，你最爱哪位歌手的作品，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '756897',
 'songs': '64',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:42:04 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=10115027923>
{'collection': '播放',
 'comments': '11',
 'description': '介绍：天赐的声音历届金曲舞台live盘点，如果可以，若月亮没来，字字句句等火遍全网的歌曲都在这里，你最爱哪位歌手的作品，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '756897',
 'songs': '64',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:42:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12706578179> (referer: None)
2024-11-11 17:42:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12683398712> (referer: None)
2024-11-11 17:42:05 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：华语R&B|陶喆/方大同/余佳运/王力宏，华语r&b精选，开启你的旅途好心情',
 'play': '3707',
 'songs': '80',
 'tag': '华语-R&B/Soul-旅行',
 'title': '无标题'}
2024-11-11 17:42:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12640145521>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：华语R&B|陶喆/方大同/余佳运/王力宏，华语r&b精选，开启你的旅途好心情',
 'play': '3707',
 'songs': '80',
 'tag': '华语-R&B/Soul-旅行',
 'title': '无标题'}
2024-11-11 17:42:05 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：在这宽阔的道路上，尽情感受操控的乐趣和自由的脉搏。让每一个转弯都成为难忘的瞬间，让每一次加速都成为激情的释放。',
 'play': '2800',
 'songs': '41',
 'tag': '华语-驾车-放松',
 'title': '无标题'}
2024-11-11 17:42:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12588251660>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：在这宽阔的道路上，尽情感受操控的乐趣和自由的脉搏。让每一个转弯都成为难忘的瞬间，让每一次加速都成为激情的释放。',
 'play': '2800',
 'songs': '41',
 'tag': '华语-驾车-放松',
 'title': '无标题'}
2024-11-11 17:42:05 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：盘点声生不息，那些让人头皮发麻的live，每一首都华语顶级实力派歌手的用心演绎，直击心灵，欢迎收藏，感谢聆听',
 'play': '163949',
 'songs': '69',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:42:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=10180263776>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：盘点声生不息，那些让人头皮发麻的live，每一首都华语顶级实力派歌手的用心演绎，直击心灵，欢迎收藏，感谢聆听',
 'play': '163949',
 'songs': '69',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:42:05 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '44',
 'description': '介绍：《有歌2024》是一档专注于华语音乐发展的的节目，以“寻找华语乐坛下一首大热金曲”为核心主旨。节目由李宇春、汪苏泷、蔡健雅等专业音乐人组成常驻“寻歌官”，并在每期邀请飞行“寻歌官”一起深挖原创佳作，围绕新作品、好作品进行改编提升。在这个舞台上，乐坛前辈与年轻新生代音乐人携手并肩，共同努力，致力打造下一首华语乐坛品质好歌，全力寻找华语乐坛新一代品质金曲。每周五20：20节目音频上线云村，山海不阻，热爱让音乐不将就！',
 'play': '109446',
 'songs': '30',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:42:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12706578179>
{'collection': '播放',
 'comments': '44',
 'description': '介绍：《有歌2024》是一档专注于华语音乐发展的的节目，以“寻找华语乐坛下一首大热金曲”为核心主旨。节目由李宇春、汪苏泷、蔡健雅等专业音乐人组成常驻“寻歌官”，并在每期邀请飞行“寻歌官”一起深挖原创佳作，围绕新作品、好作品进行改编提升。在这个舞台上，乐坛前辈与年轻新生代音乐人携手并肩，共同努力，致力打造下一首华语乐坛品质好歌，全力寻找华语乐坛新一代品质金曲。每周五20：20节目音频上线云村，山海不阻，热爱让音乐不将就！',
 'play': '109446',
 'songs': '30',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:42:05 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：开车必须要有个好歌单！走进这首首深情旋律 '
                '穿越不同时代的温暖声音在悠长的时光河中为你轻轻响起带来一段温馨而忧郁的陪伴旅程',
 'play': '5597',
 'songs': '107',
 'tag': '流行-华语-R&B/Soul',
 'title': '无标题'}
2024-11-11 17:42:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12683398712>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：开车必须要有个好歌单！走进这首首深情旋律 '
                '穿越不同时代的温暖声音在悠长的时光河中为你轻轻响起带来一段温馨而忧郁的陪伴旅程',
 'play': '5597',
 'songs': '107',
 'tag': '流行-华语-R&B/Soul',
 'title': '无标题'}
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:42:05 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:43:29 [scrapy.extensions.logstats] INFO: Crawled 161 pages (at 16 pages/min), scraped 113 items (at 16 items/min)
2024-11-11 17:43:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6845897480> (referer: None)
2024-11-11 17:43:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8402855265> (referer: None)
2024-11-11 17:43:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6957296439> (referer: None)
2024-11-11 17:43:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7403030418> (referer: None)
2024-11-11 17:43:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6847249919> (referer: None)
2024-11-11 17:43:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=924680166> (referer: None)
2024-11-11 17:43:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7572518150> (referer: None)
2024-11-11 17:43:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8376978101> (referer: None)
2024-11-11 17:43:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '268',
 'description': '介绍：让旧时的CD，唱出喜怒哀乐，和所有难忘的记忆',
 'play': '25070944',
 'songs': '187',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6845897480>
{'collection': '播放',
 'comments': '268',
 'description': '介绍：让旧时的CD，唱出喜怒哀乐，和所有难忘的记忆',
 'play': '25070944',
 'songs': '187',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '254',
 'description': '介绍：东西南北中，各路Rapper齐相聚！“中文说唱超级联赛” '
                '正式打响，《中国说唱巅峰对决2023》音频现已登陆云村，每周六18点音频上线。收听巅峰音频，与云村homie聊聊真Hip-Hop！',
 'play': '3497600',
 'songs': '142',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8402855265>
{'collection': '播放',
 'comments': '254',
 'description': '介绍：东西南北中，各路Rapper齐相聚！“中文说唱超级联赛” '
                '正式打响，《中国说唱巅峰对决2023》音频现已登陆云村，每周六18点音频上线。收听巅峰音频，与云村homie聊聊真Hip-Hop！',
 'play': '3497600',
 'songs': '142',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9251843597> (referer: None)
2024-11-11 17:43:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8804782200> (referer: None)
2024-11-11 17:43:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8497878200> (referer: None)
2024-11-11 17:43:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8484246204> (referer: None)
2024-11-11 17:43:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '6',
 'description': '介绍：1999年经典歌曲精选',
 'play': '604412',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6957296439>
{'collection': '播放',
 'comments': '6',
 'description': '介绍：1999年经典歌曲精选',
 'play': '604412',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '28',
 'description': '介绍：眼泪一定会随着时间慢慢蒸发消失不见',
 'play': '407171',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7403030418>
{'collection': '播放',
 'comments': '28',
 'description': '介绍：眼泪一定会随着时间慢慢蒸发消失不见',
 'play': '407171',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '3',
 'description': '介绍：炫目的灯光、 强烈的节奏、 喧闹的人群、 花哨的服装.... 风靡当年的劲歌热舞仍在 '
                '是时候再来回味一下往日的潇洒了！',
 'play': '139056',
 'songs': '95',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6847249919>
{'collection': '播放',
 'comments': '3',
 'description': '介绍：炫目的灯光、 强烈的节奏、 喧闹的人群、 花哨的服装.... 风靡当年的劲歌热舞仍在 '
                '是时候再来回味一下往日的潇洒了！',
 'play': '139056',
 'songs': '95',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '60265',
 'description': '介绍：优质华语新歌，网易云音乐每周精选推荐。本期封面：陈奕迅',
 'play': '1088548992',
 'songs': '20',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=924680166>
{'collection': '播放',
 'comments': '60265',
 'description': '介绍：优质华语新歌，网易云音乐每周精选推荐。本期封面：陈奕迅',
 'play': '1088548992',
 'songs': '20',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '47',
 'description': '介绍：攒起甜蜜的小心思，听着冒出粉红泡泡的歌曲，跨越银河，也要来见你。',
 'play': '2787747',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7572518150>
{'collection': '播放',
 'comments': '47',
 'description': '介绍：攒起甜蜜的小心思，听着冒出粉红泡泡的歌曲，跨越银河，也要来见你。',
 'play': '2787747',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12371765641> (referer: None)
2024-11-11 17:43:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8484246201> (referer: None)
2024-11-11 17:43:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12657710629> (referer: None)
2024-11-11 17:43:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9364024209> (referer: None)
2024-11-11 17:43:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '149',
 'description': '介绍：《伍六七》是由啊哈时光与小疯映画联合出品的原创动画作品。《伍六七》动画内的原声音乐由啊哈时光旗下厂牌啊哈音乐独家策划并发行。',
 'play': '284002',
 'songs': '65',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8376978101>
{'collection': '播放',
 'comments': '149',
 'description': '介绍：《伍六七》是由啊哈时光与小疯映画联合出品的原创动画作品。《伍六七》动画内的原声音乐由啊哈时光旗下厂牌啊哈音乐独家策划并发行。',
 'play': '284002',
 'songs': '65',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '9',
 'description': '介绍：充电进行中',
 'play': '214652',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9251843597>
{'collection': '播放',
 'comments': '9',
 'description': '介绍：充电进行中',
 'play': '214652',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '6',
 'description': '介绍：呼喊明天与自由的声音 追寻心底赤诚的理想',
 'play': '124442',
 'songs': '63',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8804782200>
{'collection': '播放',
 'comments': '6',
 'description': '介绍：呼喊明天与自由的声音 追寻心底赤诚的理想',
 'play': '124442',
 'songs': '63',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1',
 'description': '介绍：福茂唱片音乐股份有限公司（Linfair Records '
                'Ltd.）是一家台湾唱片公司，曾为环球音乐旗下子公司之一，2002年正式退出环球音乐旗下，成为独立唱片公司',
 'play': '34174',
 'songs': '67',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8484246204>
{'collection': '播放',
 'comments': '1',
 'description': '介绍：福茂唱片音乐股份有限公司（Linfair Records '
                'Ltd.）是一家台湾唱片公司，曾为环球音乐旗下子公司之一，2002年正式退出环球音乐旗下，成为独立唱片公司',
 'play': '34174',
 'songs': '67',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '4',
 'description': '介绍：2012经典歌曲精选',
 'play': '105890',
 'songs': '99',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8497878200>
{'collection': '播放',
 'comments': '4',
 'description': '介绍：2012经典歌曲精选',
 'play': '105890',
 'songs': '99',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:31 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：精选热门华语流行歌曲 从热门单曲到耳熟能详的流行金曲 陪你度过每一个游戏精彩时刻',
 'play': '257187',
 'songs': '70',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12371765641>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：精选热门华语流行歌曲 从热门单曲到耳熟能详的流行金曲 陪你度过每一个游戏精彩时刻',
 'play': '257187',
 'songs': '70',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:31 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2',
 'description': '介绍：听见滚石时光经典。',
 'play': '70827',
 'songs': '80',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8484246201>
{'collection': '播放',
 'comments': '2',
 'description': '介绍：听见滚石时光经典。',
 'play': '70827',
 'songs': '80',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:31 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '3',
 'description': '介绍：敲好汀的华语浪漫R&B！别人一起听歌：（暧昧）（歌词暗示）（蜜里调油）我一起听歌：不行我必须让你见识一下世界第一的歌品 '
                '我真的急了',
 'play': '21557',
 'songs': '49',
 'tag': '华语-流行-R&B/Soul',
 'title': '无标题'}
2024-11-11 17:43:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12657710629>
{'collection': '播放',
 'comments': '3',
 'description': '介绍：敲好汀的华语浪漫R&B！别人一起听歌：（暧昧）（歌词暗示）（蜜里调油）我一起听歌：不行我必须让你见识一下世界第一的歌品 '
                '我真的急了',
 'play': '21557',
 'songs': '49',
 'tag': '华语-流行-R&B/Soul',
 'title': '无标题'}
2024-11-11 17:43:31 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：精选热门流行歌曲，让你享受属于你的音乐狂欢！',
 'play': '351881',
 'songs': '67',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9364024209>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：精选热门流行歌曲，让你享受属于你的音乐狂欢！',
 'play': '351881',
 'songs': '67',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:43:31 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:44:57 [scrapy.extensions.logstats] INFO: Crawled 177 pages (at 16 pages/min), scraped 129 items (at 16 items/min)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7371547358> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9286334271> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12339396405> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8201823014> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12231985750> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7051875969> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7505456487> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7840686287> (referer: None)
2024-11-11 17:44:58 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '5',
 'description': '介绍：《为歌而赞第二季》是浙江卫视与抖音联合出品的跨屏互动音乐综艺。节目集结几十组实力歌手与新世代音乐人，以“热歌VS新歌”的形式进行音乐舞台竞演。',
 'play': '120908',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:44:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7371547358>
{'collection': '播放',
 'comments': '5',
 'description': '介绍：《为歌而赞第二季》是浙江卫视与抖音联合出品的跨屏互动音乐综艺。节目集结几十组实力歌手与新世代音乐人，以“热歌VS新歌”的形式进行音乐舞台竞演。',
 'play': '120908',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:44:58 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '13',
 'description': '介绍：《天赐的声音》是浙江卫视推出的音乐励志节目，节目由音乐合伙人寻找音乐中的另一半，每期六组飞行合伙人两两成组合作演唱，一人和常驻音乐合伙人合作共同演绎一首歌曲，进行“推荐金曲争夺战””。正如节目名称一样，无数打动人心的天赐之声倾情演唱，留下了令人回味无穷的舞台佳作，现在就一起来回顾吧。',
 'play': '401716',
 'songs': '124',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:44:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9286334271>
{'collection': '播放',
 'comments': '13',
 'description': '介绍：《天赐的声音》是浙江卫视推出的音乐励志节目，节目由音乐合伙人寻找音乐中的另一半，每期六组飞行合伙人两两成组合作演唱，一人和常驻音乐合伙人合作共同演绎一首歌曲，进行“推荐金曲争夺战””。正如节目名称一样，无数打动人心的天赐之声倾情演唱，留下了令人回味无穷的舞台佳作，现在就一起来回顾吧。',
 'play': '401716',
 'songs': '124',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:44:58 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '10',
 'description': '介绍：音综神级live：一开嗓直击心灵！每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '357141',
 'songs': '98',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:44:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12339396405>
{'collection': '播放',
 'comments': '10',
 'description': '介绍：音综神级live：一开嗓直击心灵！每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '357141',
 'songs': '98',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:44:58 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '46',
 'description': '介绍：《时光音乐会》是由湖南卫视、芒果TV双平台制作的中国首档户外音乐慢音综，是一场时代歌手的顶级聚会。两季时光音乐会的音频全部收录其中，有哪首能够唤起你记忆中那些年呢？',
 'play': '1534348',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:44:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8201823014>
{'collection': '播放',
 'comments': '46',
 'description': '介绍：《时光音乐会》是由湖南卫视、芒果TV双平台制作的中国首档户外音乐慢音综，是一场时代歌手的顶级聚会。两季时光音乐会的音频全部收录其中，有哪首能够唤起你记忆中那些年呢？',
 'play': '1534348',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:44:58 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '40',
 'description': '介绍：《天赐的声音》是浙江卫视推出的音乐励志节目，节目由音乐合伙人寻找音乐中的另一半，每期六组飞行合伙人两两成组合作演唱，一人和常驻音乐合伙人合作共同演绎一首歌曲，进行“推荐金曲争夺战”。正如节目名称一样，无数打动人心的天赐之声倾情演唱，留下了令人回味无穷的舞台佳作，现在就一起来回顾吧！',
 'play': '1162297',
 'songs': '73',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:44:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12231985750>
{'collection': '播放',
 'comments': '40',
 'description': '介绍：《天赐的声音》是浙江卫视推出的音乐励志节目，节目由音乐合伙人寻找音乐中的另一半，每期六组飞行合伙人两两成组合作演唱，一人和常驻音乐合伙人合作共同演绎一首歌曲，进行“推荐金曲争夺战”。正如节目名称一样，无数打动人心的天赐之声倾情演唱，留下了令人回味无穷的舞台佳作，现在就一起来回顾吧！',
 'play': '1162297',
 'songs': '73',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12595925247> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12643750583> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12541082075> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12655464916> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12689581696> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12615758496> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12674370601> (referer: None)
2024-11-11 17:44:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12632193454> (referer: None)
2024-11-11 17:44:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '15',
 'description': '介绍：《中国新说唱》是爱奇艺自制华语青年说唱音乐系列节目。中国第一个以“剧集式”叙事理念制作的真人秀节目，也是一档华语青年说唱音乐真人秀。这档节目用年轻人的语态承载主流价值观，传播富有青年文化特色的正能量。',
 'play': '245866',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:44:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7051875969>
{'collection': '播放',
 'comments': '15',
 'description': '介绍：《中国新说唱》是爱奇艺自制华语青年说唱音乐系列节目。中国第一个以“剧集式”叙事理念制作的真人秀节目，也是一档华语青年说唱音乐真人秀。这档节目用年轻人的语态承载主流价值观，传播富有青年文化特色的正能量。',
 'play': '245866',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:44:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '101',
 'description': '介绍：本季新说唱将组成四大联盟，为团队荣誉而战。通过最专业的中文说唱舞台竞演，聚焦华语顶尖说唱音乐，带领观众享受极致的说唱音乐舞台，重塑华语乐坛说唱音乐的“巅峰”之境，打造中文说唱“梦之队”。',
 'play': '3007287',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:44:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7505456487>
{'collection': '播放',
 'comments': '101',
 'description': '介绍：本季新说唱将组成四大联盟，为团队荣誉而战。通过最专业的中文说唱舞台竞演，聚焦华语顶尖说唱音乐，带领观众享受极致的说唱音乐舞台，重塑华语乐坛说唱音乐的“巅峰”之境，打造中文说唱“梦之队”。',
 'play': '3007287',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:44:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '63',
 'description': '介绍：本歌单收录《我们民谣2022》节目内容音频~在城市烟火气里，用音乐治愈人心。29组会生活有表达的音乐人，齐聚烟火长沙。用民谣唱生活故事，共同呈现五场民谣音乐盛会，诞生观众最喜爱的年度TOP5音乐人。',
 'play': '1140088',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:44:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7840686287>
{'collection': '播放',
 'comments': '63',
 'description': '介绍：本歌单收录《我们民谣2022》节目内容音频~在城市烟火气里，用音乐治愈人心。29组会生活有表达的音乐人，齐聚烟火长沙。用民谣唱生活故事，共同呈现五场民谣音乐盛会，诞生观众最喜爱的年度TOP5音乐人。',
 'play': '1140088',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:44:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：久听不讨厌，你爱的歌 '
                '，值得反复聆听，热门情歌，收藏你的最爱歌，经典新老歌曲，每一首歌有你的故事，希望你们，收藏起来!歌单制作；新疆RaZeL哥封面来源；网络歌单更新；每日更新请注意; '
                '歌单不要模仿\u200b勿侵；欢迎收藏，关注 ！',
 'play': '2560',
 'songs': '156',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:44:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12595925247>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：久听不讨厌，你爱的歌 '
                '，值得反复聆听，热门情歌，收藏你的最爱歌，经典新老歌曲，每一首歌有你的故事，希望你们，收藏起来!歌单制作；新疆RaZeL哥封面来源；网络歌单更新；每日更新请注意; '
                '歌单不要模仿\u200b勿侵；欢迎收藏，关注 ！',
 'play': '2560',
 'songs': '156',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:44:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：封神音综：顶级编唱神仙都沦陷！每一首都是顶级实力派歌手的用心演绎，白月光级别的存在，欢迎收藏，感谢聆听',
 'play': '94603',
 'songs': '86',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:44:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12541082075>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：封神音综：顶级编唱神仙都沦陷！每一首都是顶级实力派歌手的用心演绎，白月光级别的存在，欢迎收藏，感谢聆听',
 'play': '94603',
 'songs': '86',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:44:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：我们已不在年轻，你还记得校园岁月的那些往事吗，那里有你的同学，老师，恋人，初恋。可能有的现在还联系着，有的分开了，有的也组成了家庭。时光流逝，岁月匆匆，歌单选取了那些校园时期的流行歌曲，跟着歌声来回忆下那段回不去的青葱岁月把。网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.9.28歌單完善: 2024.10.3歌單製作: 莣情歌單封面: 来源于网络侵删',
 'play': '1649',
 'songs': '54',
 'tag': '流行-华语-校园',
 'title': '无标题'}
2024-11-11 17:44:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12655464916>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：我们已不在年轻，你还记得校园岁月的那些往事吗，那里有你的同学，老师，恋人，初恋。可能有的现在还联系着，有的分开了，有的也组成了家庭。时光流逝，岁月匆匆，歌单选取了那些校园时期的流行歌曲，跟着歌声来回忆下那段回不去的青葱岁月把。网易云音乐·发现好音樂------------------------------------------------------------本歌单都是精挑细选给大家分享的！希望大家能喜欢!来都来了，点个收藏再走呗！歌單創建: '
                '2024.9.28歌單完善: 2024.10.3歌單製作: 莣情歌單封面: 来源于网络侵删',
 'play': '1649',
 'songs': '54',
 'tag': '流行-华语-校园',
 'title': '无标题'}
2024-11-11 17:44:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2',
 'description': '介绍：有没有那么一首歌，让你一听就能回到那个纯真的年代？今天，就来给大家种草一些我心中的回忆杀经典老歌，让我们一起重温那些美好的时光吧！',
 'play': '236429',
 'songs': '202',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
2024-11-11 17:44:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12643750583>
{'collection': '播放',
 'comments': '2',
 'description': '介绍：有没有那么一首歌，让你一听就能回到那个纯真的年代？今天，就来给大家种草一些我心中的回忆杀经典老歌，让我们一起重温那些美好的时光吧！',
 'play': '236429',
 'songs': '202',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
2024-11-11 17:44:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：这个世界从来都不公平，你只有努力，才能换来平等的待遇。收录国语励志歌曲，希望你们能跨过困难，遇见更好的自己。',
 'play': '952',
 'songs': '35',
 'tag': '华语-流行-快乐',
 'title': '无标题'}
2024-11-11 17:44:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12689581696>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：这个世界从来都不公平，你只有努力，才能换来平等的待遇。收录国语励志歌曲，希望你们能跨过困难，遇见更好的自己。',
 'play': '952',
 'songs': '35',
 'tag': '华语-流行-快乐',
 'title': '无标题'}
2024-11-11 17:44:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：单依纯周深张碧晨陈楚生薛之谦汪苏泷，满满的感动，好听到停不下来，每一首都好听，你最爱哪位歌手的作品',
 'play': '69391',
 'songs': '119',
 'tag': '华语-流行-感动',
 'title': '无标题'}
2024-11-11 17:44:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12615758496>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：单依纯周深张碧晨陈楚生薛之谦汪苏泷，满满的感动，好听到停不下来，每一首都好听，你最爱哪位歌手的作品',
 'play': '69391',
 'songs': '119',
 'tag': '华语-流行-感动',
 'title': '无标题'}
2024-11-11 17:44:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：天赐的声音：神仙打架的顶级live，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '9931',
 'songs': '40',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:44:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12674370601>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：天赐的声音：神仙打架的顶级live，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '9931',
 'songs': '40',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:44:59 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1',
 'description': '介绍：华语顶级嗓：单依纯 张碧晨 刘惜君 郁可唯，女神嗓音每一首都好好听，你最爱哪位歌手，欢迎评论区留言',
 'play': '125704',
 'songs': '88',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:44:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12632193454>
{'collection': '播放',
 'comments': '1',
 'description': '介绍：华语顶级嗓：单依纯 张碧晨 刘惜君 郁可唯，女神嗓音每一首都好好听，你最爱哪位歌手，欢迎评论区留言',
 'play': '125704',
 'songs': '88',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:44:59 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:46:23 [scrapy.extensions.logstats] INFO: Crawled 193 pages (at 16 pages/min), scraped 145 items (at 16 items/min)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6845897480> (referer: None)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=919939187> (referer: None)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=2312165875> (referer: None)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8294817780> (referer: None)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=2143660964> (referer: None)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8232519802> (referer: None)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6686195351> (referer: None)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7049395408> (referer: None)
2024-11-11 17:46:23 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '268',
 'description': '介绍：让旧时的CD，唱出喜怒哀乐，和所有难忘的记忆',
 'play': '25070996',
 'songs': '187',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:46:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6845897480>
{'collection': '播放',
 'comments': '268',
 'description': '介绍：让旧时的CD，唱出喜怒哀乐，和所有难忘的记忆',
 'play': '25070996',
 'songs': '187',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:46:23 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '826',
 'description': '介绍：想开那么一家茶馆，过往的人能暂且休憩，安放内心深处难以释怀的感情，听那么一首民谣，想想从前，想起了曾爱过的姑娘。当这杯茶落在你面前，是否这袅袅升起的热气，能忆起你容颜。让民谣与记忆叙个旧吧。',
 'play': '18193206',
 'songs': '29',
 'tag': '华语-民谣-治愈',
 'title': '无标题'}
2024-11-11 17:46:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=919939187>
{'collection': '播放',
 'comments': '826',
 'description': '介绍：想开那么一家茶馆，过往的人能暂且休憩，安放内心深处难以释怀的感情，听那么一首民谣，想想从前，想起了曾爱过的姑娘。当这杯茶落在你面前，是否这袅袅升起的热气，能忆起你容颜。让民谣与记忆叙个旧吧。',
 'play': '18193206',
 'songs': '29',
 'tag': '华语-民谣-治愈',
 'title': '无标题'}
2024-11-11 17:46:23 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1021',
 'description': '介绍：民谣是最安静的角落，民谣是一种诉说，包含了一种朴素的情感，在听的过程中可能会与自己的故事契合，产生共鸣，100首华语民谣，因为懂得才有共鸣。',
 'play': '51762764',
 'songs': '99',
 'tag': '华语-流行-民谣',
 'title': '无标题'}
2024-11-11 17:46:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=2312165875>
{'collection': '播放',
 'comments': '1021',
 'description': '介绍：民谣是最安静的角落，民谣是一种诉说，包含了一种朴素的情感，在听的过程中可能会与自己的故事契合，产生共鸣，100首华语民谣，因为懂得才有共鸣。',
 'play': '51762764',
 'songs': '99',
 'tag': '华语-流行-民谣',
 'title': '无标题'}
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8775729080> (referer: None)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8497873200> (referer: None)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8899456168> (referer: None)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8912074743> (referer: None)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9116503856> (referer: None)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8804782200> (referer: None)
2024-11-11 17:46:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8672228634> (referer: None)
2024-11-11 17:46:23 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '22',
 'description': '介绍：在微醺中 把自己还给自己酒杯里有今天的情绪 '
                '也有明天的期许是不是每个人喝了酒都会变得更浪漫如果有相似风格的歌可以在评论区推荐噢！',
 'play': '8367168',
 'songs': '126',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
2024-11-11 17:46:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8294817780>
{'collection': '播放',
 'comments': '22',
 'description': '介绍：在微醺中 把自己还给自己酒杯里有今天的情绪 '
                '也有明天的期许是不是每个人喝了酒都会变得更浪漫如果有相似风格的歌可以在评论区推荐噢！',
 'play': '8367168',
 'songs': '126',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
2024-11-11 17:46:23 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '64',
 'description': '介绍：雷⿁是早期⽛买加的流⾏⾳乐之⼀，由斯卡(Ska)和洛克斯代迪(Rock '
                'Steady)⾳乐演变⽽来，它不仅融合了美国节奏蓝调的抒情曲风，同时还加⼊了拉丁⾳乐的热情。另外，雷⿁⼗分强调vocal的部份，不论是独唱或合唱，通常它是运⽤吟唱的⽅式来表现，并且藉由吉他、打击乐器、电⼦琴或其他乐器带出主要的旋律和节奏。⽽在雷⿁乐当中，电贝斯占了相当重要的⽐例!雷⿁乐是属于四四拍的⾳乐，重⾳落在 '
                '第⼆和第四拍。从⾳乐中⼤⿎的部份，我们可以清楚的听出⼀个明显的节奏和固定的旋律线。拥有⾃成⼀派、懒洋洋的独特节奏。国内雷鬼在上世纪80年代便已出现，而后崔健、窦唯等创作人尝试了这种风格的演绎，如今有更多的年轻血液去探索这样一种独特的唱作风格，探索雷鬼，而不拘于雷鬼，即使雷鬼乐在国内并不是很成熟，但音乐多元化才是我们听众所要追求的，当然，如果你想听纯正的雷鬼乐，你可以先听听它的缔造者，Bob '
                'Marley的作品，相信我，你会发现一个新世界～歌曲排列随机整理by仲冬二二',
 'play': '1870043',
 'songs': '85',
 'tag': '华语-雷鬼',
 'title': '无标题'}
2024-11-11 17:46:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=2143660964>
{'collection': '播放',
 'comments': '64',
 'description': '介绍：雷⿁是早期⽛买加的流⾏⾳乐之⼀，由斯卡(Ska)和洛克斯代迪(Rock '
                'Steady)⾳乐演变⽽来，它不仅融合了美国节奏蓝调的抒情曲风，同时还加⼊了拉丁⾳乐的热情。另外，雷⿁⼗分强调vocal的部份，不论是独唱或合唱，通常它是运⽤吟唱的⽅式来表现，并且藉由吉他、打击乐器、电⼦琴或其他乐器带出主要的旋律和节奏。⽽在雷⿁乐当中，电贝斯占了相当重要的⽐例!雷⿁乐是属于四四拍的⾳乐，重⾳落在 '
                '第⼆和第四拍。从⾳乐中⼤⿎的部份，我们可以清楚的听出⼀个明显的节奏和固定的旋律线。拥有⾃成⼀派、懒洋洋的独特节奏。国内雷鬼在上世纪80年代便已出现，而后崔健、窦唯等创作人尝试了这种风格的演绎，如今有更多的年轻血液去探索这样一种独特的唱作风格，探索雷鬼，而不拘于雷鬼，即使雷鬼乐在国内并不是很成熟，但音乐多元化才是我们听众所要追求的，当然，如果你想听纯正的雷鬼乐，你可以先听听它的缔造者，Bob '
                'Marley的作品，相信我，你会发现一个新世界～歌曲排列随机整理by仲冬二二',
 'play': '1870043',
 'songs': '85',
 'tag': '华语-雷鬼',
 'title': '无标题'}
2024-11-11 17:46:23 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '21',
 'description': '介绍：细心聆听那些触动你内心的华语伤感女声。',
 'play': '2820380',
 'songs': '69',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:46:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8232519802>
{'collection': '播放',
 'comments': '21',
 'description': '介绍：细心聆听那些触动你内心的华语伤感女声。',
 'play': '2820380',
 'songs': '69',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:46:24 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '30',
 'description': '介绍：无论你是摇滚乐迷 还是想要尝试新的音乐风格 都请一起来尽情感受流行摇滚青春的力量和激情',
 'play': '908987',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:46:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6686195351>
{'collection': '播放',
 'comments': '30',
 'description': '介绍：无论你是摇滚乐迷 还是想要尝试新的音乐风格 都请一起来尽情感受流行摇滚青春的力量和激情',
 'play': '908987',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:46:24 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '6',
 'description': '介绍：本歌单收录《草莓星球来的人》节目音频。《草莓星球来的人》是优酷、摩登天空、大麦、沐光时代联合推出的户外音乐竞演真人秀。节目由池子担任节目MC及安可团成员，张亚东、GAI、萧敬腾担任安可团成员。',
 'play': '38348',
 'songs': '96',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:46:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7049395408>
{'collection': '播放',
 'comments': '6',
 'description': '介绍：本歌单收录《草莓星球来的人》节目音频。《草莓星球来的人》是优酷、摩登天空、大麦、沐光时代联合推出的户外音乐竞演真人秀。节目由池子担任节目MC及安可团成员，张亚东、GAI、萧敬腾担任安可团成员。',
 'play': '38348',
 'songs': '96',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:46:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12619965468> (referer: None)
2024-11-11 17:46:24 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '26',
 'description': '介绍：这个歌单是专为喜欢国语R&B流行音乐的朋友们精心挑选的。从经典的老歌到最新的热门单曲，涵盖了华语乐坛最具代表性的R&B风格作品。这个歌单旨在让您在忙碌的生活中找到一丝宁静与愉悦，感受R&B音乐的魅力。在这个歌单中，您可以欣赏到许多脍炙人口的经典之作，如陶喆的《普通朋友》、《飞机场的十点半》等，以及方大同的《小小虫》、《Love '
                'song》等。此外，还有一些典型的流行歌手尝试的r&b歌曲，如陈奕迅《爱是一本书》，陈小春的《0932》还有许多新生代歌手的代表作品，以及r&b新声代代表余佳运，Matt吕彦良等人的歌曲。不仅旋律优美，歌词深入人心，更是R&B音乐风格的典范。希望您在聆听这些美妙旋律的同时，也能感受到华语R&B流行音乐的独特魅力和丰富内涵。快来加入这个歌单，一起沉浸在国语R&B流行音乐的世界中吧！',
 'play': '602774',
 'songs': '114',
 'tag': '华语-R&B/Soul-蓝调',
 'title': '无标题'}
2024-11-11 17:46:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8775729080>
{'collection': '播放',
 'comments': '26',
 'description': '介绍：这个歌单是专为喜欢国语R&B流行音乐的朋友们精心挑选的。从经典的老歌到最新的热门单曲，涵盖了华语乐坛最具代表性的R&B风格作品。这个歌单旨在让您在忙碌的生活中找到一丝宁静与愉悦，感受R&B音乐的魅力。在这个歌单中，您可以欣赏到许多脍炙人口的经典之作，如陶喆的《普通朋友》、《飞机场的十点半》等，以及方大同的《小小虫》、《Love '
                'song》等。此外，还有一些典型的流行歌手尝试的r&b歌曲，如陈奕迅《爱是一本书》，陈小春的《0932》还有许多新生代歌手的代表作品，以及r&b新声代代表余佳运，Matt吕彦良等人的歌曲。不仅旋律优美，歌词深入人心，更是R&B音乐风格的典范。希望您在聆听这些美妙旋律的同时，也能感受到华语R&B流行音乐的独特魅力和丰富内涵。快来加入这个歌单，一起沉浸在国语R&B流行音乐的世界中吧！',
 'play': '602774',
 'songs': '114',
 'tag': '华语-R&B/Soul-蓝调',
 'title': '无标题'}
2024-11-11 17:46:24 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '4',
 'description': '介绍：2013经典歌曲精选',
 'play': '129920',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:46:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8497873200>
{'collection': '播放',
 'comments': '4',
 'description': '介绍：2013经典歌曲精选',
 'play': '129920',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:46:24 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '16',
 'description': '介绍：顶级女嗓精选，单依纯刘惜君张碧晨郁可唯等，神仙女声一开嗓就惊艳，你最爱哪位神仙姐姐的舞台，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '1433768',
 'songs': '141',
 'tag': '流行-华语-感动',
 'title': '无标题'}
2024-11-11 17:46:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8899456168>
{'collection': '播放',
 'comments': '16',
 'description': '介绍：顶级女嗓精选，单依纯刘惜君张碧晨郁可唯等，神仙女声一开嗓就惊艳，你最爱哪位神仙姐姐的舞台，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '1433768',
 'songs': '141',
 'tag': '流行-华语-感动',
 'title': '无标题'}
2024-11-11 17:46:24 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '31',
 'description': '介绍：想买束花给你送给在城市里总是愣在原地的你很喜欢这种嗓音 像是在军训的时候 大家晚上围在羹火旁 然后有人提议唱歌 '
                '你的crush 毫不犹豫站起来 指了指你 说“唱给她的”',
 'play': '579947',
 'songs': '110',
 'tag': '华语-R&B/Soul-浪漫',
 'title': '无标题'}
2024-11-11 17:46:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8912074743>
{'collection': '播放',
 'comments': '31',
 'description': '介绍：想买束花给你送给在城市里总是愣在原地的你很喜欢这种嗓音 像是在军训的时候 大家晚上围在羹火旁 然后有人提议唱歌 '
                '你的crush 毫不犹豫站起来 指了指你 说“唱给她的”',
 'play': '579947',
 'songs': '110',
 'tag': '华语-R&B/Soul-浪漫',
 'title': '无标题'}
2024-11-11 17:46:24 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '289',
 'description': '介绍：五月天 [ 回到那一天 ] 25周年 '
                '巡回演唱会音乐是时光机回忆是任意门穿越第1天到第9125天你想回到五月天的哪一天？台中站：跨年场演出日期：2023/12/31(日)、2024/1/1(一)－2(二)－5(五)－6(六)－7(日)演出场地：台中洲际棒球场高雄站：无限放大版演出日期：2024/3/23(六)－24(日)－29(五)－30(六)－31(日)演出场地：高雄世运主场馆香港站：五月之约演出日期：2024/4/30(二)、5/3(五)－4(六)－5(日)－7(二)－8(三)－9(四)演出场地：中环海滨活动空间北京站：鸟巢有你 '
                '十全十美演出日期：2024/5/18(六)－19(日)－21(二)－22(三)－24(五)－25(六)－26(日)－30(四)－31(五)、6/1(六)演出场地：国家体育场 '
                '(鸟巢)深圳站：环场夏日版演出日期：2024/7/1(一)－2(二)－3(三)－5(五)－6(六)－7(日)演出场地：深圳大运中心体育场太原站：灿烂夏夜版演出日期：2024/7/31(三)、8/2(五)－3(六)－4(日)演出场地：山西体育中心体育场武汉站：仲夏狂热版演出日期：2024/9/6(五)－7(六)－8(日)－10(二)－11(三)演出场地：武汉体育中心体育场成都站：麻辣环场版演出日期：2024/9/27(五)－28(六)－30(一)、10/4(五)演出场地：成都东安湖体育公园主体育场上海站：绚烂天幕版演出日期：2024/11/10(日)－12(二)－13(三)－15(五)－16(六)－17(日)－19(二)－20(三)－22(五)－23(六)－24(日)演出场地：上海体育场桃园站：新年特别版演出时间：2024/12/28(六)－29(日)—31(二)、2025/1/1(三)—4(六)—5(日)演出场地：乐天桃园棒球场新加坡站：环场·狂欢版演出日期：2025/1/11(六)－12(日)演出场地：新加坡国家体育场',
 'play': '1186177',
 'songs': '56',
 'tag': '华语-流行-摇滚',
 'title': '无标题'}
2024-11-11 17:46:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9116503856>
{'collection': '播放',
 'comments': '289',
 'description': '介绍：五月天 [ 回到那一天 ] 25周年 '
                '巡回演唱会音乐是时光机回忆是任意门穿越第1天到第9125天你想回到五月天的哪一天？台中站：跨年场演出日期：2023/12/31(日)、2024/1/1(一)－2(二)－5(五)－6(六)－7(日)演出场地：台中洲际棒球场高雄站：无限放大版演出日期：2024/3/23(六)－24(日)－29(五)－30(六)－31(日)演出场地：高雄世运主场馆香港站：五月之约演出日期：2024/4/30(二)、5/3(五)－4(六)－5(日)－7(二)－8(三)－9(四)演出场地：中环海滨活动空间北京站：鸟巢有你 '
                '十全十美演出日期：2024/5/18(六)－19(日)－21(二)－22(三)－24(五)－25(六)－26(日)－30(四)－31(五)、6/1(六)演出场地：国家体育场 '
                '(鸟巢)深圳站：环场夏日版演出日期：2024/7/1(一)－2(二)－3(三)－5(五)－6(六)－7(日)演出场地：深圳大运中心体育场太原站：灿烂夏夜版演出日期：2024/7/31(三)、8/2(五)－3(六)－4(日)演出场地：山西体育中心体育场武汉站：仲夏狂热版演出日期：2024/9/6(五)－7(六)－8(日)－10(二)－11(三)演出场地：武汉体育中心体育场成都站：麻辣环场版演出日期：2024/9/27(五)－28(六)－30(一)、10/4(五)演出场地：成都东安湖体育公园主体育场上海站：绚烂天幕版演出日期：2024/11/10(日)－12(二)－13(三)－15(五)－16(六)－17(日)－19(二)－20(三)－22(五)－23(六)－24(日)演出场地：上海体育场桃园站：新年特别版演出时间：2024/12/28(六)－29(日)—31(二)、2025/1/1(三)—4(六)—5(日)演出场地：乐天桃园棒球场新加坡站：环场·狂欢版演出日期：2025/1/11(六)－12(日)演出场地：新加坡国家体育场',
 'play': '1186177',
 'songs': '56',
 'tag': '华语-流行-摇滚',
 'title': '无标题'}
2024-11-11 17:46:24 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '6',
 'description': '介绍：呼喊明天与自由的声音 追寻心底赤诚的理想',
 'play': '124446',
 'songs': '63',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:46:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8804782200>
{'collection': '播放',
 'comments': '6',
 'description': '介绍：呼喊明天与自由的声音 追寻心底赤诚的理想',
 'play': '124446',
 'songs': '63',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:46:24 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '54',
 'description': '介绍：每次看完一本小说心里都空落落的，好像自己也陪他们走过了一生，结局以后的事情我不知道了，但他们的故事还在继续。',
 'play': '1463527',
 'songs': '111',
 'tag': '华语-浪漫-流行',
 'title': '无标题'}
2024-11-11 17:46:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8672228634>
{'collection': '播放',
 'comments': '54',
 'description': '介绍：每次看完一本小说心里都空落落的，好像自己也陪他们走过了一生，结局以后的事情我不知道了，但他们的故事还在继续。',
 'play': '1463527',
 'songs': '111',
 'tag': '华语-浪漫-流行',
 'title': '无标题'}
2024-11-11 17:46:24 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：人生就是生活的过程。哪能没有风没有雨?正是因为有了风雨的洗礼，才能看见斑斓的彩虹；有了失败的痛苦才会尝到成功的喜悦。',
 'play': '868',
 'songs': '33',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:46:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12619965468>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：人生就是生活的过程。哪能没有风没有雨?正是因为有了风雨的洗礼，才能看见斑斓的彩虹；有了失败的痛苦才会尝到成功的喜悦。',
 'play': '868',
 'songs': '33',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:46:24 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:47:49 [scrapy.extensions.logstats] INFO: Crawled 209 pages (at 16 pages/min), scraped 161 items (at 16 items/min)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9671964220> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9502587901> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9964159988> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9220725164> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12330775893> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9487776260> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9337352507> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12269472913> (referer: None)
2024-11-11 17:47:50 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '15',
 'description': '介绍：久听不讨厌，你爱的歌 '
                '，值得反复聆听，热门情歌，收藏你的最爱歌，经典新老歌曲，每一首歌有你的故事，希望你们，收藏起来!歌单制作；新疆RaZeL哥封面来源；网络歌单更新；每日更新请注意; '
                '歌单不要模仿歌单；2024.4.4创建\u200b勿侵；欢迎收藏，关注 ！',
 'play': '1561394',
 'songs': '184',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:47:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9671964220>
{'collection': '播放',
 'comments': '15',
 'description': '介绍：久听不讨厌，你爱的歌 '
                '，值得反复聆听，热门情歌，收藏你的最爱歌，经典新老歌曲，每一首歌有你的故事，希望你们，收藏起来!歌单制作；新疆RaZeL哥封面来源；网络歌单更新；每日更新请注意; '
                '歌单不要模仿歌单；2024.4.4创建\u200b勿侵；欢迎收藏，关注 ！',
 'play': '1561394',
 'songs': '184',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:47:50 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '4',
 'description': '介绍：90后回忆杀，那些年我们追过的偶像剧主题曲精选，每一首都是我们的青春',
 'play': '916337',
 'songs': '81',
 'tag': '华语-影视原声-90后',
 'title': '无标题'}
2024-11-11 17:47:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9502587901>
{'collection': '播放',
 'comments': '4',
 'description': '介绍：90后回忆杀，那些年我们追过的偶像剧主题曲精选，每一首都是我们的青春',
 'play': '916337',
 'songs': '81',
 'tag': '华语-影视原声-90后',
 'title': '无标题'}
2024-11-11 17:47:50 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '10',
 'description': '介绍：国内比较具有代表性的R&B歌手经典歌曲收录：陶喆 方大同 周杰伦 陈奕迅 王力宏 胡彦斌 丁世光 '
                '余佳运……小百科：国内华语流行歌曲中的“节奏布鲁斯”风格发轫于上世纪八十年代，形成于九十年代，并在2000年以来不断发展，充分与华语流行音乐风格特点相结合，在港台流行音乐、内地流行音乐中掀起了一股经久不衰的R&B音乐风格潮流。可以说，节奏布鲁斯是当代我国流行音乐中的主流风格类型，早期在音乐作品中使用节奏布鲁斯的艺人包括有庾澄庆、林忆莲、王菲等歌手九十年代以来则以陶喆、王力宏、周杰伦等歌手为代表，进入新世纪后，华语流行歌曲的风格更加多元，除林俊杰、胡彦斌等歌手外，我们还能从大部分华语流行歌手的音乐作品中寻找到明显的"节奏布鲁斯"音乐风格.那些耳熟能详的华语R&B经典歌曲，你都听过几首？欢迎推荐和补充！',
 'play': '927715',
 'songs': '93',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
2024-11-11 17:47:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9964159988>
{'collection': '播放',
 'comments': '10',
 'description': '介绍：国内比较具有代表性的R&B歌手经典歌曲收录：陶喆 方大同 周杰伦 陈奕迅 王力宏 胡彦斌 丁世光 '
                '余佳运……小百科：国内华语流行歌曲中的“节奏布鲁斯”风格发轫于上世纪八十年代，形成于九十年代，并在2000年以来不断发展，充分与华语流行音乐风格特点相结合，在港台流行音乐、内地流行音乐中掀起了一股经久不衰的R&B音乐风格潮流。可以说，节奏布鲁斯是当代我国流行音乐中的主流风格类型，早期在音乐作品中使用节奏布鲁斯的艺人包括有庾澄庆、林忆莲、王菲等歌手九十年代以来则以陶喆、王力宏、周杰伦等歌手为代表，进入新世纪后，华语流行歌曲的风格更加多元，除林俊杰、胡彦斌等歌手外，我们还能从大部分华语流行歌手的音乐作品中寻找到明显的"节奏布鲁斯"音乐风格.那些耳熟能详的华语R&B经典歌曲，你都听过几首？欢迎推荐和补充！',
 'play': '927715',
 'songs': '93',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
2024-11-11 17:47:50 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '4',
 'description': '介绍：车载顶级治愈，李健周深毛不易单依纯郁可唯，华语顶级嗓音，每一首都能唱进你心里',
 'play': '337443',
 'songs': '121',
 'tag': '华语-驾车-治愈',
 'title': '无标题'}
2024-11-11 17:47:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9220725164>
{'collection': '播放',
 'comments': '4',
 'description': '介绍：车载顶级治愈，李健周深毛不易单依纯郁可唯，华语顶级嗓音，每一首都能唱进你心里',
 'play': '337443',
 'songs': '121',
 'tag': '华语-驾车-治愈',
 'title': '无标题'}
2024-11-11 17:47:50 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2',
 'description': '介绍：《名侦探学院》要做就做南波万有学院主题曲，以及好听的单人歌曲从他们身上我们能学到很多东西，都各自在各自的领域闪闪发光吧',
 'play': '70092',
 'songs': '59',
 'tag': '华语-放松-综艺',
 'title': '无标题'}
2024-11-11 17:47:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12330775893>
{'collection': '播放',
 'comments': '2',
 'description': '介绍：《名侦探学院》要做就做南波万有学院主题曲，以及好听的单人歌曲从他们身上我们能学到很多东西，都各自在各自的领域闪闪发光吧',
 'play': '70092',
 'songs': '59',
 'tag': '华语-放松-综艺',
 'title': '无标题'}
2024-11-11 17:47:50 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2',
 'description': '介绍：许嵩（Vae），1986年5月14日生于安徽省合肥市，中国内地流行乐男歌手、词曲创作人、音乐制作人，现任海蝶音乐公司（现为太合音乐集团）音乐总监，毕业于安徽医科大学。',
 'play': '172547',
 'songs': '159',
 'tag': '华语-流行-网络歌曲',
 'title': '无标题'}
2024-11-11 17:47:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9487776260>
{'collection': '播放',
 'comments': '2',
 'description': '介绍：许嵩（Vae），1986年5月14日生于安徽省合肥市，中国内地流行乐男歌手、词曲创作人、音乐制作人，现任海蝶音乐公司（现为太合音乐集团）音乐总监，毕业于安徽医科大学。',
 'play': '172547',
 'songs': '159',
 'tag': '华语-流行-网络歌曲',
 'title': '无标题'}
2024-11-11 17:47:50 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '33',
 'description': '介绍：洗澡的时候不唱歌，怎么可能洗的下去？不信？请你点击随机播放，打开热水开关，记得洗完回来告诉我你唱没唱出来！',
 'play': '1633055',
 'songs': '128',
 'tag': '华语-放松-快乐',
 'title': '无标题'}
2024-11-11 17:47:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9337352507>
{'collection': '播放',
 'comments': '33',
 'description': '介绍：洗澡的时候不唱歌，怎么可能洗的下去？不信？请你点击随机播放，打开热水开关，记得洗完回来告诉我你唱没唱出来！',
 'play': '1633055',
 'songs': '128',
 'tag': '华语-放松-快乐',
 'title': '无标题'}
2024-11-11 17:47:50 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '108',
 'description': '介绍：那段值得珍惜的时光里，我们相遇，然后匆匆离开。那时候我们一起走过校园的每个角落，一起分享彼此的喜怒哀乐。青涩的我们并不懂什么是爱，只是被那种单纯的感觉吸引。我们一起经历的那些瞬间，都如同昨日一般清晰可见…耳熟能详的怀旧歌，聆听珍藏记忆中的青春！',
 'play': '6532796',
 'songs': '134',
 'tag': '90后-华语-流行',
 'title': '无标题'}
2024-11-11 17:47:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12269472913>
{'collection': '播放',
 'comments': '108',
 'description': '介绍：那段值得珍惜的时光里，我们相遇，然后匆匆离开。那时候我们一起走过校园的每个角落，一起分享彼此的喜怒哀乐。青涩的我们并不懂什么是爱，只是被那种单纯的感觉吸引。我们一起经历的那些瞬间，都如同昨日一般清晰可见…耳熟能详的怀旧歌，聆听珍藏记忆中的青春！',
 'play': '6532796',
 'songs': '134',
 'tag': '90后-华语-流行',
 'title': '无标题'}
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12629365606> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12665429217> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12651009503> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12659067361> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12516797531> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12584933689> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12622442250> (referer: None)
2024-11-11 17:47:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12728984760> (referer: None)
2024-11-11 17:47:50 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：救命啊啊啊这首歌真的太招桃花啦！！！！我从我家小区门口出来的时候刚好听到“恋爱频率，开启。”（当时我在低头看手机）然后抬起头看见一个抱着篮球坐在椅子帅帅男孩子也刚好抬头和我对视！！！狠狠心动了！！！——来自《恋爱频率》评论区的一位可爱女孩',
 'play': '351',
 'songs': '75',
 'tag': '华语-流行-快乐',
 'title': '无标题'}
2024-11-11 17:47:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12629365606>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：救命啊啊啊这首歌真的太招桃花啦！！！！我从我家小区门口出来的时候刚好听到“恋爱频率，开启。”（当时我在低头看手机）然后抬起头看见一个抱着篮球坐在椅子帅帅男孩子也刚好抬头和我对视！！！狠狠心动了！！！——来自《恋爱频率》评论区的一位可爱女孩',
 'play': '351',
 'songs': '75',
 'tag': '华语-流行-快乐',
 'title': '无标题'}
2024-11-11 17:47:50 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：还是老一辈的歌手有气节 只唱自己创作的歌我觉得在许多80、90后心中只有这些才真正配得上"音乐人"这个称号吧…',
 'play': '872',
 'songs': '210',
 'tag': '经典-怀旧-华语',
 'title': '无标题'}
2024-11-11 17:47:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12665429217>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：还是老一辈的歌手有气节 只唱自己创作的歌我觉得在许多80、90后心中只有这些才真正配得上"音乐人"这个称号吧…',
 'play': '872',
 'songs': '210',
 'tag': '经典-怀旧-华语',
 'title': '无标题'}
2024-11-11 17:47:50 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：需要一点好听的R&B给日常充充电，突如其来的降温让散步成了最好的消遣方式。傍晚吹着凉风戴上耳机听着歌发呆…',
 'play': '422',
 'songs': '53',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
2024-11-11 17:47:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12651009503>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：需要一点好听的R&B给日常充充电，突如其来的降温让散步成了最好的消遣方式。傍晚吹着凉风戴上耳机听着歌发呆…',
 'play': '422',
 'songs': '53',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
2024-11-11 17:47:50 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '12',
 'description': '介绍：星辰大海不过是背景，真正让我心动的是与你共赏着浩瀚星空的每个瞬间',
 'play': '116376',
 'songs': '43',
 'tag': '华语-流行-浪漫',
 'title': '无标题'}
2024-11-11 17:47:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12659067361>
{'collection': '播放',
 'comments': '12',
 'description': '介绍：星辰大海不过是背景，真正让我心动的是与你共赏着浩瀚星空的每个瞬间',
 'play': '116376',
 'songs': '43',
 'tag': '华语-流行-浪漫',
 'title': '无标题'}
2024-11-11 17:47:51 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：周传雄 凤凰传奇 伍佰 张信哲，每一首都很好听，你最爱哪位歌手的作品，欢迎评论区留言',
 'play': '135801',
 'songs': '76',
 'tag': '华语-流行-网络歌曲',
 'title': '无标题'}
2024-11-11 17:47:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12516797531>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：周传雄 凤凰传奇 伍佰 张信哲，每一首都很好听，你最爱哪位歌手的作品，欢迎评论区留言',
 'play': '135801',
 'songs': '76',
 'tag': '华语-流行-网络歌曲',
 'title': '无标题'}
2024-11-11 17:47:51 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：时光很匆忙，别错过落日和晚霞，日落是每日的心动时刻。',
 'play': '1351',
 'songs': '177',
 'tag': '华语-流行-网络歌曲',
 'title': '无标题'}
2024-11-11 17:47:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12584933689>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：时光很匆忙，别错过落日和晚霞，日落是每日的心动时刻。',
 'play': '1351',
 'songs': '177',
 'tag': '华语-流行-网络歌曲',
 'title': '无标题'}
2024-11-11 17:47:51 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：跟我走吧 忐忑给你 情书给你 不眠的夜给你 四月的清晨给你 雪糕的第一口给你 海底捞最后一颗鱼丸给你 手给你 '
                '怀抱给你 车票给你 跋涉给你 等待给你 钥匙给你 家给你 一腔孤勇和余生六十年 全都给你！',
 'play': '292',
 'songs': '98',
 'tag': '华语-流行-放松',
 'title': '无标题'}
2024-11-11 17:47:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12622442250>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：跟我走吧 忐忑给你 情书给你 不眠的夜给你 四月的清晨给你 雪糕的第一口给你 海底捞最后一颗鱼丸给你 手给你 '
                '怀抱给你 车票给你 跋涉给你 等待给你 钥匙给你 家给你 一腔孤勇和余生六十年 全都给你！',
 'play': '292',
 'songs': '98',
 'tag': '华语-流行-放松',
 'title': '无标题'}
2024-11-11 17:47:51 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：2025孙燕姿「就在日落以后」巡回演唱会 演出歌单新加坡站 '
                '2025/04/05-06上海深圳北京南京重庆台湾、香港、马来西亚',
 'play': '1166',
 'songs': '45',
 'tag': '华语-流行-旅行',
 'title': '无标题'}
2024-11-11 17:47:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12728984760>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：2025孙燕姿「就在日落以后」巡回演唱会 演出歌单新加坡站 '
                '2025/04/05-06上海深圳北京南京重庆台湾、香港、马来西亚',
 'play': '1166',
 'songs': '45',
 'tag': '华语-流行-旅行',
 'title': '无标题'}
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:47:51 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:49:11 [scrapy.extensions.logstats] INFO: Crawled 225 pages (at 16 pages/min), scraped 177 items (at 16 items/min)
2024-11-11 17:49:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9466230257> (referer: None)
2024-11-11 17:49:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9905297712> (referer: None)
2024-11-11 17:49:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9596126355> (referer: None)
2024-11-11 17:49:11 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '3',
 'description': '介绍：天赐的声音+声生不息，历届金曲舞台精选，神仙综艺，值得聆听',
 'play': '165104',
 'songs': '100',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:49:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9466230257>
{'collection': '播放',
 'comments': '3',
 'description': '介绍：天赐的声音+声生不息，历届金曲舞台精选，神仙综艺，值得聆听',
 'play': '165104',
 'songs': '100',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:49:11 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：华语实力派歌手，每一位都好喜欢，任素汐毛不易单依纯张碧晨薛之谦张杰，哪一位是你的最爱，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '152122',
 'songs': '114',
 'tag': '华语-流行-驾车',
 'title': '无标题'}
2024-11-11 17:49:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9905297712>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：华语实力派歌手，每一位都好喜欢，任素汐毛不易单依纯张碧晨薛之谦张杰，哪一位是你的最爱，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '152122',
 'songs': '114',
 'tag': '华语-流行-驾车',
 'title': '无标题'}
2024-11-11 17:49:11 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1',
 'description': '介绍：天花板女嗓，单依纯张碧晨刘惜君郁可唯，顶级的女嗓一开嗓就让全场沦陷，你最爱哪位歌手的作品，欢迎评论区留言',
 'play': '181619',
 'songs': '90',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:49:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9596126355>
{'collection': '播放',
 'comments': '1',
 'description': '介绍：天花板女嗓，单依纯张碧晨刘惜君郁可唯，顶级的女嗓一开嗓就让全场沦陷，你最爱哪位歌手的作品，欢迎评论区留言',
 'play': '181619',
 'songs': '90',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:49:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12607527671> (referer: None)
2024-11-11 17:49:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12652103093> (referer: None)
2024-11-11 17:49:12 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '5',
 'description': '介绍：浪漫随心听~日常的爱意散落在不经意之间，无聊时的白日梦里想和你一起冒险~',
 'play': '42880',
 'songs': '43',
 'tag': '华语-R&B/Soul-快乐',
 'title': '无标题'}
2024-11-11 17:49:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12607527671>
{'collection': '播放',
 'comments': '5',
 'description': '介绍：浪漫随心听~日常的爱意散落在不经意之间，无聊时的白日梦里想和你一起冒险~',
 'play': '42880',
 'songs': '43',
 'tag': '华语-R&B/Soul-快乐',
 'title': '无标题'}
2024-11-11 17:49:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12669933388> (referer: None)
2024-11-11 17:49:12 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：一曲老歌，一段回忆，悠悠旋律，诉说着往昔的风华绝代。每个老歌曲都有它独特的故事和情感，让我们一起重温那段美好时光。',
 'play': '1426',
 'songs': '67',
 'tag': '华语-怀旧-经典',
 'title': '无标题'}
2024-11-11 17:49:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12652103093>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：一曲老歌，一段回忆，悠悠旋律，诉说着往昔的风华绝代。每个老歌曲都有它独特的故事和情感，让我们一起重温那段美好时光。',
 'play': '1426',
 'songs': '67',
 'tag': '华语-怀旧-经典',
 'title': '无标题'}
2024-11-11 17:49:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9490737167> (referer: None)
2024-11-11 17:49:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9639063649> (referer: None)
2024-11-11 17:49:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=10089081606> (referer: None)
2024-11-11 17:49:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=10131782395> (referer: None)
2024-11-11 17:49:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12583411431> (referer: None)
2024-11-11 17:49:12 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：给你一张过去的CD，听听那时我们的回忆回忆自动倒带A面是斑驳老屋屋檐下的滴滴雨B面是一群青涩少年，等待着墙脚的指甲花开流年声里，一切如昔所谓完美就是耳机音量刚好盖过外界噪音闹钟响起时你刚好自然醒你爱的人刚好也爱你我多希望你也能听到我耳机 '
                '里的音乐这样你就能陪我睡不着',
 'play': '1926',
 'songs': '188',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
2024-11-11 17:49:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12669933388>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：给你一张过去的CD，听听那时我们的回忆回忆自动倒带A面是斑驳老屋屋檐下的滴滴雨B面是一群青涩少年，等待着墙脚的指甲花开流年声里，一切如昔所谓完美就是耳机音量刚好盖过外界噪音闹钟响起时你刚好自然醒你爱的人刚好也爱你我多希望你也能听到我耳机 '
                '里的音乐这样你就能陪我睡不着',
 'play': '1926',
 'songs': '188',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
2024-11-11 17:49:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12695997403> (referer: None)
2024-11-11 17:49:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12679654931> (referer: None)
2024-11-11 17:49:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12557672249> (referer: None)
2024-11-11 17:49:12 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '3',
 'description': '介绍：华语女声精选，张碧晨单依纯张靓颖邓紫棋实力派女嗓精选，每一首都很好听，你最爱哪位女歌手，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '452414',
 'songs': '118',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:49:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9490737167>
{'collection': '播放',
 'comments': '3',
 'description': '介绍：华语女声精选，张碧晨单依纯张靓颖邓紫棋实力派女嗓精选，每一首都很好听，你最爱哪位女歌手，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '452414',
 'songs': '118',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:49:13 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '24',
 'description': '介绍：音综封神舞台，全场观众都沦陷的绝美好声音，实力派歌手的用心演唱，不得不爱',
 'play': '1330639',
 'songs': '145',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:49:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9639063649>
{'collection': '播放',
 'comments': '24',
 'description': '介绍：音综封神舞台，全场观众都沦陷的绝美好声音，实力派歌手的用心演唱，不得不爱',
 'play': '1330639',
 'songs': '145',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:49:13 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1',
 'description': '介绍：歌手2024+天赐的声音+中国好声音，每一首都是顶级献唱，好听到停不下来，你最爱哪位歌手的舞台，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '91978',
 'songs': '101',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:49:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=10089081606>
{'collection': '播放',
 'comments': '1',
 'description': '介绍：歌手2024+天赐的声音+中国好声音，每一首都是顶级献唱，好听到停不下来，你最爱哪位歌手的舞台，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '91978',
 'songs': '101',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:49:13 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '167',
 'description': '介绍：我迷迷糊糊的爱上你 却清清楚楚的失去你 \u200b\u200b\u200b 我也不知道还有什么是我该去期待的 '
                '———————————————————————— 在13月 星期八 第25小时 第61分 或许你会是我的',
 'play': '17230760',
 'songs': '118',
 'tag': '华语-流行-伤感',
 'title': '无标题'}
2024-11-11 17:49:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=10131782395>
{'collection': '播放',
 'comments': '167',
 'description': '介绍：我迷迷糊糊的爱上你 却清清楚楚的失去你 \u200b\u200b\u200b 我也不知道还有什么是我该去期待的 '
                '———————————————————————— 在13月 星期八 第25小时 第61分 或许你会是我的',
 'play': '17230760',
 'songs': '118',
 'tag': '华语-流行-伤感',
 'title': '无标题'}
2024-11-11 17:49:13 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：沦陷于R&B的降噪模式，看着日暮与绿影，沿路的风景晃过，耳机里的歌曲温柔又带着淡淡的治愈。悲伤不要藏在心里，不管好坏记得分享…',
 'play': '2304',
 'songs': '46',
 'tag': '华语-流行-R&B/Soul',
 'title': '无标题'}
2024-11-11 17:49:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12583411431>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：沦陷于R&B的降噪模式，看着日暮与绿影，沿路的风景晃过，耳机里的歌曲温柔又带着淡淡的治愈。悲伤不要藏在心里，不管好坏记得分享…',
 'play': '2304',
 'songs': '46',
 'tag': '华语-流行-R&B/Soul',
 'title': '无标题'}
2024-11-11 17:49:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12749026931> (referer: None)
2024-11-11 17:49:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12767069610> (referer: None)
2024-11-11 17:49:13 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：“如果大海能够换回曾经的爱，就让我用一生等待，如果深情往事你已不再留恋，就让他随风飘远“张雨生的《大海》是我拥有过的第一张磁带听的第一首歌，在那个还是录音机的90年代，首歌都能听上好久，从此也在心里生了根。选了一些90年代的歌曲，满满都是回忆，有你的记忆吗?',
 'play': '24648',
 'songs': '159',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:49:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12695997403>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：“如果大海能够换回曾经的爱，就让我用一生等待，如果深情往事你已不再留恋，就让他随风飘远“张雨生的《大海》是我拥有过的第一张磁带听的第一首歌，在那个还是录音机的90年代，首歌都能听上好久，从此也在心里生了根。选了一些90年代的歌曲，满满都是回忆，有你的记忆吗?',
 'play': '24648',
 'songs': '159',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:49:13 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：生活嘈杂，热烈不减，要在热爱里，爱的很慢，很踏实！幸福是一只难以捕捉的蝴蝶 但如果你安静的坐在那里 '
                '也许他会落在你手上~',
 'play': '1111',
 'songs': '52',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:49:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12679654931>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：生活嘈杂，热烈不减，要在热爱里，爱的很慢，很踏实！幸福是一只难以捕捉的蝴蝶 但如果你安静的坐在那里 '
                '也许他会落在你手上~',
 'play': '1111',
 'songs': '52',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:49:13 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '45',
 'description': '介绍：爱不是一时好感而是明明知道没结果还想要坚持下去的冲动我知道遇到你不容易错过了会很可惜 所以不顾一切后果继续爱你 '
                '爱到最后很卑微即使是伤痕累累 却还是爱着你原来 不是所有的爱都结果我犯过最大的错误就是 '
                '我爱你最后想放下你的时候却发现我早己经放不下了你的名字很短 却贯彻了我整个青春封面：源自网络图片整理：陈穆泽',
 'play': '47815',
 'songs': '51',
 'tag': '华语-流行-伤感',
 'title': '无标题'}
2024-11-11 17:49:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12557672249>
{'collection': '播放',
 'comments': '45',
 'description': '介绍：爱不是一时好感而是明明知道没结果还想要坚持下去的冲动我知道遇到你不容易错过了会很可惜 所以不顾一切后果继续爱你 '
                '爱到最后很卑微即使是伤痕累累 却还是爱着你原来 不是所有的爱都结果我犯过最大的错误就是 '
                '我爱你最后想放下你的时候却发现我早己经放不下了你的名字很短 却贯彻了我整个青春封面：源自网络图片整理：陈穆泽',
 'play': '47815',
 'songs': '51',
 'tag': '华语-流行-伤感',
 'title': '无标题'}
2024-11-11 17:49:14 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '15',
 'description': '介绍：哪怕现实不尽人意我也要开出自己的花今天的你还好吗觉得累吗不妨听会儿歌吧疗愈一下相信明天会更好相信自己值得被爱吧现实如山可你却浪漫如云如此独一无二',
 'play': '30772',
 'songs': '31',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:49:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12749026931>
{'collection': '播放',
 'comments': '15',
 'description': '介绍：哪怕现实不尽人意我也要开出自己的花今天的你还好吗觉得累吗不妨听会儿歌吧疗愈一下相信明天会更好相信自己值得被爱吧现实如山可你却浪漫如云如此独一无二',
 'play': '30772',
 'songs': '31',
 'tag': '华语-流行-治愈',
 'title': '无标题'}
2024-11-11 17:49:14 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '10',
 'description': '介绍：林俊杰JJ20世界巡回演唱会收官站重庆场歌单JJ20 '
                '重庆彼此圆满11月1号惊喜歌曲：周杰伦《不能说的秘密+星晴》，Patti《我不在乎世界如此荒唐》11月2号嘉宾歌曲：王源《流星也为你落下来》11月3号嘉宾歌曲：陶喆《爱我还是他》',
 'play': '20956',
 'songs': '59',
 'tag': '华语-流行-榜单',
 'title': '无标题'}
2024-11-11 17:49:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12767069610>
{'collection': '播放',
 'comments': '10',
 'description': '介绍：林俊杰JJ20世界巡回演唱会收官站重庆场歌单JJ20 '
                '重庆彼此圆满11月1号惊喜歌曲：周杰伦《不能说的秘密+星晴》，Patti《我不在乎世界如此荒唐》11月2号嘉宾歌曲：王源《流星也为你落下来》11月3号嘉宾歌曲：陶喆《爱我还是他》',
 'play': '20956',
 'songs': '59',
 'tag': '华语-流行-榜单',
 'title': '无标题'}
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:49:14 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:50:39 [scrapy.extensions.logstats] INFO: Crawled 241 pages (at 16 pages/min), scraped 193 items (at 16 items/min)
2024-11-11 17:50:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9286416393> (referer: None)
2024-11-11 17:50:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7708843538> (referer: None)
2024-11-11 17:50:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9471473728> (referer: None)
2024-11-11 17:50:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7662533400> (referer: None)
2024-11-11 17:50:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7662449932> (referer: None)
2024-11-11 17:50:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7718785279> (referer: None)
2024-11-11 17:50:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7662624876> (referer: None)
2024-11-11 17:50:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '10',
 'description': '介绍：路途再遥远 爱这条路 我依然想和你一起走.「南北弘石的轮回歌单」(本歌单现在只添加4个人本人的歌曲哦)',
 'play': '100807',
 'songs': '37',
 'tag': '华语',
 'title': '无标题'}
2024-11-11 17:50:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9286416393>
{'collection': '播放',
 'comments': '10',
 'description': '介绍：路途再遥远 爱这条路 我依然想和你一起走.「南北弘石的轮回歌单」(本歌单现在只添加4个人本人的歌曲哦)',
 'play': '100807',
 'songs': '37',
 'tag': '华语',
 'title': '无标题'}
2024-11-11 17:50:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12511338928> (referer: None)
2024-11-11 17:50:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=9781230130> (referer: None)
2024-11-11 17:50:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7660895089> (referer: None)
2024-11-11 17:50:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=10105076943> (referer: None)
2024-11-11 17:50:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=10184764630> (referer: None)
2024-11-11 17:50:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12665644879> (referer: None)
2024-11-11 17:50:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '310',
 'description': '介绍：顏社由迪拉胖2005年同一群热爱嘻哈饶舌音乐的伙伴一起成立，跨足演唱会制作、展览、纪录片、书籍、音乐节等领域，且皆赢得金音奖、金曲奖、金马奖、金点奖等多项重要大奖的肯定。',
 'play': '468416',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:50:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7708843538>
{'collection': '播放',
 'comments': '310',
 'description': '介绍：顏社由迪拉胖2005年同一群热爱嘻哈饶舌音乐的伙伴一起成立，跨足演唱会制作、展览、纪录片、书籍、音乐节等领域，且皆赢得金音奖、金曲奖、金马奖、金点奖等多项重要大奖的肯定。',
 'play': '468416',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:50:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '15',
 'description': '介绍：神仙嗓音天花板，单依纯徐佳莹郁可唯周深，每一位都是华语乐坛的顶级歌手，总有一首能成为你的白月光，欢迎收藏，感谢聆听',
 'play': '487858',
 'songs': '125',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:50:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9471473728>
{'collection': '播放',
 'comments': '15',
 'description': '介绍：神仙嗓音天花板，单依纯徐佳莹郁可唯周深，每一位都是华语乐坛的顶级歌手，总有一首能成为你的白月光，欢迎收藏，感谢聆听',
 'play': '487858',
 'songs': '125',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:50:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '4',
 'description': '介绍：郝云，1979年2月25日出生于河南省郑州市，中国内地男歌手、音乐制作人、词曲创作人。坦然面对、真诚歌唱，说起来容易做起来难，而他的歌听来有苦也有乐，这就是生活，这就是郝云！',
 'play': '63225',
 'songs': '23',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:50:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7662533400>
{'collection': '播放',
 'comments': '4',
 'description': '介绍：郝云，1979年2月25日出生于河南省郑州市，中国内地男歌手、音乐制作人、词曲创作人。坦然面对、真诚歌唱，说起来容易做起来难，而他的歌听来有苦也有乐，这就是生活，这就是郝云！',
 'play': '63225',
 'songs': '23',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:50:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '3',
 'description': '介绍：“小娟&山谷里的居民”他们是一支三个亲密无间的好朋友组成的乐队组合。小娟的歌声代表着人间的赤诚与美好，像是涓涓流水流淌在我们心间，纯真中带着向往。他们的每一首歌都像是一条清澈的溪流，带着干净与纯粹。',
 'play': '78433',
 'songs': '51',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:50:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7662449932>
{'collection': '播放',
 'comments': '3',
 'description': '介绍：“小娟&山谷里的居民”他们是一支三个亲密无间的好朋友组成的乐队组合。小娟的歌声代表着人间的赤诚与美好，像是涓涓流水流淌在我们心间，纯真中带着向往。他们的每一首歌都像是一条清澈的溪流，带着干净与纯粹。',
 'play': '78433',
 'songs': '51',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:50:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '45',
 'description': '介绍：国蛋是蛋堡在台南一中的学弟，毕业于台大化学系。更位人所知的的称号是”Dr.Paper '
                '紙博士”。曾赴紐約求学的他，在美国东岸文化洗礼下，用一口正統饒舌的嘴，征服各界鐵粉挑剔的耳。',
 'play': '97552',
 'songs': '33',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:50:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7718785279>
{'collection': '播放',
 'comments': '45',
 'description': '介绍：国蛋是蛋堡在台南一中的学弟，毕业于台大化学系。更位人所知的的称号是”Dr.Paper '
                '紙博士”。曾赴紐約求学的他，在美国东岸文化洗礼下，用一口正統饒舌的嘴，征服各界鐵粉挑剔的耳。',
 'play': '97552',
 'songs': '33',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:50:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2',
 'description': '介绍：中国内地人文民谣乐团，名字取自于“水木清华”， 前后共有五位成员，目前由卢庚戌、缪杰、陈秋桦组成。 '
                '手里的吉他是治愈世界的枪，草莓时光隐喻自在时光，抛开世俗，人人都是无拘无束的乌托邦少年。',
 'play': '176554',
 'songs': '35',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:50:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7662624876>
{'collection': '播放',
 'comments': '2',
 'description': '介绍：中国内地人文民谣乐团，名字取自于“水木清华”， 前后共有五位成员，目前由卢庚戌、缪杰、陈秋桦组成。 '
                '手里的吉他是治愈世界的枪，草莓时光隐喻自在时光，抛开世俗，人人都是无拘无束的乌托邦少年。',
 'play': '176554',
 'songs': '35',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:50:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12775741905> (referer: None)
2024-11-11 17:50:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：鸽子嫌弃乌鸦没有归宿乌鸦嫌弃鸽子被圈在信仰里从此只能你奔赴大海我跨越山河风好自由，雨也随性，太阳如此热烈，我承认我爱这一切',
 'play': '226823',
 'songs': '70',
 'tag': '华语-流行-另类/独立',
 'title': '无标题'}
2024-11-11 17:50:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12511338928>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：鸽子嫌弃乌鸦没有归宿乌鸦嫌弃鸽子被圈在信仰里从此只能你奔赴大海我跨越山河风好自由，雨也随性，太阳如此热烈，我承认我爱这一切',
 'play': '226823',
 'songs': '70',
 'tag': '华语-流行-另类/独立',
 'title': '无标题'}
2024-11-11 17:50:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '9',
 'description': '介绍：时光音乐会最值得的60首精选歌曲，温柔治愈，一开嗓就是心动的声音，你最爱哪位歌手的舞台，欢迎评论区留言，感谢收藏，感谢聆听',
 'play': '707933',
 'songs': '94',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:50:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=9781230130>
{'collection': '播放',
 'comments': '9',
 'description': '介绍：时光音乐会最值得的60首精选歌曲，温柔治愈，一开嗓就是心动的声音，你最爱哪位歌手的舞台，欢迎评论区留言，感谢收藏，感谢聆听',
 'play': '707933',
 'songs': '94',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:50:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '4',
 'description': '介绍：2024必听的神仙音综！天赐的声音第五季+歌手2024，顶级献唱惊艳全场，你最爱哪位歌手的演唱，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '101285',
 'songs': '93',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:50:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=10105076943>
{'collection': '播放',
 'comments': '4',
 'description': '介绍：2024必听的神仙音综！天赐的声音第五季+歌手2024，顶级献唱惊艳全场，你最爱哪位歌手的演唱，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '101285',
 'songs': '93',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:50:42 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：听老歌，听的是情怀，是回忆，每首歌都有不同的回忆老歌听的是情怀，新曲听的是时代。不变的是情怀，前进的是时代。',
 'play': '2228',
 'songs': '203',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
2024-11-11 17:50:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12665644879>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：听老歌，听的是情怀，是回忆，每首歌都有不同的回忆老歌听的是情怀，新曲听的是时代。不变的是情怀，前进的是时代。',
 'play': '2228',
 'songs': '203',
 'tag': '华语-经典-怀旧',
 'title': '无标题'}
2024-11-11 17:50:42 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '60',
 'description': '介绍：天赐的声音，一开嗓就封神的顶级live，神仙演绎直击心灵，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '2258881',
 'songs': '103',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:50:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=10184764630>
{'collection': '播放',
 'comments': '60',
 'description': '介绍：天赐的声音，一开嗓就封神的顶级live，神仙演绎直击心灵，欢迎评论区留言，欢迎收藏，感谢聆听',
 'play': '2258881',
 'songs': '103',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:50:42 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '37',
 'description': '介绍：愿时光能缓，故人不散。相识，不觉一年又一年，人生弥散在那些无悔的岁月里。本歌单收录了齐秦、王祖贤、林志颖、刘惜君等多位歌手的歌曲，带我们重温旧时光里的美好回忆。',
 'play': '319883',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:50:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7660895089>
{'collection': '播放',
 'comments': '37',
 'description': '介绍：愿时光能缓，故人不散。相识，不觉一年又一年，人生弥散在那些无悔的岁月里。本歌单收录了齐秦、王祖贤、林志颖、刘惜君等多位歌手的歌曲，带我们重温旧时光里的美好回忆。',
 'play': '319883',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:50:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12706925419> (referer: None)
2024-11-11 17:50:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12682164571> (referer: None)
2024-11-11 17:50:42 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：无人问津也好，技不如人也罢。你都要试着安静下来，去做自己该做的事，而不是让内心烦躁，焦虑，毁掉你本就不多的热情和定力。昨日之深渊，今日之浅谈。路虽远，行则将至。事虽难，做则可成。',
 'play': '19982',
 'songs': '49',
 'tag': '华语-流行',
 'title': '无标题'}
2024-11-11 17:50:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12775741905>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：无人问津也好，技不如人也罢。你都要试着安静下来，去做自己该做的事，而不是让内心烦躁，焦虑，毁掉你本就不多的热情和定力。昨日之深渊，今日之浅谈。路虽远，行则将至。事虽难，做则可成。',
 'play': '19982',
 'songs': '49',
 'tag': '华语-流行',
 'title': '无标题'}
2024-11-11 17:50:42 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：没有意义的情绪就带上耳机耳机是人类的避难所，音乐是我的速效药。是啊，那音乐里的共鸣才是你我深夜崩溃的救赎。生活中总有一个会打动你的地方，一句歌词，一个声音，一份安静的环境，一个有趣的灵魂，当你想要一个人安静一会，想去一个角落思考，但这繁乱的世界里，耳机就像输液管，听音乐就像生病打点滴，是一个治愈的过程。',
 'play': '9494',
 'songs': '77',
 'tag': '华语-流行-夜晚',
 'title': '无标题'}
2024-11-11 17:50:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12706925419>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：没有意义的情绪就带上耳机耳机是人类的避难所，音乐是我的速效药。是啊，那音乐里的共鸣才是你我深夜崩溃的救赎。生活中总有一个会打动你的地方，一句歌词，一个声音，一份安静的环境，一个有趣的灵魂，当你想要一个人安静一会，想去一个角落思考，但这繁乱的世界里，耳机就像输液管，听音乐就像生病打点滴，是一个治愈的过程。',
 'play': '9494',
 'songs': '77',
 'tag': '华语-流行-夜晚',
 'title': '无标题'}
2024-11-11 17:50:42 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2',
 'description': '介绍：还不知道要唱什么歌吗每次朋友在KTV唱起这些歌我也不知不觉的跟着一起唱了如果你不知道唱什么可以点这些歌',
 'play': '242695',
 'songs': '250',
 'tag': 'KTV-华语-流行',
 'title': '无标题'}
2024-11-11 17:50:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12682164571>
{'collection': '播放',
 'comments': '2',
 'description': '介绍：还不知道要唱什么歌吗每次朋友在KTV唱起这些歌我也不知不觉的跟着一起唱了如果你不知道唱什么可以点这些歌',
 'play': '242695',
 'songs': '250',
 'tag': 'KTV-华语-流行',
 'title': '无标题'}
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:50:42 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:50:58 [scrapy.extensions.logstats] INFO: Crawled 257 pages (at 16 pages/min), scraped 209 items (at 16 items/min)
2024-11-11 17:51:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845409713> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6957219650> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=2829883282> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845421558> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8756917202> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6957231163> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6703233707> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:00 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8170169684> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8804731200> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8892142201> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12268029094> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12486085747> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12461145779> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12463419337> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=9332993088> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12656493657> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=2829883282> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6703233707> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845409713> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845421558> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6957219650> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6957231163> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8170169684> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8756917202> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8804731200> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8892142201> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=9332993088> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12268029094> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12463419337> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12461145779> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12486085747> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12656493657> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=2829883282> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6703233707> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6845409713> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6845421558> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6957219650> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6957231163> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8170169684> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8756917202> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=2829883282>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6703233707>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6845409713>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6845421558>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6957231163>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6957219650>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8170169684>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8756917202>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8804731200> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8892142201> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=9332993088> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12268029094> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12461145779> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12463419337> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12486085747> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12656493657> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8804731200>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8892142201>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=9332993088>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12268029094>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12461145779>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12463419337>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12486085747>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12656493657>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:10 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:51:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=5172410111> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845908342> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8164148113> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6847225823> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8497844200> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845896399> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845404732> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845433317> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=9407025865> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12486457680> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12501264222> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=5172410111> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12554132768> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12601032488> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12601076950> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12633659256> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845404732> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845433317> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845896399> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845908342> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8497844200> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=9407025865> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6847225823> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:16 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8164148113> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12486457680> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12501264222> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12554132768> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12601032488> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6845404732> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12601076950> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12633659256> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:18 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=5172410111> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6845404732>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=5172410111>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6845433317> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6845896399> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6845908342> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6847225823> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8164148113> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8497844200> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12486457680> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=9407025865> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6845433317>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6845896399>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6845908342>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6847225823>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8164148113>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8497844200>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=9407025865>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12486457680>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12501264222> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12554132768> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12633659256> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12601032488> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:22 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12601076950> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12501264222>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12554132768>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12633659256>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12601032488>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12601076950>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:23 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:51:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6703233707> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7210744423> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7049343482> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6952319059> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7095057417> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8804731200> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7059948706> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:25 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7095432074> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8865057200> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12361297869> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12477473306> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12501308052> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12564922080> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12573817765> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12652461415> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12786877786> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6703233707> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6952319059> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7049343482> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7095432074> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7210744423> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7059948706> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7095057417> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8804731200> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8865057200> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12361297869> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12477473306> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12573817765> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12652461415> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12501308052> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12564922080> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12786877786> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6703233707> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6952319059> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=7049343482> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6703233707>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=7059948706> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=7095057417> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=7210744423> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8804731200> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=7095432074> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6952319059>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=7049343482>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=7059948706>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=7095057417>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=7210744423>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8804731200>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=7095432074>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8865057200> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12361297869> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12477473306> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8865057200>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12501308052> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12564922080> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12573817765> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12652461415> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12786877786> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12361297869>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12477473306>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12501308052>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12573817765>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12786877786>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12652461415>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12564922080>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:35 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:51:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6957231163> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=9310458102> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7848930171> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7775475086> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7838437309> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7737156437> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7718807599> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8437419066> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=9470426097> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=10064625970> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12582178406> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12585459038> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12626569525> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12655777991> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12676914379> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:39 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12736860181> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6957231163> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7718807599> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7737156437> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7775475086> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7838437309> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7848930171> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8437419066> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:41 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=9310458102> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=9470426097> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=10064625970> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12582178406> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12585459038> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12626569525> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12736860181> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12655777991> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:43 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12676914379> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6957231163> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=7718807599> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=7737156437> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6957231163>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=7775475086> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=7838437309> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=7848930171> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8437419066> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:45 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=9310458102> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=7718807599>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=7737156437>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=7775475086>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8437419066>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=7848930171>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=7838437309>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=9310458102>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=9470426097> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=10064625970> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12582178406> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=9470426097>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12585459038> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=10064625970>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12655777991> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12626569525> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12676914379> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:47 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12736860181> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12582178406>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12585459038>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12736860181>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12626569525>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12676914379>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12655777991>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:51:48 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:51:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845442284> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8164148113> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8233799987> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6957253005> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8451919201> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7119800243> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7561460225> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:50 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8293792441> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8484246204> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8484467201> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8892140200> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=9377284526> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12426468826> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12655639016> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8804731200> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:52 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12711444140> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845442284> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6957253005> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7119800243> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8293792441> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7561460225> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8164148113> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8233799987> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8451919201> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:55 [scrapy.extensions.logstats] INFO: Crawled 257 pages (at 0 pages/min), scraped 209 items (at 0 items/min)
2024-11-11 17:51:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8484246204> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8484467201> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8804731200> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=9377284526> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8892140200> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12426468826> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12711444140> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:56 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12655639016> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6845442284> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6957253005> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=7119800243> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=7561460225> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8164148113> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8233799987> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8451919201> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8293792441> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6845442284>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6957253005>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=7119800243>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=7561460225>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8164148113>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8233799987>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8451919201>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:51:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8293792441>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8484246204> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8484467201> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8804731200> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8892140200> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=9377284526> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12426468826> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12655639016> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12711444140> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8484246204>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8484467201>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8804731200>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8892140200>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=9377284526>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12426468826>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12655639016>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12711444140>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:00 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:52:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845730053> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12200756252> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8482331201> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8549100202> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=9381079097> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7308142944> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8278937351> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:02 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8481098203> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12423512206> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12483216525> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12548260208> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12504665735> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12548419675> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12573303801> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12656069654> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:04 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12704232618> (failed 1 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=6845730053> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=7308142944> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8278937351> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8482331201> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8481098203> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=8549100202> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=9381079097> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:06 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12200756252> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12423512206> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12483216525> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12504665735> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12548260208> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12573303801> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12548419675> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12656069654> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://music.163.com/playlist?id=12704232618> (failed 2 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=6845730053> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=7308142944> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8278937351> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=6845730053>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:10 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8481098203> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8482331201> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=8549100202> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=9381079097> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12200756252> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=7308142944>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8278937351>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8481098203>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8482331201>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12200756252>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=9381079097>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=8549100202>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12423512206> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12483216525> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:12 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12504665735> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12423512206>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12548260208> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12548419675> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12573303801> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12656069654> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:13 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://music.163.com/playlist?id=12704232618> (failed 3 times): Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12483216525>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12504665735>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12548260208>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12704232618>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12573303801>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12548419675>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://music.163.com/playlist?id=12656069654>
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
             ^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\downloader\middleware.py", line 54, in process_request
    return (yield download_func(request=request, spider=spider))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
twisted.internet.error.ConnectionRefusedError: Connection was refused by other side: 10061: 由于目标计算机积极拒绝，无法连接。.
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:52:13 [music_detail_spider] DEBUG: Read 16 requests from 'detail_url_queue'
2024-11-11 17:53:35 [scrapy.extensions.logstats] INFO: Crawled 257 pages (at 0 pages/min), scraped 209 items (at 0 items/min)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7233044181> (referer: None)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6957226907> (referer: None)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7492285791> (referer: None)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6845868899> (referer: None)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7527131664> (referer: None)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7368548653> (referer: None)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7476280844> (referer: None)
2024-11-11 17:53:36 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '6',
 'description': '介绍：演唱会最大的魅力也许就是它的“不可再现”，坐在台下，和自己喜爱的人在同一秒钟，唱出同一句，像是共同分享了一个秘密。那一刻的感动无法言喻。',
 'play': '768623',
 'songs': '72',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7233044181>
{'collection': '播放',
 'comments': '6',
 'description': '介绍：演唱会最大的魅力也许就是它的“不可再现”，坐在台下，和自己喜爱的人在同一秒钟，唱出同一句，像是共同分享了一个秘密。那一刻的感动无法言喻。',
 'play': '768623',
 'songs': '72',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7514752540> (referer: None)
2024-11-11 17:53:36 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '8',
 'description': '介绍：1997年经典歌曲精选',
 'play': '274393',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6957226907>
{'collection': '播放',
 'comments': '8',
 'description': '介绍：1997年经典歌曲精选',
 'play': '274393',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1066',
 'description': '介绍：时代少年团(Teens In Times、TNT) '
                '是由时代峰峻推出的中国内地男子演唱组合，由马嘉祺、丁程鑫、宋亚轩、刘耀文、张真源、严浩翔、贺峻霖七人组成。',
 'play': '588364',
 'songs': '39',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7492285791>
{'collection': '播放',
 'comments': '1066',
 'description': '介绍：时代少年团(Teens In Times、TNT) '
                '是由时代峰峻推出的中国内地男子演唱组合，由马嘉祺、丁程鑫、宋亚轩、刘耀文、张真源、严浩翔、贺峻霖七人组成。',
 'play': '588364',
 'songs': '39',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '12',
 'description': '介绍：还记得手机彩铃风靡的年代吗？',
 'play': '902444',
 'songs': '61',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=6845868899>
{'collection': '播放',
 'comments': '12',
 'description': '介绍：还记得手机彩铃风靡的年代吗？',
 'play': '902444',
 'songs': '61',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '9',
 'description': '介绍：五月天，中国台湾摇滚乐团，由五个大男孩所组成的五月天，呈现出清新健康的青春活力，令人激赏 '
                '。五月天的作品和行动相一致，可以这样说，他们的歌和他们的人符合乐迷期待，对这个世界充满期望。',
 'play': '527539',
 'songs': '49',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7527131664>
{'collection': '播放',
 'comments': '9',
 'description': '介绍：五月天，中国台湾摇滚乐团，由五个大男孩所组成的五月天，呈现出清新健康的青春活力，令人激赏 '
                '。五月天的作品和行动相一致，可以这样说，他们的歌和他们的人符合乐迷期待，对这个世界充满期望。',
 'play': '527539',
 'songs': '49',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '55',
 'description': '介绍：《放羊的星星》《我可能不会爱你》《海豚湾恋人》《海豚爱上猫》……福茂唱片是台湾偶像剧ost大户，唱片公司里的“情歌王”福茂唱片版权回归网易云音乐，一起走进它的宝藏曲库吧！',
 'play': '297858',
 'songs': '79',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7368548653>
{'collection': '播放',
 'comments': '55',
 'description': '介绍：《放羊的星星》《我可能不会爱你》《海豚湾恋人》《海豚爱上猫》……福茂唱片是台湾偶像剧ost大户，唱片公司里的“情歌王”福茂唱片版权回归网易云音乐，一起走进它的宝藏曲库吧！',
 'play': '297858',
 'songs': '79',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2178',
 'description': '介绍：夏天到了，少年们回来了！北京时代峰峻文化艺术发展有限公司成立于2009年，极巨影响力的超人气组合TFBOYS、时代少年团、TF家族三代……都出自这里时代峰峻版权正式回归云音乐！',
 'play': '1397469',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7476280844>
{'collection': '播放',
 'comments': '2178',
 'description': '介绍：夏天到了，少年们回来了！北京时代峰峻文化艺术发展有限公司成立于2009年，极巨影响力的超人气组合TFBOYS、时代少年团、TF家族三代……都出自这里时代峰峻版权正式回归云音乐！',
 'play': '1397469',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8636932202> (referer: None)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7849682229> (referer: None)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12694038404> (referer: None)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12554056559> (referer: None)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8756917202> (referer: None)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7527357861> (referer: None)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8325650845> (referer: None)
2024-11-11 17:53:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8170169684> (referer: None)
2024-11-11 17:53:36 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '333',
 'description': '介绍：打开这份歌单的每个人，青春中都有许巍的名字。那是熙熙攘攘的街头巷尾，是一程又一程的旅途，是我们驻足过的每个街角，是回忆里那个人的微笑，是最寻常的问候，是每一次和音乐的久别重逢。',
 'play': '934150',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7514752540>
{'collection': '播放',
 'comments': '333',
 'description': '介绍：打开这份歌单的每个人，青春中都有许巍的名字。那是熙熙攘攘的街头巷尾，是一程又一程的旅途，是我们驻足过的每个街角，是回忆里那个人的微笑，是最寻常的问候，是每一次和音乐的久别重逢。',
 'play': '934150',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1',
 'description': '介绍：品尝一口醇香的卡布奇诺 激活体内的浪漫因子',
 'play': '146593',
 'songs': '79',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8636932202>
{'collection': '播放',
 'comments': '1',
 'description': '介绍：品尝一口醇香的卡布奇诺 激活体内的浪漫因子',
 'play': '146593',
 'songs': '79',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '244',
 'description': '介绍：华语流行音乐界最具影响力与实力的杰出音乐制作人／词曲创作者／歌手，作品广为流传，有百万制作人以及音乐教父之称，影响数以亿计华语乐迷。',
 'play': '1342244',
 'songs': '59',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7849682229>
{'collection': '播放',
 'comments': '244',
 'description': '介绍：华语流行音乐界最具影响力与实力的杰出音乐制作人／词曲创作者／歌手，作品广为流传，有百万制作人以及音乐教父之称，影响数以亿计华语乐迷。',
 'play': '1342244',
 'songs': '59',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:37 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：在我的印象里，九十年代的味道是游戏厅里的汗臭味与吵闹声。 在我的印象里，九十年代的味道是冰绿豆汤的甜味。 '
                '在我的印象里，九十年代的味道是拉面拌着香菜的味道。 在我的印象里，九十年代的味道是香蕉冰棒和小浣熊方便面的味道。 '
                '但是九十年代最令我难以忘记的味道，还是那时的歌曲，那个时候的音乐是那么纯粹，世界是那么美好。 '
                '真想有一天我能躺在那片没被挖走的绿草地上，在阳光明媚的梦里听到那过去的歌声。',
 'play': '71717',
 'songs': '121',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:53:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12694038404>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：在我的印象里，九十年代的味道是游戏厅里的汗臭味与吵闹声。 在我的印象里，九十年代的味道是冰绿豆汤的甜味。 '
                '在我的印象里，九十年代的味道是拉面拌着香菜的味道。 在我的印象里，九十年代的味道是香蕉冰棒和小浣熊方便面的味道。 '
                '但是九十年代最令我难以忘记的味道，还是那时的歌曲，那个时候的音乐是那么纯粹，世界是那么美好。 '
                '真想有一天我能躺在那片没被挖走的绿草地上，在阳光明媚的梦里听到那过去的歌声。',
 'play': '71717',
 'songs': '121',
 'tag': '华语-流行-90后',
 'title': '无标题'}
2024-11-11 17:53:37 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：天赐的声音：如果可以 暮色回响 字字句句，神级嗓音，一开嗓就让全场沦陷，总有一首能唱进你心里，欢迎收藏，好像聆听',
 'play': '5185',
 'songs': '100',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:53:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=12554056559>
{'collection': '播放',
 'comments': '评论',
 'description': '介绍：天赐的声音：如果可以 暮色回响 字字句句，神级嗓音，一开嗓就让全场沦陷，总有一首能唱进你心里，欢迎收藏，好像聆听',
 'play': '5185',
 'songs': '100',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:53:37 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '9',
 'description': '介绍：回溯金色的1990年代 听那个年代的故事',
 'play': '412031',
 'songs': '37',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8756917202>
{'collection': '播放',
 'comments': '9',
 'description': '介绍：回溯金色的1990年代 听那个年代的故事',
 'play': '412031',
 'songs': '37',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:37 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '41',
 'description': '介绍：张震岳，中国台湾男歌手、音乐人。从少年偶像男生蜕变成为一名摇滚歌手，作为一个多面的音乐人，张震岳的才能不仅局限在旋律方面，他生活化歌词也是亮点之一 '
                '。',
 'play': '730357',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=7527357861>
{'collection': '播放',
 'comments': '41',
 'description': '介绍：张震岳，中国台湾男歌手、音乐人。从少年偶像男生蜕变成为一名摇滚歌手，作为一个多面的音乐人，张震岳的才能不仅局限在旋律方面，他生活化歌词也是亮点之一 '
                '。',
 'play': '730357',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:37 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '20',
 'description': '介绍：人生有那么多意难平的瞬间\xa0从熟悉到陌生也只需要一瞬间',
 'play': '1405827',
 'songs': '40',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8325650845>
{'collection': '播放',
 'comments': '20',
 'description': '介绍：人生有那么多意难平的瞬间\xa0从熟悉到陌生也只需要一瞬间',
 'play': '1405827',
 'songs': '40',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:37 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '31',
 'description': '介绍：戴上耳机放下烦恼，将快乐进行到底！',
 'play': '2297579',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://music.163.com/playlist?id=8170169684>
{'collection': '播放',
 'comments': '31',
 'description': '介绍：戴上耳机放下烦恼，将快乐进行到底！',
 'play': '2297579',
 'songs': '60',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:53:37 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:53:37 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:53:37 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:53:37 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:53:37 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:53:37 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:53:37 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:53:37 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:53:37 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:53:37 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:53:37 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:53:37 [music_detail_spider] WARNING: [93mWARNING: String request is deprecated, please use JSON data format. Detail information, please check https://github.com/rmax/scrapy-redis#features[0m
2024-11-11 17:53:37 [music_detail_spider] DEBUG: Read 12 requests from 'detail_url_queue'
2024-11-11 17:53:42 [twisted] CRITICAL: while handling timed call
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 1428, in get_connection
    if connection.can_read() and self.cache is None:
       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 570, in can_read
    return self._parser.can_read(timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\base.py", line 128, in can_read
    return self._buffer and self._buffer.can_read(timeout)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\socket.py", line 95, in can_read
    return bool(self.unread_bytes()) or self._read_from_socket(
                                        ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\socket.py", line 68, in _read_from_socket
    raise ConnectionError(SERVER_CLOSED_CONNECTION_ERROR)
redis.exceptions.ConnectionError: Connection closed by server.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\base.py", line 1105, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy_redis\scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy_redis\queue.py", line 123, in pop
    results, count = pipe.execute()
                     ^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\client.py", line 1524, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 1432, in get_connection
    connection.connect()
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 369, in connect
    self.on_connect()
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 471, in on_connect
    self.read_response()
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 592, in read_response
    response = self._parser.read_response(disable_decoding=disable_decoding)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\resp2.py", line 15, in read_response
    result = self._read_response(disable_decoding=disable_decoding)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\resp2.py", line 25, in _read_response
    raw = self._buffer.readline()
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\socket.py", line 115, in readline
    self._read_from_socket()
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\socket.py", line 68, in _read_from_socket
    raise ConnectionError(SERVER_CLOSED_CONNECTION_ERROR)
redis.exceptions.ConnectionError: Connection closed by server.
2024-11-11 17:53:42 [twisted] CRITICAL: while handling timed call
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\base.py", line 1105, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy_redis\scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy_redis\queue.py", line 123, in pop
    results, count = pipe.execute()
                     ^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\client.py", line 1524, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 1422, in get_connection
    connection.connect()
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 369, in connect
    self.on_connect()
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 471, in on_connect
    self.read_response()
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 592, in read_response
    response = self._parser.read_response(disable_decoding=disable_decoding)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\resp2.py", line 15, in read_response
    result = self._read_response(disable_decoding=disable_decoding)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\resp2.py", line 25, in _read_response
    raw = self._buffer.readline()
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\socket.py", line 115, in readline
    self._read_from_socket()
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\socket.py", line 68, in _read_from_socket
    raise ConnectionError(SERVER_CLOSED_CONNECTION_ERROR)
redis.exceptions.ConnectionError: Connection closed by server.
2024-11-11 17:53:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=2945028696> (referer: None)
2024-11-11 17:53:43 [twisted] CRITICAL: while handling timed call
Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\base.py", line 1105, in runUntilCurrent
    call.func(*call.args, **call.kw)
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\reactor.py", line 58, in __call__
    return self._func(*self._a, **self._kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\engine.py", line 176, in _next_request
    and self._next_request_from_scheduler() is not None
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\core\engine.py", line 212, in _next_request_from_scheduler
    request = self.slot.scheduler.next_request()
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy_redis\scheduler.py", line 176, in next_request
    request = self.queue.pop(block_pop_timeout)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy_redis\queue.py", line 123, in pop
    results, count = pipe.execute()
                     ^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\client.py", line 1524, in execute
    conn = self.connection_pool.get_connection("MULTI", self.shard_hint)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 1422, in get_connection
    connection.connect()
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 369, in connect
    self.on_connect()
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 471, in on_connect
    self.read_response()
  File "C:\robot_work\.venv\Lib\site-packages\redis\connection.py", line 592, in read_response
    response = self._parser.read_response(disable_decoding=disable_decoding)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\resp2.py", line 15, in read_response
    result = self._read_response(disable_decoding=disable_decoding)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\resp2.py", line 25, in _read_response
    raw = self._buffer.readline()
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\socket.py", line 115, in readline
    self._read_from_socket()
  File "C:\robot_work\.venv\Lib\site-packages\redis\_parsers\socket.py", line 68, in _read_from_socket
    raise ConnectionError(SERVER_CLOSED_CONNECTION_ERROR)
redis.exceptions.ConnectionError: Connection closed by server.
2024-11-11 17:53:43 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '568',
 'description': '介绍：记忆快转\xa0转回90年代\xa0用老式收录音机听歌的日子\xa0时光点唱机\xa0回忆刚刚好',
 'play': '50308004',
 'songs': '30',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:54:13 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '568',
 'description': '介绍：记忆快转\xa0转回90年代\xa0用老式收录音机听歌的日子\xa0时光点唱机\xa0回忆刚刚好',
 'play': '50308004',
 'songs': '30',
 'tag': '无',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:54:13 [scrapy.extensions.logstats] INFO: Crawled 274 pages (at 17 pages/min), scraped 225 items (at 16 items/min)
2024-11-11 17:55:08 [scrapy.extensions.logstats] INFO: Crawled 274 pages (at 0 pages/min), scraped 225 items (at 0 items/min)
2024-11-11 17:55:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6969447123> (referer: None)
2024-11-11 17:55:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=7527357873> (referer: None)
2024-11-11 17:55:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=6957253005> (referer: None)
2024-11-11 17:55:09 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '8',
 'description': '介绍：月亮和音乐代表我的心。',
 'play': '227122',
 'songs': '35',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:55:39 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '8',
 'description': '介绍：月亮和音乐代表我的心。',
 'play': '227122',
 'songs': '35',
 'tag': '无',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:55:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12655214309> (referer: None)
2024-11-11 17:55:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12620838411> (referer: None)
2024-11-11 17:55:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=2968527373> (referer: None)
2024-11-11 17:55:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8756906204> (referer: None)
2024-11-11 17:55:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8661866203> (referer: None)
2024-11-11 17:55:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8484467201> (referer: None)
2024-11-11 17:55:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=12718935640> (referer: None)
2024-11-11 17:55:39 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '18',
 'description': '介绍：莫文蔚，华语流行乐女歌手、影视演员、音乐制作人。莫文蔚有特立独行的作派，她亦不介意在电影中作出丑态百出的装扮或行为；她是个有魅力的女人。她的脸上写满了风情和自信。',
 'play': '699323',
 'songs': '45',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:56:10 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '18',
 'description': '介绍：莫文蔚，华语流行乐女歌手、影视演员、音乐制作人。莫文蔚有特立独行的作派，她亦不介意在电影中作出丑态百出的装扮或行为；她是个有魅力的女人。她的脸上写满了风情和自信。',
 'play': '699323',
 'songs': '45',
 'tag': '无',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:56:10 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '6',
 'description': '介绍：1996年经典歌曲精选',
 'play': '333340',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:56:40 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '6',
 'description': '介绍：1996年经典歌曲精选',
 'play': '333340',
 'songs': '100',
 'tag': '无',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:56:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://music.163.com/playlist?id=8803637201> (referer: None)
2024-11-11 17:56:40 [scrapy.extensions.logstats] INFO: Crawled 285 pages (at 11 pages/min), scraped 225 items (at 0 items/min)
2024-11-11 17:56:40 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：永远会被R&B的律动与旋律打动，当下华语乐坛主流，R&B风格迎来了又一个春天，零几年的华语经典R&B歌曲，放在现在听依旧很超前！',
 'play': '4606',
 'songs': '88',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
2024-11-11 17:57:10 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：永远会被R&B的律动与旋律打动，当下华语乐坛主流，R&B风格迎来了又一个春天，零几年的华语经典R&B歌曲，放在现在听依旧很超前！',
 'play': '4606',
 'songs': '88',
 'tag': '华语-R&B/Soul-流行',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:57:10 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：天赐的声音：百听不厌的神仙live，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '2657',
 'songs': '40',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
2024-11-11 17:57:41 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：天赐的声音：百听不厌的神仙live，每一首都值得反复聆听，总有一首能成为你的白月光，你最爱哪位歌手的作品，欢迎评论区留言，歌单持续更新中，欢迎收藏，感谢聆听',
 'play': '2657',
 'songs': '40',
 'tag': '华语-流行-综艺',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:57:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1443',
 'description': '介绍：上课时\xa0塞在袖子里的MP3\xa0和同桌\xa0一人一只的耳机\xa0现在想想\xa0那时的歌那么好听\xa0'
                '只因我们\xa0都曾听得入了神',
 'play': '44983432',
 'songs': '30',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:58:11 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '1443',
 'description': '介绍：上课时\xa0塞在袖子里的MP3\xa0和同桌\xa0一人一只的耳机\xa0现在想想\xa0那时的歌那么好听\xa0'
                '只因我们\xa0都曾听得入了神',
 'play': '44983432',
 'songs': '30',
 'tag': '无',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:58:11 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2',
 'description': '介绍：EMI唱片公司前身是1897年成立于伦敦的英国留声机公司，是当今历史最悠久的唱片公司，迄今已有百年。',
 'play': '53990',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:58:41 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '2',
 'description': '介绍：EMI唱片公司前身是1897年成立于伦敦的英国留声机公司，是当今历史最悠久的唱片公司，迄今已有百年。',
 'play': '53990',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:58:41 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '评论',
 'description': '介绍：重温承载着情感与故事的旋律 带你重返记忆中的华语R&B',
 'play': '62388',
 'songs': '40',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:59:12 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '评论',
 'description': '介绍：重温承载着情感与故事的旋律 带你重返记忆中的华语R&B',
 'play': '62388',
 'songs': '40',
 'tag': '无',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:59:12 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '2',
 'description': '介绍：心情糟糕的时候 安静地听一首民谣 让音乐驱散情绪',
 'play': '600591',
 'songs': '40',
 'tag': '无',
 'title': '无标题'}
2024-11-11 17:59:42 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '2',
 'description': '介绍：心情糟糕的时候 安静地听一首民谣 让音乐驱散情绪',
 'play': '600591',
 'songs': '40',
 'tag': '无',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 17:59:42 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '1',
 'description': '介绍：出去走走吧 不是所有事情都必须有意义 在街头巷尾流憩也是种自由',
 'play': '12282',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
2024-11-11 18:00:13 [scrapy.core.scraper] ERROR: Error processing {'collection': '播放',
 'comments': '1',
 'description': '介绍：出去走走吧 不是所有事情都必须有意义 在街头巷尾流憩也是种自由',
 'play': '12282',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
Traceback (most recent call last):
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 37, in process_item
    collection.insert_one(dict(item))
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 891, in insert_one
    self._insert_one(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\collection.py", line 831, in _insert_one
    self._database.client._retryable_write(
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1898, in _retryable_write
    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1784, in _retry_with_session
    return self._retry_internal(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\_csot.py", line 119, in csot_wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1830, in _retry_internal
    ).run()
      ^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2554, in run
    return self._read() if self._is_read else self._write()
                                              ^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2662, in _write
    self._server = self._get_server()
                   ^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 2645, in _get_server
    return self._client._select_server(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\mongo_client.py", line 1649, in _select_server
    server = topology.select_server(
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 398, in select_server
    server = self._select_server(
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 376, in _select_server
    servers = self.select_servers(
              ^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 283, in select_servers
    server_descriptions = self._select_servers_loop(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\pymongo\synchronous\topology.py", line 333, in _select_servers_loop
    raise ServerSelectionTimeoutError(
pymongo.errors.ServerSelectionTimeoutError: localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6731c87bb46ad984d55fc818, topology_type: Single, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] 由于目标计算机积极拒绝，无法连接。 (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\robot_work\.venv\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\robot_work\.venv\Lib\site-packages\scrapy\utils\defer.py", line 340, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\robot_work\eggs\robot_work\1731216209.egg\robot_work\pipelines.py", line 41, in process_item
    except errors.PyMongoError as e:
           ^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'PyMongoError'
2024-11-11 18:00:13 [scrapy.extensions.logstats] INFO: Crawled 285 pages (at 0 pages/min), scraped 225 items (at 0 items/min)
2024-11-11 18:00:13 [root] INFO: 插入产品到MongoDB: {'collection': '播放',
 'comments': '19',
 'description': '介绍：2010年代华语R&B热歌精选',
 'play': '1074579',
 'songs': '50',
 'tag': '无',
 'title': '无标题'}
